# Snippets from revised chapter "Parameter estimation"


## Comparing Bayesian and frequentist estimates {#ch-03-03-estimation-comparison}


## Best fits for linear regression

```{r}
# function for the negative log-likelihood of the given
# data and fixed parameter values
nll = function(y, x, beta_0, beta_1, sd) {
  # negative sigma is logically impossible
  if (sd <= 0) {return( Inf )}
  # predicted values
  yPred = beta_0 + x * beta_1
  # negative log-likelihood of each data point 
  nll = -dnorm(y, mean=yPred, sd=sd, log = T)
  # sum over all observations
  sum(nll)
}
fit_lh = optim(
  # initial parameter values
  par = c(1.5, 0, 0.5),
  # function to optimize
  fn = function(par) {
    with(avocado_data, 
         nll(average_price, total_volume_sold,
             par[1], par[2], par[3])
    )
  }
)
fit_lh$par
```

This result tells us that the best fitting parameter triple has an intercept of $\beta_0 \approx 1.42$, a slope $\beta_1 \approx -2.47$ and a standard deviation $\sigma \approx 0.39$. We can compare these values with a built-in function for linear regression models (which, however, does not return an estimate of $\sigma$ (see Chapter \@ref(Chap-04-01-simple-linear-regression) for more information)):

```{r}
lm(average_price ~ total_volume_sold, avocado_data)$coef
```
