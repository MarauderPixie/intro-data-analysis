<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.4 Strolling the zoo of models | Introduction to Data Analysis</title>
  <meta name="description" content="Introductory text for statistics and data analysis (using R)" />
  <meta name="generator" content="bookdown 0.21.4 and GitBook 2.6.7" />

  <meta property="og:title" content="1.4 Strolling the zoo of models | Introduction to Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Introductory text for statistics and data analysis (using R)" />
  <meta name="github-repo" content="michael-franke/intro-data-analysis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.4 Strolling the zoo of models | Introduction to Data Analysis" />
  
  <meta name="twitter:description" content="Introductory text for statistics and data analysis (using R)" />
  

<meta name="author" content="Michael Franke" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="Chap-03-03-models-three-pillars.html"/>
<link rel="next" href="Chap-03-03-models-hypotheses.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<!--<link rel="stylesheet" href="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-editor-1.0.9.css">-->
<link rel="stylesheet" href="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-viz-0.7.11.css">

<script src="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-editor-1.0.9.js"></script>
<script src="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-viz-0.7.11.js"></script>
<script src="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-v0.9.13.js" defer async></script>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />

<script type="application/javascript">
document.addEventListener('DOMContentLoaded', function() {
  document.querySelectorAll('.collapsibleSolution').forEach(function(collapsible) {
    const content = collapsible.querySelector('.content')
    content.style.display = 'none';
    collapsible.querySelector('.trigger').addEventListener('click', function() {
      if (content.style.display === 'none') {
        content.style.display = 'block';
      } else {
        content.style.display = 'none';
      }
    })
  })
})
</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span. { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />
<link rel="stylesheet" href="webppl-editor.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="snippets-from-revised-chapters.html"><a href="snippets-from-revised-chapters.html"><i class="fa fa-check"></i><b>1</b> Snippets from revised chapters</a><ul>
<li class="chapter" data-level="1.1" data-path="model-examples.html"><a href="model-examples.html"><i class="fa fa-check"></i><b>1.1</b> Model examples</a><ul>
<li class="chapter" data-level="1.1.1" data-path="model-examples.html"><a href="model-examples.html#Chap-03-03-models-general-urn-example"><i class="fa fa-check"></i><b>1.1.1</b> Example 1: a single draw from an urn</a></li>
<li class="chapter" data-level="1.1.2" data-path="model-examples.html"><a href="model-examples.html#example-2-avocado-prices-by-type"><i class="fa fa-check"></i><b>1.1.2</b> Example 2: avocado prices by type</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="more-on-notation-for-models.html"><a href="more-on-notation-for-models.html"><i class="fa fa-check"></i><b>1.2</b> More on notation for models</a><ul>
<li class="chapter" data-level="1.2.1" data-path="more-on-notation-for-models.html"><a href="more-on-notation-for-models.html#multiple-observations"><i class="fa fa-check"></i><b>1.2.1</b> Multiple observations</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="Chap-03-03-models-three-pillars.html"><a href="Chap-03-03-models-three-pillars.html"><i class="fa fa-check"></i><b>1.3</b> Three pillars of data analysis</a><ul>
<li class="chapter" data-level="1.3.1" data-path="Chap-03-03-models-three-pillars.html"><a href="Chap-03-03-models-three-pillars.html#two-notions-of-probability-revisited"><i class="fa fa-check"></i><b>1.3.1</b> Two notions of probability (revisited)</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="Chap-03-03-models-examples.html"><a href="Chap-03-03-models-examples.html"><i class="fa fa-check"></i><b>1.4</b> Strolling the zoo of models</a><ul>
<li class="chapter" data-level="1.4.1" data-path="Chap-03-03-models-examples.html"><a href="Chap-03-03-models-examples.html#Chap-03-03-models-examples-binomial"><i class="fa fa-check"></i><b>1.4.1</b> The Binomial Model</a></li>
<li class="chapter" data-level="1.4.2" data-path="Chap-03-03-models-examples.html"><a href="Chap-03-03-models-examples.html#flip-and-draw-model"><i class="fa fa-check"></i><b>1.4.2</b> Flip-and-Draw Model</a></li>
<li class="chapter" data-level="1.4.3" data-path="Chap-03-03-models-examples.html"><a href="Chap-03-03-models-examples.html#flip-and-draw-hypergeometric-model"><i class="fa fa-check"></i><b>1.4.3</b> Flip-and-Draw-Hypergeometric Model</a></li>
<li class="chapter" data-level="1.4.4" data-path="Chap-03-03-models-examples.html"><a href="Chap-03-03-models-examples.html#t-test-model-comparing-two-groups"><i class="fa fa-check"></i><b>1.4.4</b> T-Test Model: comparing two groups</a></li>
<li class="chapter" data-level="1.4.5" data-path="Chap-03-03-models-examples.html"><a href="Chap-03-03-models-examples.html#simple-linear-regression-model"><i class="fa fa-check"></i><b>1.4.5</b> Simple Linear Regression Model</a></li>
<li class="chapter" data-level="1.4.6" data-path="Chap-03-03-models-examples.html"><a href="Chap-03-03-models-examples.html#Chap-03-03-models-examples-linear-regression"><i class="fa fa-check"></i><b>1.4.6</b> Linear Regression with Two Groups</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="Chap-03-03-models-hypotheses.html"><a href="Chap-03-03-models-hypotheses.html"><i class="fa fa-check"></i><b>1.5</b> Expressing hypotheses with models</a></li>
</ul></li>
<li class="part"><span><b>I Preliminaries</b></span></li>
<li class="chapter" data-level="2" data-path="general-introduction.html"><a href="general-introduction.html"><i class="fa fa-check"></i><b>2</b> General Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="Chap-01-00-intro-learning-goals.html"><a href="Chap-01-00-intro-learning-goals.html"><i class="fa fa-check"></i><b>2.1</b> Learning goals</a></li>
<li class="chapter" data-level="2.2" data-path="Chap-01-00-intro-course-structure.html"><a href="Chap-01-00-intro-course-structure.html"><i class="fa fa-check"></i><b>2.2</b> Course structure</a></li>
<li class="chapter" data-level="2.3" data-path="Chap-01-00-intro-tools.html"><a href="Chap-01-00-intro-tools.html"><i class="fa fa-check"></i><b>2.3</b> Tools used in this course</a></li>
<li class="chapter" data-level="2.4" data-path="Chap-01-00-intro-topics.html"><a href="Chap-01-00-intro-topics.html"><i class="fa fa-check"></i><b>2.4</b> Topics covered (and not covered) in the course</a></li>
<li class="chapter" data-level="2.5" data-path="Chap-01-00-intro-data-sets.html"><a href="Chap-01-00-intro-data-sets.html"><i class="fa fa-check"></i><b>2.5</b> Data sets covered</a></li>
<li class="chapter" data-level="2.6" data-path="Chap-01-00-intro-installation.html"><a href="Chap-01-00-intro-installation.html"><i class="fa fa-check"></i><b>2.6</b> Installation</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Chap-01-01-R.html"><a href="Chap-01-01-R.html"><i class="fa fa-check"></i><b>3</b> Basics of R</a><ul>
<li class="chapter" data-level="3.1" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html"><i class="fa fa-check"></i><b>3.1</b> First steps</a><ul>
<li class="chapter" data-level="3.1.1" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#functions"><i class="fa fa-check"></i><b>3.1.1</b> Functions</a></li>
<li class="chapter" data-level="3.1.2" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#variables"><i class="fa fa-check"></i><b>3.1.2</b> Variables</a></li>
<li class="chapter" data-level="3.1.3" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#literate-coding"><i class="fa fa-check"></i><b>3.1.3</b> Literate coding</a></li>
<li class="chapter" data-level="3.1.4" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#objects"><i class="fa fa-check"></i><b>3.1.4</b> Objects</a></li>
<li class="chapter" data-level="3.1.5" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#packages"><i class="fa fa-check"></i><b>3.1.5</b> Packages</a></li>
<li class="chapter" data-level="3.1.6" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#Chap-01-01-R-help"><i class="fa fa-check"></i><b>3.1.6</b> Getting help</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="ch1-data-types.html"><a href="ch1-data-types.html"><i class="fa fa-check"></i><b>3.2</b> Data types</a><ul>
<li class="chapter" data-level="3.2.1" data-path="ch1-data-types.html"><a href="ch1-data-types.html#numeric-vectors-matrices"><i class="fa fa-check"></i><b>3.2.1</b> Numeric vectors &amp; matrices</a></li>
<li class="chapter" data-level="3.2.2" data-path="ch1-data-types.html"><a href="ch1-data-types.html#booleans"><i class="fa fa-check"></i><b>3.2.2</b> Booleans</a></li>
<li class="chapter" data-level="3.2.3" data-path="ch1-data-types.html"><a href="ch1-data-types.html#special-values"><i class="fa fa-check"></i><b>3.2.3</b> Special values</a></li>
<li class="chapter" data-level="3.2.4" data-path="ch1-data-types.html"><a href="ch1-data-types.html#characters-strings"><i class="fa fa-check"></i><b>3.2.4</b> Characters (= strings)</a></li>
<li class="chapter" data-level="3.2.5" data-path="ch1-data-types.html"><a href="ch1-data-types.html#factors"><i class="fa fa-check"></i><b>3.2.5</b> Factors</a></li>
<li class="chapter" data-level="3.2.6" data-path="ch1-data-types.html"><a href="ch1-data-types.html#lists-data-frames-tibbles"><i class="fa fa-check"></i><b>3.2.6</b> Lists, data frames &amp; tibbles</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="Chap-01-01-functions.html"><a href="Chap-01-01-functions.html"><i class="fa fa-check"></i><b>3.3</b> Functions</a><ul>
<li class="chapter" data-level="3.3.1" data-path="Chap-01-01-functions.html"><a href="Chap-01-01-functions.html#some-important-built-in-functions"><i class="fa fa-check"></i><b>3.3.1</b> Some important built-in functions</a></li>
<li class="chapter" data-level="3.3.2" data-path="Chap-01-01-functions.html"><a href="Chap-01-01-functions.html#defining-your-own-functions"><i class="fa fa-check"></i><b>3.3.2</b> Defining your own functions</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="ch-01-01-loops-and-maps.html"><a href="ch-01-01-loops-and-maps.html"><i class="fa fa-check"></i><b>3.4</b> Loops and maps</a><ul>
<li class="chapter" data-level="3.4.1" data-path="ch-01-01-loops-and-maps.html"><a href="ch-01-01-loops-and-maps.html#for-loops"><i class="fa fa-check"></i><b>3.4.1</b> For-loops</a></li>
<li class="chapter" data-level="3.4.2" data-path="ch-01-01-loops-and-maps.html"><a href="ch-01-01-loops-and-maps.html#functional-iterators"><i class="fa fa-check"></i><b>3.4.2</b> Functional iterators</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="Chap-01-01-piping.html"><a href="Chap-01-01-piping.html"><i class="fa fa-check"></i><b>3.5</b> Piping</a></li>
<li class="chapter" data-level="3.6" data-path="ch-01-01-Rmarkdown.html"><a href="ch-01-01-Rmarkdown.html"><i class="fa fa-check"></i><b>3.6</b> Rmarkdown</a></li>
</ul></li>
<li class="part"><span><b>II Data</b></span></li>
<li class="chapter" data-level="4" data-path="Chap-02-01-data.html"><a href="Chap-02-01-data.html"><i class="fa fa-check"></i><b>4</b> Data, variables &amp; experimental designs</a><ul>
<li class="chapter" data-level="4.1" data-path="Chap-02-01-data-what-is-data.html"><a href="Chap-02-01-data-what-is-data.html"><i class="fa fa-check"></i><b>4.1</b> What is data?</a></li>
<li class="chapter" data-level="4.2" data-path="Chap-02-01-data-kinds-of-data.html"><a href="Chap-02-01-data-kinds-of-data.html"><i class="fa fa-check"></i><b>4.2</b> Different kinds of data</a></li>
<li class="chapter" data-level="4.3" data-path="Chap-02-01-data-variables.html"><a href="Chap-02-01-data-variables.html"><i class="fa fa-check"></i><b>4.3</b> On the notion of “variables”</a></li>
<li class="chapter" data-level="4.4" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html"><i class="fa fa-check"></i><b>4.4</b> Basics of experimental design</a><ul>
<li class="chapter" data-level="4.4.1" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html#what-to-analyze-dependent-variables"><i class="fa fa-check"></i><b>4.4.1</b> What to analyze? – Dependent variables</a></li>
<li class="chapter" data-level="4.4.2" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html#conditions-trials-items"><i class="fa fa-check"></i><b>4.4.2</b> Conditions, trials, items</a></li>
<li class="chapter" data-level="4.4.3" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html#sample-size"><i class="fa fa-check"></i><b>4.4.3</b> Sample size</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="data-wrangling.html"><a href="data-wrangling.html"><i class="fa fa-check"></i><b>5</b> Data Wrangling</a><ul>
<li class="chapter" data-level="5.1" data-path="Chap-02-02-data-IO.html"><a href="Chap-02-02-data-IO.html"><i class="fa fa-check"></i><b>5.1</b> Data in, data out</a></li>
<li class="chapter" data-level="5.2" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html"><i class="fa fa-check"></i><b>5.2</b> Tidy data</a><ul>
<li class="chapter" data-level="5.2.1" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html#running-example"><i class="fa fa-check"></i><b>5.2.1</b> Running example</a></li>
<li class="chapter" data-level="5.2.2" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html#definition-of-tidy-data"><i class="fa fa-check"></i><b>5.2.2</b> Definition of <em>tidy data</em></a></li>
<li class="chapter" data-level="5.2.3" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html#excursion-non-redundant-data"><i class="fa fa-check"></i><b>5.2.3</b> Excursion: non-redundant data</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html"><i class="fa fa-check"></i><b>5.3</b> Data manipulation: the basics</a><ul>
<li class="chapter" data-level="5.3.1" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#pivoting"><i class="fa fa-check"></i><b>5.3.1</b> Pivoting</a></li>
<li class="chapter" data-level="5.3.2" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#subsetting-row-columns"><i class="fa fa-check"></i><b>5.3.2</b> Subsetting row &amp; columns</a></li>
<li class="chapter" data-level="5.3.3" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#Chap-02-02-tidy-selection"><i class="fa fa-check"></i><b>5.3.3</b> Tidy selection of column names</a></li>
<li class="chapter" data-level="5.3.4" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#adding-changing-and-renaming-columns"><i class="fa fa-check"></i><b>5.3.4</b> Adding, changing and renaming columns</a></li>
<li class="chapter" data-level="5.3.5" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#splitting-and-uniting-columns"><i class="fa fa-check"></i><b>5.3.5</b> Splitting and uniting columns</a></li>
<li class="chapter" data-level="5.3.6" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#sorting-a-data-set"><i class="fa fa-check"></i><b>5.3.6</b> Sorting a data set</a></li>
<li class="chapter" data-level="5.3.7" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#combining-tibbles"><i class="fa fa-check"></i><b>5.3.7</b> Combining tibbles</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="Chap-02-02-data-grouping-nesting.html"><a href="Chap-02-02-data-grouping-nesting.html"><i class="fa fa-check"></i><b>5.4</b> Grouped operations</a></li>
<li class="chapter" data-level="5.5" data-path="Chap-02-02-data-case-study-KoF.html"><a href="Chap-02-02-data-case-study-KoF.html"><i class="fa fa-check"></i><b>5.5</b> Case study: the King of France</a><ul>
<li class="chapter" data-level="5.5.1" data-path="Chap-02-02-data-case-study-KoF.html"><a href="Chap-02-02-data-case-study-KoF.html#cleaning-the-data"><i class="fa fa-check"></i><b>5.5.1</b> Cleaning the data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Chap-02-03-summary-statistics.html"><a href="Chap-02-03-summary-statistics.html"><i class="fa fa-check"></i><b>6</b> Summary statistics</a><ul>
<li class="chapter" data-level="6.1" data-path="Chap-02-03-summary-statistics-counts.html"><a href="Chap-02-03-summary-statistics-counts.html"><i class="fa fa-check"></i><b>6.1</b> Counts and proportions</a><ul>
<li class="chapter" data-level="6.1.1" data-path="Chap-02-03-summary-statistics-counts.html"><a href="Chap-02-03-summary-statistics-counts.html#loading-and-inspecting-the-data"><i class="fa fa-check"></i><b>6.1.1</b> Loading and inspecting the data</a></li>
<li class="chapter" data-level="6.1.2" data-path="Chap-02-03-summary-statistics-counts.html"><a href="Chap-02-03-summary-statistics-counts.html#obtaining-counts-with-n-count-and-tally"><i class="fa fa-check"></i><b>6.1.2</b> Obtaining counts with <code>n</code>, <code>count</code> and <code>tally</code></a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html"><i class="fa fa-check"></i><b>6.2</b> Central tendency and dispersion</a><ul>
<li class="chapter" data-level="6.2.1" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#the-data-for-the-remainder-of-the-chapter"><i class="fa fa-check"></i><b>6.2.1</b> The data for the remainder of the chapter</a></li>
<li class="chapter" data-level="6.2.2" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#measures-of-central-tendency"><i class="fa fa-check"></i><b>6.2.2</b> Measures of central tendency</a></li>
<li class="chapter" data-level="6.2.3" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#measures-of-dispersion"><i class="fa fa-check"></i><b>6.2.3</b> Measures of dispersion</a></li>
<li class="chapter" data-level="6.2.4" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#excursion-quantifying-confidence-with-bootstrapping"><i class="fa fa-check"></i><b>6.2.4</b> Excursion: Quantifying confidence with bootstrapping</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="Chap-02-03-summary-statistics-2D.html"><a href="Chap-02-03-summary-statistics-2D.html"><i class="fa fa-check"></i><b>6.3</b> Covariance and correlation</a><ul>
<li class="chapter" data-level="6.3.1" data-path="Chap-02-03-summary-statistics-2D.html"><a href="Chap-02-03-summary-statistics-2D.html#covariance"><i class="fa fa-check"></i><b>6.3.1</b> Covariance</a></li>
<li class="chapter" data-level="6.3.2" data-path="Chap-02-03-summary-statistics-2D.html"><a href="Chap-02-03-summary-statistics-2D.html#correlation"><i class="fa fa-check"></i><b>6.3.2</b> Correlation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Chap-02-02-visualization.html"><a href="Chap-02-02-visualization.html"><i class="fa fa-check"></i><b>7</b> Data Visualization</a><ul>
<li class="chapter" data-level="7.1" data-path="Chap-02-04-Anscombe-example.html"><a href="Chap-02-04-Anscombe-example.html"><i class="fa fa-check"></i><b>7.1</b> Motivating example: Anscombe’s quartet</a></li>
<li class="chapter" data-level="7.2" data-path="Chap-02-04-good-visualization.html"><a href="Chap-02-04-good-visualization.html"><i class="fa fa-check"></i><b>7.2</b> Visualization: the good, the bad and the infographic</a></li>
<li class="chapter" data-level="7.3" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html"><i class="fa fa-check"></i><b>7.3</b> Basics of <code>ggplot</code></a><ul>
<li class="chapter" data-level="7.3.1" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#incremental-composition-of-a-plot"><i class="fa fa-check"></i><b>7.3.1</b> Incremental composition of a plot</a></li>
<li class="chapter" data-level="7.3.2" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#elements-in-the-layered-grammar-of-graphs"><i class="fa fa-check"></i><b>7.3.2</b> Elements in the layered grammar of graphs</a></li>
<li class="chapter" data-level="7.3.3" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#layers-and-groups"><i class="fa fa-check"></i><b>7.3.3</b> Layers and groups</a></li>
<li class="chapter" data-level="7.3.4" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#grouping"><i class="fa fa-check"></i><b>7.3.4</b> Grouping</a></li>
<li class="chapter" data-level="7.3.5" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#example-of-a-customized-plot"><i class="fa fa-check"></i><b>7.3.5</b> Example of a customized plot</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html"><i class="fa fa-check"></i><b>7.4</b> A rendezvous with popular geoms</a><ul>
<li class="chapter" data-level="7.4.1" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#scatter-plots-with-geom_point"><i class="fa fa-check"></i><b>7.4.1</b> Scatter plots with <code>geom_point</code></a></li>
<li class="chapter" data-level="7.4.2" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#smooth"><i class="fa fa-check"></i><b>7.4.2</b> Smooth</a></li>
<li class="chapter" data-level="7.4.3" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#line"><i class="fa fa-check"></i><b>7.4.3</b> Line</a></li>
<li class="chapter" data-level="7.4.4" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#barplot"><i class="fa fa-check"></i><b>7.4.4</b> Barplot</a></li>
<li class="chapter" data-level="7.4.5" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#plotting-distributions-histograms-boxplots-densities-and-violins"><i class="fa fa-check"></i><b>7.4.5</b> Plotting distributions: histograms, boxplots, densities and violins</a></li>
<li class="chapter" data-level="7.4.6" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#rugs"><i class="fa fa-check"></i><b>7.4.6</b> Rugs</a></li>
<li class="chapter" data-level="7.4.7" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#annotation"><i class="fa fa-check"></i><b>7.4.7</b> Annotation</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="Chap-02-04-faceting.html"><a href="Chap-02-04-faceting.html"><i class="fa fa-check"></i><b>7.5</b> Faceting</a></li>
<li class="chapter" data-level="7.6" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html"><i class="fa fa-check"></i><b>7.6</b> Customization etc.</a><ul>
<li class="chapter" data-level="7.6.1" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#themes"><i class="fa fa-check"></i><b>7.6.1</b> Themes</a></li>
<li class="chapter" data-level="7.6.2" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#guides"><i class="fa fa-check"></i><b>7.6.2</b> Guides</a></li>
<li class="chapter" data-level="7.6.3" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#axes-ticks-and-tick-labels"><i class="fa fa-check"></i><b>7.6.3</b> Axes, ticks and tick labels</a></li>
<li class="chapter" data-level="7.6.4" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#labels"><i class="fa fa-check"></i><b>7.6.4</b> Labels</a></li>
<li class="chapter" data-level="7.6.5" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#combining-arranging-plots"><i class="fa fa-check"></i><b>7.6.5</b> Combining &amp; arranging plots</a></li>
<li class="chapter" data-level="7.6.6" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#latex-expressions-in-plot-labels"><i class="fa fa-check"></i><b>7.6.6</b> LaTeX expressions in plot labels</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Models and inferences</b></span></li>
<li class="chapter" data-level="8" data-path="Chap-03-01-probability.html"><a href="Chap-03-01-probability.html"><i class="fa fa-check"></i><b>8</b> Basics of Probability Theory</a><ul>
<li class="chapter" data-level="8.1" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html"><i class="fa fa-check"></i><b>8.1</b> Probability</a><ul>
<li class="chapter" data-level="8.1.1" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#outcomes-events-observations"><i class="fa fa-check"></i><b>8.1.1</b> Outcomes, events, observations</a></li>
<li class="chapter" data-level="8.1.2" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#probability-distributions"><i class="fa fa-check"></i><b>8.1.2</b> Probability distributions</a></li>
<li class="chapter" data-level="8.1.3" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#interpretations-of-probability"><i class="fa fa-check"></i><b>8.1.3</b> Interpretations of probability</a></li>
<li class="chapter" data-level="8.1.4" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#distributions-as-samples"><i class="fa fa-check"></i><b>8.1.4</b> Distributions as samples</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html"><i class="fa fa-check"></i><b>8.2</b> Structured events &amp; marginal distributions</a><ul>
<li class="chapter" data-level="8.2.1" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html#probability-table-for-a-flip-and-draw-scenario"><i class="fa fa-check"></i><b>8.2.1</b> Probability table for a flip-and-draw scenario</a></li>
<li class="chapter" data-level="8.2.2" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html#structured-events-and-joint-probability-distributions"><i class="fa fa-check"></i><b>8.2.2</b> Structured events and joint-probability distributions</a></li>
<li class="chapter" data-level="8.2.3" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html#marginalization"><i class="fa fa-check"></i><b>8.2.3</b> Marginalization</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="Chap-03-01-probability-conditional.html"><a href="Chap-03-01-probability-conditional.html"><i class="fa fa-check"></i><b>8.3</b> Conditional probability</a><ul>
<li class="chapter" data-level="8.3.1" data-path="Chap-03-01-probability-conditional.html"><a href="Chap-03-01-probability-conditional.html#bayes-rule"><i class="fa fa-check"></i><b>8.3.1</b> Bayes rule</a></li>
<li class="chapter" data-level="8.3.2" data-path="Chap-03-01-probability-conditional.html"><a href="Chap-03-01-probability-conditional.html#Chap-03-01-probability-independence"><i class="fa fa-check"></i><b>8.3.2</b> Stochastic (in-)dependence</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html"><i class="fa fa-check"></i><b>8.4</b> Random variables</a><ul>
<li class="chapter" data-level="8.4.1" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#notation-terminology"><i class="fa fa-check"></i><b>8.4.1</b> Notation &amp; terminology</a></li>
<li class="chapter" data-level="8.4.2" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#cumulative-distribution-functions-mass-density"><i class="fa fa-check"></i><b>8.4.2</b> Cumulative distribution functions, mass &amp; density</a></li>
<li class="chapter" data-level="8.4.3" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#expected-value-variance"><i class="fa fa-check"></i><b>8.4.3</b> Expected value &amp; variance</a></li>
<li class="chapter" data-level="8.4.4" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#composite-random-variables"><i class="fa fa-check"></i><b>8.4.4</b> Composite random variables</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="Chap-03-01-probability-R.html"><a href="Chap-03-01-probability-R.html"><i class="fa fa-check"></i><b>8.5</b> Probability distributions in R</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="Chap-03-03-models.html"><a href="Chap-03-03-models.html"><i class="fa fa-check"></i><b>9</b> Models</a><ul>
<li class="chapter" data-level="9.1" data-path="Chap-03-03-models-general.html"><a href="Chap-03-03-models-general.html"><i class="fa fa-check"></i><b>9.1</b> Statistical models</a></li>
<li class="chapter" data-level="9.2" data-path="Chap-03-03-models-representation.html"><a href="Chap-03-03-models-representation.html"><i class="fa fa-check"></i><b>9.2</b> Notation &amp; graphical representation</a><ul>
<li class="chapter" data-level="9.2.1" data-path="Chap-03-03-models-representation.html"><a href="Chap-03-03-models-representation.html#formula-notation"><i class="fa fa-check"></i><b>9.2.1</b> Formula notation</a></li>
<li class="chapter" data-level="9.2.2" data-path="Chap-03-03-models-representation.html"><a href="Chap-03-03-models-representation.html#graphical-notation"><i class="fa fa-check"></i><b>9.2.2</b> Graphical notation</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html"><i class="fa fa-check"></i><b>9.3</b> Parameters, priors, and prior predictions</a><ul>
<li class="chapter" data-level="9.3.1" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html#whats-a-model-parameter"><i class="fa fa-check"></i><b>9.3.1</b> What’s a model parameter?</a></li>
<li class="chapter" data-level="9.3.2" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html#Chap-03-02-models-priors"><i class="fa fa-check"></i><b>9.3.2</b> Priors over parameters</a></li>
<li class="chapter" data-level="9.3.3" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html#prior-predictions"><i class="fa fa-check"></i><b>9.3.3</b> Prior predictions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ch-03-04-parameter-estimation.html"><a href="ch-03-04-parameter-estimation.html"><i class="fa fa-check"></i><b>10</b> Parameter estimation</a><ul>
<li class="chapter" data-level="10.1" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html"><i class="fa fa-check"></i><b>10.1</b> Bayes rule of parameter estimation</a><ul>
<li class="chapter" data-level="10.1.1" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#the-effects-of-prior-and-likelihood-on-the-posterior"><i class="fa fa-check"></i><b>10.1.1</b> The effects of prior and likelihood on the posterior</a></li>
<li class="chapter" data-level="10.1.2" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#posterior-means-and-credible-intervals"><i class="fa fa-check"></i><b>10.1.2</b> Posterior means and credible intervals</a></li>
<li class="chapter" data-level="10.1.3" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#ch-03-04-parameter-estimation-conjugacy"><i class="fa fa-check"></i><b>10.1.3</b> Computing Bayesian posteriors with conjugate priors</a></li>
<li class="chapter" data-level="10.1.4" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#sequential-updating"><i class="fa fa-check"></i><b>10.1.4</b> Sequential updating</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="ch-03-03-estimation-frequentist.html"><a href="ch-03-03-estimation-frequentist.html"><i class="fa fa-check"></i><b>10.2</b> A frequentist approach to parameter estimation</a><ul>
<li class="chapter" data-level="10.2.1" data-path="ch-03-03-estimation-frequentist.html"><a href="ch-03-03-estimation-frequentist.html#maximum-likelihood-estimate"><i class="fa fa-check"></i><b>10.2.1</b> Maximum likelihood estimate</a></li>
<li class="chapter" data-level="10.2.2" data-path="ch-03-03-estimation-frequentist.html"><a href="ch-03-03-estimation-frequentist.html#confidence-intervals"><i class="fa fa-check"></i><b>10.2.2</b> Confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="ch-03-03-estimation-testing.html"><a href="ch-03-03-estimation-testing.html"><i class="fa fa-check"></i><b>10.3</b> Addressing point-valued hypotheses with parameter estimation</a></li>
<li class="chapter" data-level="10.4" data-path="ch-03-03-estimation-comparison.html"><a href="ch-03-03-estimation-comparison.html"><i class="fa fa-check"></i><b>10.4</b> Comparing Bayesian and frequentist estimates</a></li>
<li class="chapter" data-level="10.5" data-path="Ch-03-03-estimation-algorithms.html"><a href="Ch-03-03-estimation-algorithms.html"><i class="fa fa-check"></i><b>10.5</b> Algorithms for parameter estimation</a><ul>
<li class="chapter" data-level="10.5.1" data-path="Ch-03-03-estimation-algorithms.html"><a href="Ch-03-03-estimation-algorithms.html#optimizing-functions"><i class="fa fa-check"></i><b>10.5.1</b> Optimizing functions</a></li>
<li class="chapter" data-level="10.5.2" data-path="Ch-03-03-estimation-algorithms.html"><a href="Ch-03-03-estimation-algorithms.html#approximating-posterior-distributions"><i class="fa fa-check"></i><b>10.5.2</b> Approximating posterior distributions</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="ch-03-03-estimation-Stan.html"><a href="ch-03-03-estimation-Stan.html"><i class="fa fa-check"></i><b>10.6</b> Probabilistic modeling with Stan</a><ul>
<li class="chapter" data-level="10.6.1" data-path="ch-03-03-estimation-Stan.html"><a href="ch-03-03-estimation-Stan.html#basics-of-stan"><i class="fa fa-check"></i><b>10.6.1</b> Basics of Stan</a></li>
<li class="chapter" data-level="10.6.2" data-path="ch-03-03-estimation-Stan.html"><a href="ch-03-03-estimation-Stan.html#binomial-model"><i class="fa fa-check"></i><b>10.6.2</b> Binomial Model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ch-03-05-hypothesis-testing.html"><a href="ch-03-05-hypothesis-testing.html"><i class="fa fa-check"></i><b>11</b> Hypothesis Testing</a><ul>
<li class="chapter" data-level="11.1" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html"><i class="fa fa-check"></i><b>11.1</b> <em>p</em>-values</a><ul>
<li class="chapter" data-level="11.1.1" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#binomial-model---frequentist-version"><i class="fa fa-check"></i><b>11.1.1</b> Binomial Model - frequentist version</a></li>
<li class="chapter" data-level="11.1.2" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#p-values-for-the-binomial-model"><i class="fa fa-check"></i><b>11.1.2</b> <em>p</em>-values for the Binomial Model</a></li>
<li class="chapter" data-level="11.1.3" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#statistical-significance"><i class="fa fa-check"></i><b>11.1.3</b> Statistical significance</a></li>
<li class="chapter" data-level="11.1.4" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#p-values-and-alpha-errors"><i class="fa fa-check"></i><b>11.1.4</b> <em>p</em>-values and <span class="math inline">\(\alpha\)</span>-errors</a></li>
<li class="chapter" data-level="11.1.5" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#relation-of-p-values-to-confidence-intervals"><i class="fa fa-check"></i><b>11.1.5</b> Relation of <em>p</em>-values to confidence intervals</a></li>
<li class="chapter" data-level="11.1.6" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#distribution-of-p-values"><i class="fa fa-check"></i><b>11.1.6</b> Distribution of <span class="math inline">\(p\)</span>-values</a></li>
<li class="chapter" data-level="11.1.7" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#how-not-to-interpret-p-values"><i class="fa fa-check"></i><b>11.1.7</b> How (not) to interpret <em>p</em>-values</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="ch-03-05-hypothesis-testing-CLT.html"><a href="ch-03-05-hypothesis-testing-CLT.html"><i class="fa fa-check"></i><b>11.2</b> Central Limit Theorem</a><ul>
<li class="chapter" data-level="11.2.1" data-path="ch-03-05-hypothesis-testing-CLT.html"><a href="ch-03-05-hypothesis-testing-CLT.html#hands-on"><i class="fa fa-check"></i><b>11.2.1</b> Hands-on</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html"><i class="fa fa-check"></i><b>11.3</b> Selected tests</a><ul>
<li class="chapter" data-level="11.3.1" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-Pearsons-Chi"><i class="fa fa-check"></i><b>11.3.1</b> Pearson’s <span class="math inline">\(\chi^2\)</span>-tests</a></li>
<li class="chapter" data-level="11.3.2" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-z-test"><i class="fa fa-check"></i><b>11.3.2</b> <em>z</em>-test</a></li>
<li class="chapter" data-level="11.3.3" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-t-test"><i class="fa fa-check"></i><b>11.3.3</b> <em>t</em>-tests</a></li>
<li class="chapter" data-level="11.3.4" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-ANOVA"><i class="fa fa-check"></i><b>11.3.4</b> ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="ch-03-05-hypothesis-testing-3-approaches.html"><a href="ch-03-05-hypothesis-testing-3-approaches.html"><i class="fa fa-check"></i><b>11.4</b> Three approaches</a><ul>
<li class="chapter" data-level="11.4.1" data-path="ch-03-05-hypothesis-testing-3-approaches.html"><a href="ch-03-05-hypothesis-testing-3-approaches.html#fisher"><i class="fa fa-check"></i><b>11.4.1</b> Fisher</a></li>
<li class="chapter" data-level="11.4.2" data-path="ch-03-05-hypothesis-testing-3-approaches.html"><a href="ch-03-05-hypothesis-testing-3-approaches.html#neyman-pearson"><i class="fa fa-check"></i><b>11.4.2</b> Neyman-Pearson</a></li>
<li class="chapter" data-level="11.4.3" data-path="ch-03-05-hypothesis-testing-3-approaches.html"><a href="ch-03-05-hypothesis-testing-3-approaches.html#hybrid-modern-nhst"><i class="fa fa-check"></i><b>11.4.3</b> Hybrid modern NHST</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="ch-03-05-hypothesis-testing-3-model-checking.html"><a href="ch-03-05-hypothesis-testing-3-model-checking.html"><i class="fa fa-check"></i><b>11.5</b> Relation to model checking</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="Chap-03-06-model-comparison.html"><a href="Chap-03-06-model-comparison.html"><i class="fa fa-check"></i><b>12</b> Model Comparison</a><ul>
<li class="chapter" data-level="12.1" data-path="Chap-03-06-model-comparison-case-study.html"><a href="Chap-03-06-model-comparison-case-study.html"><i class="fa fa-check"></i><b>12.1</b> Case study: recall models</a></li>
<li class="chapter" data-level="12.2" data-path="Chap-03-06-model-comparison-AIC.html"><a href="Chap-03-06-model-comparison-AIC.html"><i class="fa fa-check"></i><b>12.2</b> Akaike Information Criterion</a></li>
<li class="chapter" data-level="12.3" data-path="Chap-03-06-model-comparison-LR-test.html"><a href="Chap-03-06-model-comparison-LR-test.html"><i class="fa fa-check"></i><b>12.3</b> Likelihood-Ratio Test</a></li>
<li class="chapter" data-level="12.4" data-path="Chap-03-06-model-comparison-BF.html"><a href="Chap-03-06-model-comparison-BF.html"><i class="fa fa-check"></i><b>12.4</b> Bayes factors</a><ul>
<li class="chapter" data-level="12.4.1" data-path="Chap-03-06-model-comparison-BF.html"><a href="Chap-03-06-model-comparison-BF.html#grid-approximation"><i class="fa fa-check"></i><b>12.4.1</b> Grid approximation</a></li>
<li class="chapter" data-level="12.4.2" data-path="Chap-03-06-model-comparison-BF.html"><a href="Chap-03-06-model-comparison-BF.html#naive-monte-carlo"><i class="fa fa-check"></i><b>12.4.2</b> Naive Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="outlook.html"><a href="outlook.html"><i class="fa fa-check"></i><b>12.5</b> Outlook</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="ch-03-07-hypothesis-testing-Bayes.html"><a href="ch-03-07-hypothesis-testing-Bayes.html"><i class="fa fa-check"></i><b>13</b> Bayesian hypothesis testing</a><ul>
<li class="chapter" data-level="13.1" data-path="data-and-models-for-this-chapter.html"><a href="data-and-models-for-this-chapter.html"><i class="fa fa-check"></i><b>13.1</b> Data and models for this chapter</a><ul>
<li class="chapter" data-level="13.1.1" data-path="data-and-models-for-this-chapter.html"><a href="data-and-models-for-this-chapter.html#section"><i class="fa fa-check"></i><b>13.1.1</b> 24/7</a></li>
<li class="chapter" data-level="13.1.2" data-path="data-and-models-for-this-chapter.html"><a href="data-and-models-for-this-chapter.html#eco-sensitivity-fictitious"><i class="fa fa-check"></i><b>13.1.2</b> Eco-sensitivity (fictitious)</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="testing-as-posterior-estimation.html"><a href="testing-as-posterior-estimation.html"><i class="fa fa-check"></i><b>13.2</b> Testing as posterior estimation</a><ul>
<li class="chapter" data-level="13.2.1" data-path="testing-as-posterior-estimation.html"><a href="testing-as-posterior-estimation.html#example-247"><i class="fa fa-check"></i><b>13.2.1</b> Example: 24/7</a></li>
<li class="chapter" data-level="13.2.2" data-path="testing-as-posterior-estimation.html"><a href="testing-as-posterior-estimation.html#example-eco-sensitivity"><i class="fa fa-check"></i><b>13.2.2</b> Example: Eco-sensitivity</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="the-savage-dickey-method.html"><a href="the-savage-dickey-method.html"><i class="fa fa-check"></i><b>13.3</b> The Savage-Dickey method</a><ul>
<li class="chapter" data-level="13.3.1" data-path="the-savage-dickey-method.html"><a href="the-savage-dickey-method.html#nested-bayesian-models"><i class="fa fa-check"></i><b>13.3.1</b> Nested (Bayesian) models</a></li>
<li class="chapter" data-level="13.3.2" data-path="the-savage-dickey-method.html"><a href="the-savage-dickey-method.html#savage-dickey-theorem"><i class="fa fa-check"></i><b>13.3.2</b> Savage-Dickey theorem</a></li>
<li class="chapter" data-level="13.3.3" data-path="the-savage-dickey-method.html"><a href="the-savage-dickey-method.html#example-247-1"><i class="fa fa-check"></i><b>13.3.3</b> Example: 24/7</a></li>
<li class="chapter" data-level="13.3.4" data-path="the-savage-dickey-method.html"><a href="the-savage-dickey-method.html#example-eco-sensitivity-1"><i class="fa fa-check"></i><b>13.3.4</b> Example: Eco-sensitivity</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="bayes-factors-for-rope-d-hypotheses-through-encompassing-models.html"><a href="bayes-factors-for-rope-d-hypotheses-through-encompassing-models.html"><i class="fa fa-check"></i><b>13.4</b> Bayes factors for ROPE-d hypotheses through encompassing models</a><ul>
<li class="chapter" data-level="13.4.1" data-path="bayes-factors-for-rope-d-hypotheses-through-encompassing-models.html"><a href="bayes-factors-for-rope-d-hypotheses-through-encompassing-models.html#example-247-2"><i class="fa fa-check"></i><b>13.4.1</b> Example: 24/7</a></li>
<li class="chapter" data-level="13.4.2" data-path="bayes-factors-for-rope-d-hypotheses-through-encompassing-models.html"><a href="bayes-factors-for-rope-d-hypotheses-through-encompassing-models.html#example-eco-sensitivity-2"><i class="fa fa-check"></i><b>13.4.2</b> Example: Eco-sensitivity</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Applied (generalized) linear modeling</b></span></li>
<li class="chapter" data-level="14" data-path="Chap-04-01-simple-linear-regression.html"><a href="Chap-04-01-simple-linear-regression.html"><i class="fa fa-check"></i><b>14</b> Simple linear regression</a><ul>
<li class="chapter" data-level="14.1" data-path="data-set-murder-data.html"><a href="data-set-murder-data.html"><i class="fa fa-check"></i><b>14.1</b> Data set: murder data</a></li>
<li class="chapter" data-level="14.2" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html"><i class="fa fa-check"></i><b>14.2</b> Ordinary least squares regression</a><ul>
<li class="chapter" data-level="14.2.1" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html#prediction-without-any-further-information"><i class="fa fa-check"></i><b>14.2.1</b> Prediction without any further information</a></li>
<li class="chapter" data-level="14.2.2" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html#prediction-with-knowledge-of-unemployment-rate"><i class="fa fa-check"></i><b>14.2.2</b> Prediction with knowledge of unemployment rate</a></li>
<li class="chapter" data-level="14.2.3" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html#simple-linear-regression-general-problem-formulation"><i class="fa fa-check"></i><b>14.2.3</b> Simple linear regression: general problem formulation</a></li>
<li class="chapter" data-level="14.2.4" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html#finding-the-ols-solution"><i class="fa fa-check"></i><b>14.2.4</b> Finding the OLS-solution</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="a-maximum-likelihood-approach.html"><a href="a-maximum-likelihood-approach.html"><i class="fa fa-check"></i><b>14.3</b> A maximum-likelihood approach</a><ul>
<li class="chapter" data-level="14.3.1" data-path="a-maximum-likelihood-approach.html"><a href="a-maximum-likelihood-approach.html#a-likelihood-based-model"><i class="fa fa-check"></i><b>14.3.1</b> A likelihood-based model</a></li>
<li class="chapter" data-level="14.3.2" data-path="a-maximum-likelihood-approach.html"><a href="a-maximum-likelihood-approach.html#finding-the-mle-solution-with-optim"><i class="fa fa-check"></i><b>14.3.2</b> Finding the MLE-solution with <code>optim</code></a></li>
<li class="chapter" data-level="14.3.3" data-path="a-maximum-likelihood-approach.html"><a href="a-maximum-likelihood-approach.html#finding-the-mle-solution-with-math"><i class="fa fa-check"></i><b>14.3.3</b> Finding the MLE-solution with math</a></li>
<li class="chapter" data-level="14.3.4" data-path="a-maximum-likelihood-approach.html"><a href="a-maximum-likelihood-approach.html#finding-the-mle-solution-with-glm"><i class="fa fa-check"></i><b>14.3.4</b> Finding the MLE-solution with <code>glm</code></a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="a-bayesian-approach.html"><a href="a-bayesian-approach.html"><i class="fa fa-check"></i><b>14.4</b> A Bayesian approach</a><ul>
<li class="chapter" data-level="14.4.1" data-path="a-bayesian-approach.html"><a href="a-bayesian-approach.html#implementation-in-stan"><i class="fa fa-check"></i><b>14.4.1</b> Implementation in <code>Stan</code></a></li>
<li class="chapter" data-level="14.4.2" data-path="a-bayesian-approach.html"><a href="a-bayesian-approach.html#using-the-brms-package"><i class="fa fa-check"></i><b>14.4.2</b> Using the <code>brms</code> package</a></li>
<li class="chapter" data-level="14.4.3" data-path="a-bayesian-approach.html"><a href="a-bayesian-approach.html#bayesian-regression-with-non-informative-standard-priors"><i class="fa fa-check"></i><b>14.4.3</b> Bayesian regression with non-informative standard priors</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="testing-coefficients.html"><a href="testing-coefficients.html"><i class="fa fa-check"></i><b>14.5</b> Testing coefficients</a><ul>
<li class="chapter" data-level="14.5.1" data-path="testing-coefficients.html"><a href="testing-coefficients.html#bayesian-approach"><i class="fa fa-check"></i><b>14.5.1</b> Bayesian approach</a></li>
<li class="chapter" data-level="14.5.2" data-path="testing-coefficients.html"><a href="testing-coefficients.html#frequentist-approach"><i class="fa fa-check"></i><b>14.5.2</b> Frequentist approach</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="Chap-04-02-beyond-simple-regression.html"><a href="Chap-04-02-beyond-simple-regression.html"><i class="fa fa-check"></i><b>15</b> Beyond simple linear regression</a><ul>
<li class="chapter" data-level="15.1" data-path="two-categorical-predictors.html"><a href="two-categorical-predictors.html"><i class="fa fa-check"></i><b>15.1</b> Two categorical predictors</a></li>
<li class="chapter" data-level="15.2" data-path="more-than-two-categorical-predictors.html"><a href="more-than-two-categorical-predictors.html"><i class="fa fa-check"></i><b>15.2</b> More than two categorical predictors</a></li>
<li class="chapter" data-level="15.3" data-path="interaction-terms-in-factorial-designs.html"><a href="interaction-terms-in-factorial-designs.html"><i class="fa fa-check"></i><b>15.3</b> Interaction terms in factorial designs</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="app-90-further-material.html"><a href="app-90-further-material.html"><i class="fa fa-check"></i><b>A</b> Further useful material</a><ul>
<li class="chapter" data-level="A.1" data-path="material-on-introduction-to-probability.html"><a href="material-on-introduction-to-probability.html"><i class="fa fa-check"></i><b>A.1</b> Material on <em>Introduction to Probability</em>:</a></li>
<li class="chapter" data-level="A.2" data-path="material-on-bayesian-data-analysis.html"><a href="material-on-bayesian-data-analysis.html"><i class="fa fa-check"></i><b>A.2</b> Material on <em>Bayesian Data Analysis</em>:</a></li>
<li class="chapter" data-level="A.3" data-path="material-on-frequentist-statistics.html"><a href="material-on-frequentist-statistics.html"><i class="fa fa-check"></i><b>A.3</b> Material on <em>frequentist statistics</em>:</a></li>
<li class="chapter" data-level="A.4" data-path="material-on-r-tidyverse-etc-.html"><a href="material-on-r-tidyverse-etc-.html"><i class="fa fa-check"></i><b>A.4</b> Material on <em>R, tidyverse, etc.</em>:</a></li>
<li class="chapter" data-level="A.5" data-path="further-information-for-rstudio.html"><a href="further-information-for-rstudio.html"><i class="fa fa-check"></i><b>A.5</b> Further information for RStudio</a></li>
<li class="chapter" data-level="A.6" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html"><i class="fa fa-check"></i><b>A.6</b> Further information on WebPPL</a><ul>
<li class="chapter" data-level="A.6.1" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html#primitives-and-sampling-functions"><i class="fa fa-check"></i><b>A.6.1</b> Primitives and sampling functions</a></li>
<li class="chapter" data-level="A.6.2" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html#inference-with-infer"><i class="fa fa-check"></i><b>A.6.2</b> Inference with <code>Infer()</code></a></li>
<li class="chapter" data-level="A.6.3" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html#visualization"><i class="fa fa-check"></i><b>A.6.3</b> Visualization</a></li>
<li class="chapter" data-level="A.6.4" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html#installation"><i class="fa fa-check"></i><b>A.6.4</b> Installation</a></li>
<li class="chapter" data-level="A.6.5" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html#usage"><i class="fa fa-check"></i><b>A.6.5</b> Usage</a></li>
<li class="chapter" data-level="A.6.6" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html#keyboard-shortcuts-for-in-browser-use"><i class="fa fa-check"></i><b>A.6.6</b> Keyboard shortcuts (for in-browser use)</a></li>
<li class="chapter" data-level="A.6.7" data-path="further-information-on-webppl.html"><a href="further-information-on-webppl.html#further-resources"><i class="fa fa-check"></i><b>A.6.7</b> Further resources</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="app-91-distributions.html"><a href="app-91-distributions.html"><i class="fa fa-check"></i><b>B</b> Common probability distributions</a><ul>
<li class="chapter" data-level="B.1" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html"><i class="fa fa-check"></i><b>B.1</b> Selected continuous distributions of random variables</a><ul>
<li class="chapter" data-level="B.1.1" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-normal"><i class="fa fa-check"></i><b>B.1.1</b> Normal distribution</a></li>
<li class="chapter" data-level="B.1.2" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-chi2"><i class="fa fa-check"></i><b>B.1.2</b> Chi-squared distribution</a></li>
<li class="chapter" data-level="B.1.3" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#f-distribution"><i class="fa fa-check"></i><b>B.1.3</b> F-distribution</a></li>
<li class="chapter" data-level="B.1.4" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-students-t"><i class="fa fa-check"></i><b>B.1.4</b> Student’s <em>t</em>-distribution</a></li>
<li class="chapter" data-level="B.1.5" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-beta"><i class="fa fa-check"></i><b>B.1.5</b> Beta distribution</a></li>
<li class="chapter" data-level="B.1.6" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#uniform-distribution"><i class="fa fa-check"></i><b>B.1.6</b> Uniform distribution</a></li>
<li class="chapter" data-level="B.1.7" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-dirichlet"><i class="fa fa-check"></i><b>B.1.7</b> Dirichlet distribution</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html"><i class="fa fa-check"></i><b>B.2</b> Selected discrete distributions of random variables</a><ul>
<li class="chapter" data-level="B.2.1" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-binomial"><i class="fa fa-check"></i><b>B.2.1</b> Binomial distribution</a></li>
<li class="chapter" data-level="B.2.2" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-multinomial"><i class="fa fa-check"></i><b>B.2.2</b> Multinomial distribution</a></li>
<li class="chapter" data-level="B.2.3" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-bernoulli"><i class="fa fa-check"></i><b>B.2.3</b> Bernoulli distribution</a></li>
<li class="chapter" data-level="B.2.4" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-categorical"><i class="fa fa-check"></i><b>B.2.4</b> Categorical distribution</a></li>
<li class="chapter" data-level="B.2.5" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-beta-binomial"><i class="fa fa-check"></i><b>B.2.5</b> Beta-Binomial distribution</a></li>
<li class="chapter" data-level="B.2.6" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#poisson-distribution"><i class="fa fa-check"></i><b>B.2.6</b> Poisson distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="app-92-exponential-family.html"><a href="app-92-exponential-family.html"><i class="fa fa-check"></i><b>C</b> Exponential Family and Maximum Entropy</a><ul>
<li class="chapter" data-level="C.1" data-path="an-important-family-the-exponential-family.html"><a href="an-important-family-the-exponential-family.html"><i class="fa fa-check"></i><b>C.1</b> An important family: The Exponential Family</a></li>
<li class="chapter" data-level="C.2" data-path="excursus-information-entropy-and-maximum-entropy-principle.html"><a href="excursus-information-entropy-and-maximum-entropy-principle.html"><i class="fa fa-check"></i><b>C.2</b> Excursus: “Information Entropy” and “Maximum Entropy Principle”</a><ul>
<li class="chapter" data-level="C.2.1" data-path="excursus-information-entropy-and-maximum-entropy-principle.html"><a href="excursus-information-entropy-and-maximum-entropy-principle.html#information-entropy"><i class="fa fa-check"></i><b>C.2.1</b> Information Entropy</a></li>
<li class="chapter" data-level="C.2.2" data-path="excursus-information-entropy-and-maximum-entropy-principle.html"><a href="excursus-information-entropy-and-maximum-entropy-principle.html#deriving-probability-distributions-using-the-maximum-entropy-principle"><i class="fa fa-check"></i><b>C.2.2</b> Deriving Probability Distributions using the Maximum Entropy Principle</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="D" data-path="app-93-data-sets.html"><a href="app-93-data-sets.html"><i class="fa fa-check"></i><b>D</b> Data sets used in the book</a><ul>
<li class="chapter" data-level="D.1" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html"><i class="fa fa-check"></i><b>D.1</b> Mental Chronometry</a><ul>
<li class="chapter" data-level="D.1.1" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#nature-origin-and-rationale-of-the-data"><i class="fa fa-check"></i><b>D.1.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.1.2" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#loading-and-preprocessing-the-data"><i class="fa fa-check"></i><b>D.1.2</b> Loading and preprocessing the data</a></li>
<li class="chapter" data-level="D.1.3" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#cleaning-the-data-1"><i class="fa fa-check"></i><b>D.1.3</b> Cleaning the data</a></li>
<li class="chapter" data-level="D.1.4" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#exploration-summary-stats-plots"><i class="fa fa-check"></i><b>D.1.4</b> Exploration: summary stats &amp; plots</a></li>
<li class="chapter" data-level="D.1.5" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#data-analysis"><i class="fa fa-check"></i><b>D.1.5</b> Data analysis</a></li>
</ul></li>
<li class="chapter" data-level="D.2" data-path="simon-task.html"><a href="simon-task.html"><i class="fa fa-check"></i><b>D.2</b> Simon Task</a><ul>
<li class="chapter" data-level="D.2.1" data-path="simon-task.html"><a href="simon-task.html#experiment"><i class="fa fa-check"></i><b>D.2.1</b> Experiment</a></li>
<li class="chapter" data-level="D.2.2" data-path="simon-task.html"><a href="simon-task.html#results"><i class="fa fa-check"></i><b>D.2.2</b> Results</a></li>
<li class="chapter" data-level="D.2.3" data-path="simon-task.html"><a href="simon-task.html#analysis"><i class="fa fa-check"></i><b>D.2.3</b> Analysis</a></li>
</ul></li>
<li class="chapter" data-level="D.3" data-path="world-values-survey-wave-6-2010-2014.html"><a href="world-values-survey-wave-6-2010-2014.html"><i class="fa fa-check"></i><b>D.3</b> World Values Survey (wave 6 | 2010-2014)</a><ul>
<li class="chapter" data-level="D.3.1" data-path="world-values-survey-wave-6-2010-2014.html"><a href="world-values-survey-wave-6-2010-2014.html#nature-origin-and-rationale-of-the-data-1"><i class="fa fa-check"></i><b>D.3.1</b> Nature, origin and rationale of the data</a></li>
</ul></li>
<li class="chapter" data-level="D.4" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html"><i class="fa fa-check"></i><b>D.4</b> King of France</a><ul>
<li class="chapter" data-level="D.4.1" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#app-93-data-sets-king-of-france-background"><i class="fa fa-check"></i><b>D.4.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.4.2" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#loading-and-preprocessing-the-data-1"><i class="fa fa-check"></i><b>D.4.2</b> Loading and preprocessing the data</a></li>
<li class="chapter" data-level="D.4.3" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#cleaning-the-data-2"><i class="fa fa-check"></i><b>D.4.3</b> Cleaning the data</a></li>
<li class="chapter" data-level="D.4.4" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#exploration-summary-stats-plots-1"><i class="fa fa-check"></i><b>D.4.4</b> Exploration: summary stats &amp; plots</a></li>
<li class="chapter" data-level="D.4.5" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#data-analysis-1"><i class="fa fa-check"></i><b>D.4.5</b> Data analysis</a></li>
</ul></li>
<li class="chapter" data-level="D.5" data-path="app-93-data-sets-BLJM.html"><a href="app-93-data-sets-BLJM.html"><i class="fa fa-check"></i><b>D.5</b> Bio-Logic Jazz-Metal (and where to consume it)</a><ul>
<li class="chapter" data-level="D.5.1" data-path="app-93-data-sets-BLJM.html"><a href="app-93-data-sets-BLJM.html#nature-origin-and-rationale-of-the-data-2"><i class="fa fa-check"></i><b>D.5.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.5.2" data-path="app-93-data-sets-BLJM.html"><a href="app-93-data-sets-BLJM.html#loading-and-preprocessing-the-data-2"><i class="fa fa-check"></i><b>D.5.2</b> Loading and preprocessing the data</a></li>
<li class="chapter" data-level="D.5.3" data-path="app-93-data-sets-BLJM.html"><a href="app-93-data-sets-BLJM.html#exploration-counts-plots"><i class="fa fa-check"></i><b>D.5.3</b> Exploration: counts &amp; plots</a></li>
</ul></li>
<li class="chapter" data-level="D.6" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html"><i class="fa fa-check"></i><b>D.6</b> Avocado prices</a><ul>
<li class="chapter" data-level="D.6.1" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html#nature-origin-and-rationale-of-the-data-3"><i class="fa fa-check"></i><b>D.6.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.6.2" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html#loading-and-preprocessing-the-data-3"><i class="fa fa-check"></i><b>D.6.2</b> Loading and preprocessing the data</a></li>
<li class="chapter" data-level="D.6.3" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html#summary-statistics"><i class="fa fa-check"></i><b>D.6.3</b> Summary statistics</a></li>
<li class="chapter" data-level="D.6.4" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html#plots"><i class="fa fa-check"></i><b>D.6.4</b> Plots</a></li>
</ul></li>
<li class="chapter" data-level="D.7" data-path="app-93-data-sets-temperature.html"><a href="app-93-data-sets-temperature.html"><i class="fa fa-check"></i><b>D.7</b> Annual average world surface temperature</a><ul>
<li class="chapter" data-level="D.7.1" data-path="app-93-data-sets-temperature.html"><a href="app-93-data-sets-temperature.html#nature-origin-and-rationale-of-the-data-4"><i class="fa fa-check"></i><b>D.7.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.7.2" data-path="app-93-data-sets-temperature.html"><a href="app-93-data-sets-temperature.html#loading-and-preprocessing-the-data-4"><i class="fa fa-check"></i><b>D.7.2</b> Loading and preprocessing the data</a></li>
<li class="chapter" data-level="D.7.3" data-path="app-93-data-sets-temperature.html"><a href="app-93-data-sets-temperature.html#hypothesis-modeling-approach"><i class="fa fa-check"></i><b>D.7.3</b> Hypothesis &amp; modeling approach</a></li>
<li class="chapter" data-level="D.7.4" data-path="app-93-data-sets-temperature.html"><a href="app-93-data-sets-temperature.html#plotting"><i class="fa fa-check"></i><b>D.7.4</b> Plotting</a></li>
<li class="chapter" data-level="D.7.5" data-path="app-93-data-sets-temperature.html"><a href="app-93-data-sets-temperature.html#analysis-1"><i class="fa fa-check"></i><b>D.7.5</b> Analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="Chap-03-03-models-examples" class="section level2">
<h2><span class="header-section-number">1.4</span> Strolling the zoo of models</h2>
<p>Let’s have a look at some more models. Some of the characters we will encounter here will play leading roles in the plot to come. Some are for familiarization and exercise. All are pleasant.</p>
<div id="Chap-03-03-models-examples-binomial" class="section level3">
<h3><span class="header-section-number">1.4.1</span> The Binomial Model</h3>
<p>We just repeat the Binomial Model discussed above for completeness in Figure <a href="Chap-03-03-models-examples.html#fig:ch-03-02-Binomial-Model-repeated">1.2</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:ch-03-02-Binomial-Model-repeated"></span>
<img src="visuals/binomial-model.png" alt="The Binomial Model (repeated from before)." width="40%" />
<p class="caption">
Figure 1.2: The Binomial Model (repeated from before).
</p>
</div>
</div>
<div id="flip-and-draw-model" class="section level3">
<h3><span class="header-section-number">1.4.2</span> Flip-and-Draw Model</h3>
<p>The Flip-and-Draw Model is a model for the flip-and-draw scenario introduced in Section <a href="Chap-03-01-probability-marginal.html#Chap-03-01-probability-marginal">8.2</a>. Remember that we first flip a coin and then draw from one of two urns, depending on the outcome of the coin flip. Let’s generalize this and assume that the coin has a possibly unknown bias <span class="math inline">\(\theta\)</span>. The probability of sampling a black or white ball from the first urn is given by a probability vector <span class="math inline">\(\vec{p_0} = \langle 0.2, 0.8 \rangle\)</span> (where the first entry gives the probability of sampling a black ball). The other urn has a corresponding probability vector <span class="math inline">\(\vec{p_1} = \langle 0.4, 0.6 \rangle\)</span>. The <a href="https://en.wikipedia.org/wiki/Categorical_distribution">categorical distribution</a> gives the probability of sampling an index from a given probability vector <span class="math inline">\(\vec{p}\)</span>. It is defined as:</p>
<p><span class="math display">\[ \text{Categorical}(i) = \vec{p}_i \]</span></p>
<p>Figure <a href="Chap-03-03-models-examples.html#fig:ch-03-02-FlipDraw-Model">1.3</a> gives a concise representation of the model.</p>
<div class="figure" style="text-align: center"><span id="fig:ch-03-02-FlipDraw-Model"></span>
<img src="visuals/flip-and-draw-model.png" alt="The Flip-and-Draw Model." width="30%" />
<p class="caption">
Figure 1.3: The Flip-and-Draw Model.
</p>
</div>
</div>
<div id="flip-and-draw-hypergeometric-model" class="section level3">
<h3><span class="header-section-number">1.4.3</span> Flip-and-Draw-Hypergeometric Model</h3>
<p>The Flip-and-Draw-Hypergeometric Model is exactly like the previous Flip-and-Draw Model, except that we allow ourselves to sample repeatedly <em>without replacement</em> from an urn the coin flip selected for us. The probability of observing <span class="math inline">\(k\)</span> black balls when drawing <span class="math inline">\(n\)</span> balls from an urn that contains <span class="math inline">\(N\)</span> balls in total, out of which <span class="math inline">\(K\)</span> balls are black, and we do not put each drawn ball back into the urn is described as the so-called <a href="https://en.wikipedia.org/wiki/Hypergeometric_distribution">hypergeometric distribution</a>. The hypergeometric distribution assigns to each <span class="math inline">\(k \in \{\max(0, n+K-N), \dots, \min(n,K)\}\)</span> the probability mass:</p>
<p><span class="math display">\[ \text{Hypergeometric}(k \mid n, K, N) = \frac{\binom{K}{k} \binom{N-K}{n-k}}{\binom{N}{n}}  \]</span></p>
<p>Suppose we keep the total number of urns fixed to <span class="math inline">\(N = 100\)</span> and always draw <span class="math inline">\(n = 20\)</span> balls. The two urns we have (indexed 0 and 1) hold <span class="math inline">\(K_0 = 20\)</span> and <span class="math inline">\(K_1 = 80\)</span> black balls. For a Bayesian model we could use a <span class="math inline">\(\text{Beta}\)</span> prior for <span class="math inline">\(\theta\)</span>. Figure <a href="Chap-03-03-models-examples.html#fig:ch-03-02-FlipDraw-Hypergeometric">1.4</a> shows the model.</p>
<div class="figure" style="text-align: center"><span id="fig:ch-03-02-FlipDraw-Hypergeometric"></span>
<img src="visuals/flip-and-draw-hypergeometric.png" alt="The Flip-and-Draw-Hypergeometric Model." width="60%" />
<p class="caption">
Figure 1.4: The Flip-and-Draw-Hypergeometric Model.
</p>
</div>
<p>Below is WebPPL code that allows you to test the models’ predictions about data. You can manipulate the parameter values for <span class="math inline">\(\theta\)</span> and <span class="math inline">\(K_1\)</span> and <span class="math inline">\(K_2\)</span>. The latter are represented in the array/vector <code>K = [K1, K2]</code> below.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<pre class="webppl">
var theta = 0.2; var K = [20,80];
///fold:
var N = 100;
var n = 20;

var factorial = function(x) {
  if (x < 0) {return "input to factorial function must be non-negative"}
  return x == 0 ? 1 : x * factorial(x-1)
}

var binom = function(a, b) {
  var numerator = factorial(a)
  var denominator = factorial(a-b) *  factorial(b)
  return numerator / denominator
}

// urn contains N balls of which K are black
// and N-K are white; we draw n balls at random
// without replacement; what's the probability
// of obtaining k black balls?
var hypergeometricPMF = function(k,N,K,n) {
  k > Math.min(n, K) ? 0 :
  k < n+K-N ? 0 :
  binom(K,k) * binom(N-K, n-k) / binom(N,n)
}

var hypergeometricSample = function(N,K,n) {
  var support = _.range(N+1) // possible values 0, ..., N
  var PMF = map(function(k) {hypergeometricPMF(k,N,K,n)}, support)
  categorical({vs: support, ps: PMF })
}
viz(Infer({model: function() {var K_urn = K[flip(theta) ? 1 : 0];
                              hypergeometricSample(N, K_urn, n)},
           method: "forward",
           samples: 1500}))
///
</pre>
<pre class=" CodeMirror-line " role="presentation">
</pre>
<script>
// find all <pre> elements and set up the editor on them
var preEls = Array.prototype.slice.call(document.getElementsByClassName("webppl"));
preEls.map(function(el) { console.log(el); editor.setup(el, {language: 'webppl'}); });
</script>
<!-- <!-- Ex.Maybe for HW? -->
<!-- You want to approximate how many people visited your webpage for the first time today.  You know that overall 50 people were there. And you see 7 comments, five of which are left by your old followers. Print the most likely number of new visitors.  -->
<!-- ```{r} -->
<!-- ll_new_visitors <- tibble( -->
<!--     m = 2:45, -->
<!--     LH = dhyper(2, m, 50,7) -->
<!-- ) %>%  -->
<!-- which(ll_new_visitors==max(ll_new_visitors["LH"])) -->
<!-- ``` -->
<!-- -->
</div>
<div id="t-test-model-comparing-two-groups" class="section level3">
<h3><span class="header-section-number">1.4.4</span> T-Test Model: comparing two groups</h3>
<p>Consider the example introduced in Section <a href="Chap-03-03-models-general.html#Chap-03-03-models-general">9.1</a> again, where we set out to compare the means of average prices of different types of avocados. We assume that there is an indicator variable <span class="math inline">\(g_i\)</span> (corresponding to <code>type</code>), such that, for example, <span class="math inline">\(g_i = 0\)</span> is for observations from organic avocados and <span class="math inline">\(g_i = 1\)</span> is for observations from conventionally grown avocados. A first instance from the T-Test Model family for the comparison of two groups assumes that the first group has a mean <span class="math inline">\(\mu_0\)</span> and the second has <span class="math inline">\(\mu_1\)</span>, while both share the same standard deviation <span class="math inline">\(\sigma\)</span>. Using the notation developed in Section <a href="Chap-03-03-models-representation.html#Chap-03-03-models-representation">9.2</a>, we can write the likelihood function succinctly like so:</p>
<p><span class="math display">\[ y_i \sim \text{Normal}(\mu_{g_i}, \sigma) \]</span></p>
<p>In a Bayesian approach, the priors over parameter values could use a normal distribution for <span class="math inline">\(\mu_i\)</span> and a truncated normal distribution for <span class="math inline">\(\sigma\)</span> (since <span class="math inline">\(\sigma\)</span> must be positive). Figure <a href="Chap-03-03-models-examples.html#fig:ch-03-02-Simple-Linear-Regression">1.7</a> shows the resulting model.</p>
<div class="figure" style="text-align: center"><span id="fig:ch-03-02-T-Test-Model"></span>
<img src="visuals/t-test-model.png" alt="A T-Test Model where each group has its own mean." width="70%" />
<p class="caption">
Figure 1.5: A T-Test Model where each group has its own mean.
</p>
</div>
<p>A point of general importance can be made in connection with this example. It is possible to build different prior structures around the same likelihood function. Some parameterizations can be more useful for a given purpose than others. Some parameterizations make it easier to formalize prior domain knowledge than others. To see this, consider the case at hand where we might be specifically interested in the question of how big the difference between the means is. We can therefore also level the model shown in Figure <a href="Chap-03-03-models-examples.html#fig:ch-03-02-T-Test-Model-Difference">1.6</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:ch-03-02-T-Test-Model-Difference"></span>
<img src="visuals/t-test-model-difference.png" alt="A T-Test Model where one group is the default and the difference between group means is explicitly coded as a parameter." width="70%" />
<p class="caption">
Figure 1.6: A T-Test Model where one group is the default and the difference between group means is explicitly coded as a parameter.
</p>
</div>
<p>The variant of the T-Test Model, formulated in terms of differences between groups, in Figure <a href="Chap-03-03-models-examples.html#fig:ch-03-02-T-Test-Model-Difference">1.6</a> is what is usually used in common practice. The advantage is, for example, that it is easy to address the question whether the means are identical, a case which is represented by a single parameter value <span class="math inline">\(\delta = 0\)</span> (rather than an infinite set of pairs <span class="math inline">\(\mu_0 = \mu_1\)</span>). It is also easier to specify beliefs about the differences between groups. The prior on <span class="math inline">\(\delta\)</span> in Figure <a href="Chap-03-03-models-examples.html#fig:ch-03-02-T-Test-Model-Difference">1.6</a> assumes that we expect <em>a priori</em> that <span class="math inline">\(\delta = 0\)</span>, but specifying different standard deviations for this prior allows to formalize different degrees of certainty. We could for example use a <em>skeptical prior</em>, i.e., an initial model configuration that is skeptical about a group difference, if the standard deviation is set very low.</p>
</div>
<div id="simple-linear-regression-model" class="section level3">
<h3><span class="header-section-number">1.4.5</span> Simple Linear Regression Model</h3>
<p>In Section <a href="Chap-02-04-ggplot.html#Chap-02-04-ggplot">7.3</a>, we plotted avocado prices in a scatter plot. In particular, we plotted (the log of) <code>average_price</code> as a function of <code>total_amount_sold</code>, and we also added a regression line, like so:</p>
<p><img src="I2DA_files/figure-html/unnamed-chunk-11-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>A simple linear regression tries to relate pairs of associated observations, frequently denoted as <span class="math inline">\(x_i\)</span> and <span class="math inline">\(y_i\)</span>. Here, <span class="math inline">\(i\)</span> is an index over observations, <span class="math inline">\(x_i\)</span> is the (continuous) independent variable and <span class="math inline">\(y_i\)</span> is the (continuous) dependent variable. In our example, the vector <span class="math inline">\(x\)</span> is the logarithm of <code>total_amount_sold</code> and <span class="math inline">\(y\)</span> is the vector <code>average_price</code>. The simple linear regression model assumes that there is a simple linear relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. A perfect linear relationship would exist if for all <span class="math inline">\(i\)</span>:</p>
<p><span class="math display">\[ y_i = \beta_0 + \beta_1 \ x_i \]</span></p>
<p>Given measurement error and other lingering uncertainties, we rather handle a <strong>linear relation with stochastic noise</strong>, in which the linear relationship holds, but could be distorted by an <span class="math inline">\(\epsilon\)</span> error, which we assume is independently drawn for each <span class="math inline">\(i\)</span> from a normal distribution:</p>
<p><span class="math display">\[ y_i = \beta_0 + \beta_1 \ x_i + \epsilon_1 \ \ \ \ \ \ \text{where} \ \ \ \ \epsilon_i \sim \text{Normal}(\mu=0, \sigma = \dots)\]</span></p>
<p>An alternative formulation is to simply write:</p>
<p><span class="math display">\[ y_i \sim \text{Normal}(\mu=\beta_0 + \beta_1 \ x_i , \sigma = \dots)\]</span></p>
<p>This is the likelihood function that the Simple Linear Regression Model assumes. Figure <a href="Chap-03-03-models-examples.html#fig:ch-03-02-Simple-Linear-Regression">1.7</a> summarizes the full model by also indicating roughly which kinds of prior distributions might be useful in a Bayesian analysis.</p>
<div class="figure" style="text-align: center"><span id="fig:ch-03-02-Simple-Linear-Regression"></span>
<img src="visuals/linear-regression-model.png" alt="The Simple Linear Regression Model." width="60%" />
<p class="caption">
Figure 1.7: The Simple Linear Regression Model.
</p>
</div>
</div>
<div id="Chap-03-03-models-examples-linear-regression" class="section level3">
<h3><span class="header-section-number">1.4.6</span> Linear Regression with Two Groups</h3>
<p>Section <a href="Chap-02-04-ggplot.html#Chap-02-04-ggplot">7.3</a> also plotted avocado prices against the total amount sold and distinguished the type of avocado, also adding a separate regression line for each type. The result looked like this:</p>
<p><img src="I2DA_files/figure-html/unnamed-chunk-12-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Towards a model that computes these linear regression lines, one for each group, that is in line with the idea introduced above that, for the purposes of estimation and testing, we might like to represent differences between groups as <span class="math inline">\(\delta\)</span> parameters in a model, let’s assume that the type of avocado is our grouping variable <span class="math inline">\(g_i\)</span>. The default group (say: conventional avocados) has <span class="math inline">\(g_i = 0\)</span>, the other group has <span class="math inline">\(g_i = 1\)</span>. The first group gets “its own” intercept <span class="math inline">\(\beta_0\)</span> and slope <span class="math inline">\(\beta_1\)</span>. The second group gets additive offsets <span class="math inline">\(\delta_0\)</span> and <span class="math inline">\(\delta_1\)</span> for its slope and intercept, respectively. The full model is shown in Figure <a href="Chap-03-03-models-examples.html#fig:ch-03-02-Linear-Regression-Groups">1.8</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:ch-03-02-Linear-Regression-Groups"></span>
<img src="visuals/linear-regression-with-groups.png" alt="The Linear Regression with Two Groups Model." width="80%" />
<p class="caption">
Figure 1.8: The Linear Regression with Two Groups Model.
</p>
</div>
<div class="exercises">
<p><strong>Exercise 8.6</strong></p>
<p>Which model would you rather use to investigate…</p>
<ol style="list-style-type: lower-alpha">
<li><p>…if there is a difference between chocolate consumption per person in Germany and Belgium?</p></li>
<li><p>…how many people visited your webpage for the first time? You know that overall 50 people were there. And you see 7 comments, five of which are left by your old followers.</p></li>
<li><p>…if running speed increases with every 100m among sprinters, but not within marathoners?</p></li>
<li><p>…the relationship between the time spent on studying and the amount of coffee consumption?</p></li>
<li><p>…if a football referee is biased and gives yellow cards more often to one of the teems? Consider that the fold probability is known for each team.</p></li>
</ol>
<div class="collapsibleSolution">
<button class="trigger">
Solution
</button>
<div class="content">
<ol style="list-style-type: lower-alpha">
<li><p>T-Test Model</p></li>
<li><p>Flip-and-Draw-Hypergeometric Model</p></li>
<li><p>Linear Regression with Two Groups</p></li>
<li><p>Simple Linear Regression Model</p></li>
<li><p>Binomial</p></li>
</ol>
</div>
</div>
</div>
<!-- ### Outlook: Hierarchical models -->
<!-- Often data can be considered as part of an overall structure. Single observations can be modelled belonging into different groups. These groups in turn are part of a superordinate group etc. Such information are presented in a model in form of a hierarchy. -->
<!-- For example, consider again the coin flip experiment. The outcome of *head* is influenced by the probability $\theta$. Further, $\theta$ is assumed to be distributed as Beta(1,1). Remember that the parameter a and b of a Beta-distribution can be considered in this context as: $a=$number of heads and $b=$ number of tails, consequently, $n=a+b$. -->
<!-- #### Reparameterization of a Beta distribution -->
<!-- Probability distributions can be described by their *central tendency* and *spread* (or dispersion). The *mode* of a Beta distribution is defined as: -->
<!-- $\omega=\frac{a-1}{a+b-2}$, -->
<!-- and the concentration as: -->
<!-- $\kappa=a+b.$ -->
<!-- The nice thing is, that the definition of the *mode* as well as of the *concentration* consists solely of the parameters a and b. Therefore, it is possible to re-express the parameters of a Beta density in terms of $\omega$ and $\kappa$, such that: -->
<!-- $$Beta(a,b)=Beta\left(\omega(\kappa -2)+1, (1-\omega)(\kappa -2)+1\right).$$ -->
<!-- *Why this is useful? And what is its value in connection with hierarchical modeling?* -->
<!-- Return back to the coin flip experiment. So far, the parameters of the prior on $\theta$ are fixed: $a=1$ and $b=1$. Assume that we get further information: The manufacturing process of the coins has a bias near $\omega$ (example taken from [@kruschke2015]). But how to incorporate this additional knowledge in the model? -->
<!-- At this point, the hierarchy and the reparameterization come into play. Hierarchy because a further assumption is placed on top of the existing model and reparameterization, because we want to express the prior in terms of the mode $\omega$. -->
<!-- Such that the model can be assumed as follows: -->
<!-- ![Graphical notation hierarchical Beta-Binomial Model - One group](chapters/images/binom-oneLevel.png) -->
<!-- Now, the parameters of the hyperpriors (Gamma and Beta) are fixed, but they can be treated as parameters as well ... as such hierarchical models can be created with any degree of complexity: -->
<!-- ![Graphical notation hierarchical Beta-Binomial Model - One group](chapters/images/hierarchical-model.png) -->
<!-- ### Further examples -->
<!-- #### Difference between two groups -->
<!-- In the introductory example we asked for the underlying probability $\theta$ of a single coin that was flipped repeatedly. -->
<!-- Consider now, that a second coin $y_2$ is introduced. One question that arises might be for example: *How different are the biases of the two coins?* -->
<!-- ```{r} -->
<!-- #simulate flips of two coins -->
<!-- sample.space <- c(0,1) -->
<!-- ##First coin: -->
<!-- theta1 <- 0.5              # probability of a success (here: head) -->
<!-- X1 <- 30                   # number of trials in the experiment -->
<!-- n1 <- 100                  # number of observations -->
<!-- k1 <- 0                    # number of heads [initialization] -->
<!-- for (i in 1: n1) { -->
<!--   k1[i] <- sum(sample(sample.space, size = X1, replace = TRUE, -->
<!--                      prob = c(theta1, 1 - theta1))) -->
<!-- } -->
<!-- ##Second coin: -->
<!-- theta2 <- 0.7              # probability of a success (here: head) -->
<!-- X2 <- 30                   # number of trials in the experiment -->
<!-- n2 <- 100                  # number of observations -->
<!-- k2 <- 0                    # number of heads [initialization] -->
<!-- ## repeat experiment N-times -->
<!-- for (i in 1: n2) { -->
<!--   k2[i] <- sum(sample(sample.space, size = X2, replace = TRUE, -->
<!--                      prob = c(theta2, 1 - theta2))) -->
<!-- } -->
<!-- ## show results in a tibble -->
<!-- coin.flip2 <- tibble("coin" = c(replicate(n1,"coin1"), replicate(n2,"coin2")), -->
<!--                      "n" = c(seq(from=1, to=n1, by=1), seq(from=1, to=n2, by=1)), -->
<!--                      "k" = c(k1,k2), -->
<!--                      "x" = c(replicate(n1,X1), replicate(n2,X2)) -->
<!-- ) %>% -->
<!--   print() -->
<!-- ``` -->
<!-- ```{r} -->
<!-- #Plotting the observed results -->
<!-- ggplot(data=coin.flip2,mapping = aes(x=k, fill=coin ))+ -->
<!--           geom_histogram() -->
<!-- ``` -->
<!-- ## How to create a model -->
<!-- The approach described here is based on [@mcelreath2015; @kruschke2015]. Although the approach is introduced in a Bayesian context, it can be used as a general guideline (with some caveats): -->
<!-- * Identify the relevant variables according to the hypothesis (Measurement scales, predicted vs. predictor variables). -->
<!-- * Define the descriptive model for the relevant variables. -->
<!--   + likelihood distribution (distribution of each outcome variable that defines the plausibility of individual observations) -->
<!--   + parameters (define and name all parameters of the model in order to relate the likelihood to the predictor variable(s)) -->
<!-- * Bayesian context: Specify prior distribution(s). -->
<!-- Further steps that will be subject of later chapters: -->
<!-- * estimation and interpretation of the results. -->
<!-- * Model checking (Is the defined model adequate?) -->
<!-- *In the following we are interested in the question if a certain coin is biased.* -->
<!-- **First step** is to *identify the relevant variables*. For the coin flip experiment a coin is flipped $n$ times, whereby each observation consists of $x$ trials. Imagine for example 10 people flip a coin 30 times, then $n=10$ and $x=30$. The variable *coin flip* $Y$ is dichotomous with the possible outcomes "head" and "tail". For each observation the outcome is recorded: "0" for coming up tail and "1" for coming up head. The data are summarized for each observation. The variable $k$ indicates the number of heads coming up in $x$ trials. -->
<!-- In **the second step** a *descriptive model for the identified variables* has to be defined. An underlying probability $\theta$ is assumed, indicating the probability of heads coming up $p(y=1)$. The probability that the outcome is head, given a value of parameter $\theta$, is the value of $\theta$ [@kruschke2015, p.109]. Formally, this can be written as -->
<!-- $$p(y=1|\theta)=\theta$$ -->
<!-- As only two outcomes of $Y$ exists, the probability that the outcome is tail is the complementary probability $1-\theta$. Both probabilities can be combined in one probability expression: -->
<!-- $$Pr(Y|n,\theta)=\frac{n!}{y!(n-y)!}\theta^{y}(1-\theta)^{n-y}.$$ -->
<!-- This probability distribution is called the **Binomial distribution**. The fracture at the beginning indicates how many ordered sequences of $n$ outcomes a count $y$ have. -->
<!-- ```{r ch-03-03-binomial-distribution-coin-flip-example, echo = FALSE, fig.cap = "Binomial-distribution for different coin biases"} -->
<!-- # how many trials -->
<!-- trials = 30 -->
<!-- rv_binom <- tibble( -->
<!--   x = seq(0, trials), -->
<!--   y1 = dbinom(x, size = trials, p = 0.2), -->
<!--   y2 = dbinom(x, size = trials, p = 0.5), -->
<!--   y3 = dbinom(x, size = trials, p = 0.8) -->
<!-- ) %>% -->
<!--   pivot_longer(cols = starts_with("y"), -->
<!--                names_to  = "parameter", -->
<!--                values_to = "y") %>% -->
<!--   mutate( -->
<!--     parameter = case_when(parameter == "y1" ~ "(n,0.2)", -->
<!--                           parameter == "y2" ~ "(n,0.5)", -->
<!--                           parameter == "y3" ~ "(n,0.8)") -->
<!--   ) -->
<!-- # dist plot -->
<!-- ggplot(rv_binom, aes(x, y, fill = parameter)) + -->
<!--   geom_col(position = "identity", alpha = 0.8) + -->
<!--   labs(fill = "X ~ Binomial", y = "Probability") -->
<!-- ``` -->
<!-- When the coin is flipped only once, then the probability can be written as: -->
<!-- $$Pr(Y|\theta)=\theta^{y}(1-\theta)^{1-y}.$$ -->
<!-- This special variant of the Binomial distribution is the so-called **Bernoulli distribution**. To see the connection to the first considerations: When the outcome "head" is observed the equation reduces to $Pr(y=1|\theta)=\theta$ and when the outcome "tail" is observed the equation results in $Pr(y=0|\theta)=(1-\theta).$ -->
<!-- Accordingly, for the introductory example it can be noted that the coin flip variable $Y$ *is distributed as* Binomial distribution. (Note: For Bayes' rule the *likelihood function* is needed. Remember, the likelihood function treats $\theta$ as unknow and the data as known. This role of parameter is exchanged in a probability distribution.) -->
<!-- ```{r ch-03-03-binomial-likelihood-coin-flip-example, echo = FALSE, fig.cap = "Binomial likelihoods for different observed coin flip outcomes."} -->
<!-- binomial.likelihood <- function(n, k, theta){theta^k*(1-theta)^(n-k)} -->
<!-- tibble( -->
<!--   n = 10, -->
<!--   theta = seq(from=0, to=1, by=0.01), -->
<!--   y_1 = binomial.likelihood(n,2,theta), -->
<!--   y_2 = binomial.likelihood(n,5,theta), -->
<!--   y_3 = binomial.likelihood(n,8,theta) -->
<!-- ) %>% -->
<!-- pivot_longer(cols = starts_with("y"), -->
<!--                names_to  = "parameter", -->
<!--                values_to = "y") %>% -->
<!--   mutate( -->
<!--     parameter = case_when(parameter == "y_1" ~ "(n=10,x=20,p)", -->
<!--                           parameter == "y_2" ~ "(n=10,x=50,p)", -->
<!--                           parameter == "y_3" ~ "(n=10,x=80,p)") -->
<!--   ) %>% -->
<!-- ggplot(aes(theta, y, color = parameter)) + -->
<!--   geom_line(size = 2) + -->
<!--   labs(color = "X ~ Binomial", y = "Likelihood", x = expression(theta)) -->
<!-- ``` -->
<!-- **The third step** is solely a *Bayesian idea*, that is the *incorporation of prior knowledge*. What do we believe about the coin bias $\theta$ before seeing the data? Assuming that no expectation about $\theta$ exists a priori, indicating that all values of $\theta$ between 0 and 1 are equally probable. This can be modeled by a uniform distribution or as already visualized as Beta distribution with parameters a=1 and b=1 (see following figure). -->
<!-- ```{r ch-03-03-prior-distribution-coin-flip-example, echo = FALSE, fig.cap = "Using uninformative prior distributions: The Uniform(0,1) and Beta(1,1) prior."} -->
<!-- tibble( -->
<!--   x = seq(from = -0.01, to = 1.01, by = 0.01), -->
<!--   y_1 = dunif(x, min = 0, max = 1), -->
<!--   y_2 = dbeta(x, shape1 = 1, shape2 = 1), # only for legend -->
<!--   beta = dbeta(x, shape1 = 1, shape2 = 1) -->
<!-- ) %>% -->
<!--   pivot_longer(cols = starts_with("y"), -->
<!--                names_to  = "prior", -->
<!--                values_to = "y") %>% -->
<!--   mutate( -->
<!--     prior = case_when(prior == "y_1" ~ "Uniform(0,1)", -->
<!--                       prior == "y_2" ~ "Beta(1,1)") -->
<!--   ) %>% -->
<!-- ggplot() + -->
<!--   geom_line(aes(x, y, color = prior), size = 2) + -->
<!--   geom_line(aes(x, beta), color = project_colors[2], size = 2, linetype = "dashed") + -->
<!--   labs(y = "Density", x = expression(theta)) + -->
<!--   ylim(0,1.5) -->
<!-- ``` -->
<!-- So far, the coin flip model is defined conceptually. In the following some notational considerations have to be made. -->
<!-- #### Conceptual steps for modeling -->
<!-- We suppose that the underlying probabilities of the two coins correspond to *different* latent variables $\theta_1$ and $\theta_2$. -->
<!-- **First step** is again the *identification of the relevant variables* according to the research question. As already indicated for the "one coin" example we have: -->
<!-- * the observed number of heads $k_1$ and $k_2$ (for each coin, respectively), which is influenced by -->
<!-- * the number of observations $n_1$ and $n_2$ and by -->
<!-- * the underlying probabilities $\theta_1$ and $\theta_2$. -->
<!-- Furthermore, from a conceptional perspective, we are interested in the *difference between the coin biases*. Therefore a further variable will be introduced $\delta$, defined by: -->
<!-- $$\delta =\theta_1 - \theta_2.$$ -->
<!-- The *distributional assumptions*, according to the **second and third step**, can be adopted from the "one coin" example, such that the graphical notation (including the textual notation) can be denoted as follows: -->
<!-- #### Notation Beta-Binomial Model - Two Groups -->
<!-- ![Graphical notation Beta-Binomial Model - Two groups](chapters/images/Graph-Factorial.png) -->
<!-- ### Simple linear regression with one metric predictor -->
<!-- The following example originates from a data set in which speed of cars and the distance taken to stop was recorded. It is a simple data set good for introducing the basic ideas for simple linear regression. -->
<!-- ```{r} -->
<!-- #The "cars" data set -->
<!-- data(cars) -->
<!-- #take a look at the variables included in the data set -->
<!-- str(cars) -->
<!-- ``` -->
<!-- One possible question could be how much the stopping distance increases when the speed of a car increases. -->
<!-- #### Conceptual steps for modeling -->
<!-- First step is to **identify the relevant variables**. In this case these are "speed" measured in mph and "distance" measured in ft, thus, both variables are metric variables. As distance will be predicted from speed. The *predicted variable* is "distance" and the *predictor variable* is "speed". A scatter plot can visualize a possible relationship between both variables. -->
<!-- ```{r} -->
<!-- plot(x=cars$speed,y=cars$dist, type="p", main="scatter plot of cars data set", -->
<!--      ylab="distance in ft", xlab="speed in mph") -->
<!-- ``` -->
<!-- Next step is to define a **descriptive model of the data**. According to the scatter plot it is not too absurd to think that distance might be proportional to speed. Therefore, a linear relationship between both variables can be assumed, where speed is used i order to predict distance. But how can the distribution of the predicted variable "distance" be described? The following plot shows in blue the density of the actual distance values. -->
<!-- ```{r, eval=FALSE} -->
<!-- #density of distance values in blue -->
<!-- #(in black simulation of a normal distribution) -->
<!-- dens(cars$dist, col="blue", norm.comp = TRUE, main="Distribution of distance", -->
<!--      xlab="distance in ft") -->
<!-- ``` -->
<!-- Although the distribution of "distance" values is not identical to the corresponding normal distribution, it can be assumed that the values follow a *normal distribution*. The underlying consideration is that the distance values $y_i$ are distributed randomly according to a normal distribution around the predicted value $\hat{y}$ and with a standard deviation denoted with $\sigma$. This can be denoted as: -->
<!-- $$y_i\sim Normal(\mu, \sigma).$$ -->
<!-- The index $i$ indicates each element (i.e. car) of the list $y$, which in turn is the list of distances. -->
<!-- In the third step, a Bayesian perspective is taken the **prior knowlege** (before seeing the data) has to be defined. The parameters of the current model are the predicted value $\mu$ and the standard deviation $\sigma$. For the parameter $\mu$ a normal distribution can be assumend with parameters that reflect the estimated values from the sample. -->
<!-- ```{r} -->
<!-- #descriptive statistics from the sample -->
<!-- tibble(variables=c("speed", "distance"), -->
<!--        mean=c(mean(cars$speed),mean(cars$dist)), -->
<!--        sigma = c(sd(cars$speed), sd(cars$dist))) -->
<!-- ``` -->
<!-- $$\mu\sim Normal(43,26)$$ -->
<!-- For the standard deviation $\sigma$ a uniform distribution is assumed: -->
<!-- $$\sigma\sim Uniform(0,40)$$ -->
<!-- #### Excursus: Identically and independently distributed (*iid*) -->
<!-- The short model description $y_i\sim Normal(\mu, \sigma)$ incorporates often already an assumption about the distribution of distance-values: They are *identically and independently distributed*. Often the abbreviation *iid* can be found for this assumption: -->
<!-- $$y_i\overset{\text{iid}}{\sim} Normal(\mu, \sigma).$$ -->
<!-- The abbreviation *iid* indicates that each value $y_i$ has the same probability function, independent of the other $y$ values and using the same parameters [@mcelreath2015]. This is hardly ever true (why hierarchical modeling is very attractive). For example, thinking about the cars in the current example data set. Some cars may be of different types or even the same type but different batches. But the question is: Is this underlying dependency relevant for the model? If yes, this information has to be added in the model (e.g. in form of a hierarchical model). Janyes states it as follows: "*The onus is always on the user to make sure that all information, which his common sense tells him is relevant to the problem, is actually incorporated into the equations, (...).*"[@jaynes2003,p.339]. But if one do not know any relevant underlying relationships the most conservative distribution to use is *iid*. Note, that the stated assumptions define how the model represents a problem and not how the world should be understood. For example, there might exist underlying correlations but on the overall distribution there influence tends towards zero. In such cases it remains usefull to assume iid [@mcelreath2015]. -->
<!-- ### Notation Simple Regression model -->
<!-- ![Graphical notation Simplre Regression model](chapters/images/Graph-SimpReg.png) -->
<!-- ## Greta -->
<!-- ```{r, eval = F} -->
<!-- ## --- greta model code --- -->
<!-- ## --- --- data --- --- -->
<!-- velocity  <- as_data(cars$speed) -->
<!-- distance  <- as_data(cars$dist) -->
<!-- ## --- --- latent variables --- --- -->
<!-- intercept <- normal(0, 10) -->
<!-- slope     <- normal(0, 10) -->
<!-- sigma     <- student(3, 0 , 1, truncation = c(0, Inf)) -->
<!-- # intercept <- variable() -->
<!-- # slope     <- variable() -->
<!-- # sigma     <- variable(lower = 0) -->
<!-- mean_g <- intercept + slope * velocity -->
<!-- ## --- --- likelihood --- --- -->
<!-- distribution(distance) <- normal(mean_g, sigma) -->
<!-- ## --- --- model --- --- -->
<!-- m <- model(intercept, slope, sigma) -->
<!-- # plot(m) -->
<!-- ## --- sampling --- -->
<!-- draws <- mcmc(m, n_samples = 1000) -->
<!-- tidy_draws = ggs(draws) -->
<!-- tidy_draws %>% group_by(Parameter) %>% -->
<!--   summarise(mean = mean(value), -->
<!--             '|95%' = quantile(value, probs = 0.025), -->
<!--             '95|%' = quantile(value, probs = 0.975)) -->
<!-- ``` -->
</div>
</div>
<div class="footnotes">
<hr />
<ol start="3">
<li id="fn3"><p>To learn about WebPPL the fast way, try <a href="http://www.problang.org/chapters/app-06-intro-to-webppl.html">this tutorial</a>.<a href="Chap-03-03-models-examples.html#fnref3" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="Chap-03-03-models-three-pillars.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="Chap-03-03-models-hypotheses.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["I2DA.epub", "I2DA.pdf"],
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
