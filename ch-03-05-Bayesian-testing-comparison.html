<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>11.4 Testing via model comparison | An Introduction to Data Analysis</title>
  <meta name="description" content="Introductory text for statistics and data analysis (using R)" />
  <meta name="generator" content="bookdown 0.24.1 and GitBook 2.6.7" />

  <meta property="og:title" content="11.4 Testing via model comparison | An Introduction to Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Introductory text for statistics and data analysis (using R)" />
  <meta name="github-repo" content="MarauderPixie/intro-data-analysis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="11.4 Testing via model comparison | An Introduction to Data Analysis" />
  
  <meta name="twitter:description" content="Introductory text for statistics and data analysis (using R)" />
  

<meta name="author" content="Michael Franke" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ch-03-05-Bayes-testing-estimation.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span. { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>


<link rel="stylesheet" href="styles.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="index.html#section"></a></li>
<li class="part"><span><b>I Preliminaries</b></span></li>
<li class="chapter" data-level="1" data-path="general-introduction.html"><a href="general-introduction.html"><i class="fa fa-check"></i><b>1</b> General Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="Chap-01-00-intro-learning-goals.html"><a href="Chap-01-00-intro-learning-goals.html"><i class="fa fa-check"></i><b>1.1</b> Learning goals</a></li>
<li class="chapter" data-level="1.2" data-path="Chap-01-00-intro-course-structure.html"><a href="Chap-01-00-intro-course-structure.html"><i class="fa fa-check"></i><b>1.2</b> Course structure</a></li>
<li class="chapter" data-level="1.3" data-path="Chap-01-00-intro-tools.html"><a href="Chap-01-00-intro-tools.html"><i class="fa fa-check"></i><b>1.3</b> Tools used in this course</a></li>
<li class="chapter" data-level="1.4" data-path="Chap-01-00-intro-topics.html"><a href="Chap-01-00-intro-topics.html"><i class="fa fa-check"></i><b>1.4</b> Topics covered (and not covered) in the course</a></li>
<li class="chapter" data-level="1.5" data-path="Chap-01-00-intro-data-sets.html"><a href="Chap-01-00-intro-data-sets.html"><i class="fa fa-check"></i><b>1.5</b> Data sets covered</a></li>
<li class="chapter" data-level="1.6" data-path="Chap-01-00-intro-installation.html"><a href="Chap-01-00-intro-installation.html"><i class="fa fa-check"></i><b>1.6</b> Installation</a></li>
<li class="chapter" data-level="1.7" data-path="Chap-01-00-intro-schedule.html"><a href="Chap-01-00-intro-schedule.html"><i class="fa fa-check"></i><b>1.7</b> Example schedule (12-week course)</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chap-01-01-R.html"><a href="Chap-01-01-R.html"><i class="fa fa-check"></i><b>2</b> Basics of R</a><ul>
<li class="chapter" data-level="2.1" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html"><i class="fa fa-check"></i><b>2.1</b> First steps</a><ul>
<li class="chapter" data-level="2.1.1" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#functions"><i class="fa fa-check"></i><b>2.1.1</b> Functions</a></li>
<li class="chapter" data-level="2.1.2" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#variables"><i class="fa fa-check"></i><b>2.1.2</b> Variables</a></li>
<li class="chapter" data-level="2.1.3" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#literate-coding"><i class="fa fa-check"></i><b>2.1.3</b> Literate coding</a></li>
<li class="chapter" data-level="2.1.4" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#objects"><i class="fa fa-check"></i><b>2.1.4</b> Objects</a></li>
<li class="chapter" data-level="2.1.5" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#packages"><i class="fa fa-check"></i><b>2.1.5</b> Packages</a></li>
<li class="chapter" data-level="2.1.6" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#Chap-01-01-R-help"><i class="fa fa-check"></i><b>2.1.6</b> Getting help</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="ch1-data-types.html"><a href="ch1-data-types.html"><i class="fa fa-check"></i><b>2.2</b> Data types</a><ul>
<li class="chapter" data-level="2.2.1" data-path="ch1-data-types.html"><a href="ch1-data-types.html#numeric-vectors-matrices"><i class="fa fa-check"></i><b>2.2.1</b> Numeric vectors &amp; matrices</a></li>
<li class="chapter" data-level="2.2.2" data-path="ch1-data-types.html"><a href="ch1-data-types.html#booleans"><i class="fa fa-check"></i><b>2.2.2</b> Booleans</a></li>
<li class="chapter" data-level="2.2.3" data-path="ch1-data-types.html"><a href="ch1-data-types.html#special-values"><i class="fa fa-check"></i><b>2.2.3</b> Special values</a></li>
<li class="chapter" data-level="2.2.4" data-path="ch1-data-types.html"><a href="ch1-data-types.html#characters-strings"><i class="fa fa-check"></i><b>2.2.4</b> Characters (= strings)</a></li>
<li class="chapter" data-level="2.2.5" data-path="ch1-data-types.html"><a href="ch1-data-types.html#factors"><i class="fa fa-check"></i><b>2.2.5</b> Factors</a></li>
<li class="chapter" data-level="2.2.6" data-path="ch1-data-types.html"><a href="ch1-data-types.html#lists-data-frames-tibbles"><i class="fa fa-check"></i><b>2.2.6</b> Lists, data frames &amp; tibbles</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="Chap-01-01-functions.html"><a href="Chap-01-01-functions.html"><i class="fa fa-check"></i><b>2.3</b> Functions</a><ul>
<li class="chapter" data-level="2.3.1" data-path="Chap-01-01-functions.html"><a href="Chap-01-01-functions.html#some-important-built-in-functions"><i class="fa fa-check"></i><b>2.3.1</b> Some important built-in functions</a></li>
<li class="chapter" data-level="2.3.2" data-path="Chap-01-01-functions.html"><a href="Chap-01-01-functions.html#defining-your-own-functions"><i class="fa fa-check"></i><b>2.3.2</b> Defining your own functions</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="ch-01-01-loops-and-maps.html"><a href="ch-01-01-loops-and-maps.html"><i class="fa fa-check"></i><b>2.4</b> Loops and maps</a><ul>
<li class="chapter" data-level="2.4.1" data-path="ch-01-01-loops-and-maps.html"><a href="ch-01-01-loops-and-maps.html#for-loops"><i class="fa fa-check"></i><b>2.4.1</b> For-loops</a></li>
<li class="chapter" data-level="2.4.2" data-path="ch-01-01-loops-and-maps.html"><a href="ch-01-01-loops-and-maps.html#functional-iterators"><i class="fa fa-check"></i><b>2.4.2</b> Functional iterators</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="Chap-01-01-piping.html"><a href="Chap-01-01-piping.html"><i class="fa fa-check"></i><b>2.5</b> Piping</a><ul>
<li class="chapter" data-level="2.5.1" data-path="Chap-01-01-piping.html"><a href="Chap-01-01-piping.html#excursion-more-on-pipes-in-r"><i class="fa fa-check"></i><b>2.5.1</b> Excursion: More on pipes in R</a></li>
<li class="chapter" data-level="2.5.2" data-path="Chap-01-01-piping.html"><a href="Chap-01-01-piping.html#excursion-multiple-assignments-or-unpacking"><i class="fa fa-check"></i><b>2.5.2</b> Excursion: Multiple assignments, or “unpacking”</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="ch-01-01-Rmarkdown.html"><a href="ch-01-01-Rmarkdown.html"><i class="fa fa-check"></i><b>2.6</b> Rmarkdown</a></li>
</ul></li>
<li class="part"><span><b>II Data</b></span></li>
<li class="chapter" data-level="3" data-path="Chap-02-01-data.html"><a href="Chap-02-01-data.html"><i class="fa fa-check"></i><b>3</b> Data, variables &amp; experimental designs</a><ul>
<li class="chapter" data-level="3.1" data-path="Chap-02-01-data-what-is-data.html"><a href="Chap-02-01-data-what-is-data.html"><i class="fa fa-check"></i><b>3.1</b> What is data?</a></li>
<li class="chapter" data-level="3.2" data-path="Chap-02-01-data-kinds-of-data.html"><a href="Chap-02-01-data-kinds-of-data.html"><i class="fa fa-check"></i><b>3.2</b> Different kinds of data</a></li>
<li class="chapter" data-level="3.3" data-path="Chap-02-01-data-variables.html"><a href="Chap-02-01-data-variables.html"><i class="fa fa-check"></i><b>3.3</b> On the notion of “variables”</a></li>
<li class="chapter" data-level="3.4" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html"><i class="fa fa-check"></i><b>3.4</b> Basics of experimental design</a><ul>
<li class="chapter" data-level="3.4.1" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html#what-to-analyze-dependent-variables"><i class="fa fa-check"></i><b>3.4.1</b> What to analyze? – Dependent variables</a></li>
<li class="chapter" data-level="3.4.2" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html#conditions-trials-items"><i class="fa fa-check"></i><b>3.4.2</b> Conditions, trials, items</a></li>
<li class="chapter" data-level="3.4.3" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html#sample-size"><i class="fa fa-check"></i><b>3.4.3</b> Sample size</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-wrangling.html"><a href="data-wrangling.html"><i class="fa fa-check"></i><b>4</b> Data Wrangling</a><ul>
<li class="chapter" data-level="4.1" data-path="Chap-02-02-data-IO.html"><a href="Chap-02-02-data-IO.html"><i class="fa fa-check"></i><b>4.1</b> Data in, data out</a></li>
<li class="chapter" data-level="4.2" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html"><i class="fa fa-check"></i><b>4.2</b> Tidy data</a><ul>
<li class="chapter" data-level="4.2.1" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html#running-example"><i class="fa fa-check"></i><b>4.2.1</b> Running example</a></li>
<li class="chapter" data-level="4.2.2" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html#definition-of-tidy-data"><i class="fa fa-check"></i><b>4.2.2</b> Definition of <em>tidy data</em></a></li>
<li class="chapter" data-level="4.2.3" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html#excursion-non-redundant-data"><i class="fa fa-check"></i><b>4.2.3</b> Excursion: non-redundant data</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html"><i class="fa fa-check"></i><b>4.3</b> Data manipulation: the basics</a><ul>
<li class="chapter" data-level="4.3.1" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#pivoting"><i class="fa fa-check"></i><b>4.3.1</b> Pivoting</a></li>
<li class="chapter" data-level="4.3.2" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#subsetting-rows-columns"><i class="fa fa-check"></i><b>4.3.2</b> Subsetting rows &amp; columns</a></li>
<li class="chapter" data-level="4.3.3" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#Chap-02-02-tidy-selection"><i class="fa fa-check"></i><b>4.3.3</b> Tidy selection of column names</a></li>
<li class="chapter" data-level="4.3.4" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#adding-changing-and-renaming-columns"><i class="fa fa-check"></i><b>4.3.4</b> Adding, changing and renaming columns</a></li>
<li class="chapter" data-level="4.3.5" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#splitting-and-uniting-columns"><i class="fa fa-check"></i><b>4.3.5</b> Splitting and uniting columns</a></li>
<li class="chapter" data-level="4.3.6" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#sorting-a-data-set"><i class="fa fa-check"></i><b>4.3.6</b> Sorting a data set</a></li>
<li class="chapter" data-level="4.3.7" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#combining-tibbles"><i class="fa fa-check"></i><b>4.3.7</b> Combining tibbles</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="Chap-02-02-data-grouping-nesting.html"><a href="Chap-02-02-data-grouping-nesting.html"><i class="fa fa-check"></i><b>4.4</b> Grouped operations</a></li>
<li class="chapter" data-level="4.5" data-path="Chap-02-02-data-case-study-KoF.html"><a href="Chap-02-02-data-case-study-KoF.html"><i class="fa fa-check"></i><b>4.5</b> Case study: the King of France</a><ul>
<li class="chapter" data-level="4.5.1" data-path="Chap-02-02-data-case-study-KoF.html"><a href="Chap-02-02-data-case-study-KoF.html#cleaning-the-data"><i class="fa fa-check"></i><b>4.5.1</b> Cleaning the data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Chap-02-03-summary-statistics.html"><a href="Chap-02-03-summary-statistics.html"><i class="fa fa-check"></i><b>5</b> Summary statistics</a><ul>
<li class="chapter" data-level="5.1" data-path="Chap-02-03-summary-statistics-counts.html"><a href="Chap-02-03-summary-statistics-counts.html"><i class="fa fa-check"></i><b>5.1</b> Counts and proportions</a><ul>
<li class="chapter" data-level="5.1.1" data-path="Chap-02-03-summary-statistics-counts.html"><a href="Chap-02-03-summary-statistics-counts.html#loading-and-inspecting-the-data"><i class="fa fa-check"></i><b>5.1.1</b> Loading and inspecting the data</a></li>
<li class="chapter" data-level="5.1.2" data-path="Chap-02-03-summary-statistics-counts.html"><a href="Chap-02-03-summary-statistics-counts.html#obtaining-counts-with-n-count-and-tally"><i class="fa fa-check"></i><b>5.1.2</b> Obtaining counts with <code>n</code>, <code>count</code> and <code>tally</code></a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html"><i class="fa fa-check"></i><b>5.2</b> Central tendency and dispersion</a><ul>
<li class="chapter" data-level="5.2.1" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#the-data-for-the-remainder-of-the-chapter"><i class="fa fa-check"></i><b>5.2.1</b> The data for the remainder of the chapter</a></li>
<li class="chapter" data-level="5.2.2" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#measures-of-central-tendency"><i class="fa fa-check"></i><b>5.2.2</b> Measures of central tendency</a></li>
<li class="chapter" data-level="5.2.3" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#measures-of-dispersion"><i class="fa fa-check"></i><b>5.2.3</b> Measures of dispersion</a></li>
<li class="chapter" data-level="5.2.4" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#excursion-quantifying-confidence-with-bootstrapping"><i class="fa fa-check"></i><b>5.2.4</b> Excursion: Quantifying confidence with bootstrapping</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="Chap-02-03-summary-statistics-2D.html"><a href="Chap-02-03-summary-statistics-2D.html"><i class="fa fa-check"></i><b>5.3</b> Covariance and correlation</a><ul>
<li class="chapter" data-level="5.3.1" data-path="Chap-02-03-summary-statistics-2D.html"><a href="Chap-02-03-summary-statistics-2D.html#covariance"><i class="fa fa-check"></i><b>5.3.1</b> Covariance</a></li>
<li class="chapter" data-level="5.3.2" data-path="Chap-02-03-summary-statistics-2D.html"><a href="Chap-02-03-summary-statistics-2D.html#correlation"><i class="fa fa-check"></i><b>5.3.2</b> Correlation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Chap-02-02-visualization.html"><a href="Chap-02-02-visualization.html"><i class="fa fa-check"></i><b>6</b> Data Visualization</a><ul>
<li class="chapter" data-level="6.1" data-path="Chap-02-04-Anscombe-example.html"><a href="Chap-02-04-Anscombe-example.html"><i class="fa fa-check"></i><b>6.1</b> Motivating example: Anscombe’s quartet</a></li>
<li class="chapter" data-level="6.2" data-path="Chap-02-04-good-visualization.html"><a href="Chap-02-04-good-visualization.html"><i class="fa fa-check"></i><b>6.2</b> Visualization: the good, the bad and the infographic</a></li>
<li class="chapter" data-level="6.3" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html"><i class="fa fa-check"></i><b>6.3</b> Basics of <code>ggplot</code></a><ul>
<li class="chapter" data-level="6.3.1" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#incremental-composition-of-a-plot"><i class="fa fa-check"></i><b>6.3.1</b> Incremental composition of a plot</a></li>
<li class="chapter" data-level="6.3.2" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#elements-in-the-layered-grammar-of-graphs"><i class="fa fa-check"></i><b>6.3.2</b> Elements in the layered grammar of graphs</a></li>
<li class="chapter" data-level="6.3.3" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#layers-and-groups"><i class="fa fa-check"></i><b>6.3.3</b> Layers and groups</a></li>
<li class="chapter" data-level="6.3.4" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#grouping"><i class="fa fa-check"></i><b>6.3.4</b> Grouping</a></li>
<li class="chapter" data-level="6.3.5" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#example-of-a-customized-plot"><i class="fa fa-check"></i><b>6.3.5</b> Example of a customized plot</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html"><i class="fa fa-check"></i><b>6.4</b> A rendezvous with popular geoms</a><ul>
<li class="chapter" data-level="6.4.1" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#scatter-plots-with-geom_point"><i class="fa fa-check"></i><b>6.4.1</b> Scatter plots with <code>geom_point</code></a></li>
<li class="chapter" data-level="6.4.2" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#smooth"><i class="fa fa-check"></i><b>6.4.2</b> Smooth</a></li>
<li class="chapter" data-level="6.4.3" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#line"><i class="fa fa-check"></i><b>6.4.3</b> Line</a></li>
<li class="chapter" data-level="6.4.4" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#bar-plot"><i class="fa fa-check"></i><b>6.4.4</b> Bar plot</a></li>
<li class="chapter" data-level="6.4.5" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#plotting-distributions-histograms-boxplots-densities-and-violins"><i class="fa fa-check"></i><b>6.4.5</b> Plotting distributions: histograms, boxplots, densities and violins</a></li>
<li class="chapter" data-level="6.4.6" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#rugs"><i class="fa fa-check"></i><b>6.4.6</b> Rugs</a></li>
<li class="chapter" data-level="6.4.7" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#annotation"><i class="fa fa-check"></i><b>6.4.7</b> Annotation</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="Chap-02-04-faceting.html"><a href="Chap-02-04-faceting.html"><i class="fa fa-check"></i><b>6.5</b> Faceting</a></li>
<li class="chapter" data-level="6.6" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html"><i class="fa fa-check"></i><b>6.6</b> Customization etc.</a><ul>
<li class="chapter" data-level="6.6.1" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#themes"><i class="fa fa-check"></i><b>6.6.1</b> Themes</a></li>
<li class="chapter" data-level="6.6.2" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#guides"><i class="fa fa-check"></i><b>6.6.2</b> Guides</a></li>
<li class="chapter" data-level="6.6.3" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#axes-ticks-and-tick-labels"><i class="fa fa-check"></i><b>6.6.3</b> Axes, ticks and tick labels</a></li>
<li class="chapter" data-level="6.6.4" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#labels"><i class="fa fa-check"></i><b>6.6.4</b> Labels</a></li>
<li class="chapter" data-level="6.6.5" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#combining-arranging-plots"><i class="fa fa-check"></i><b>6.6.5</b> Combining &amp; arranging plots</a></li>
<li class="chapter" data-level="6.6.6" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#latex-expressions-in-plot-labels"><i class="fa fa-check"></i><b>6.6.6</b> LaTeX expressions in plot labels</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Bayesian Data Analysis</b></span></li>
<li class="chapter" data-level="7" data-path="Chap-03-01-probability.html"><a href="Chap-03-01-probability.html"><i class="fa fa-check"></i><b>7</b> Basics of Probability Theory</a><ul>
<li class="chapter" data-level="7.1" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html"><i class="fa fa-check"></i><b>7.1</b> Probability</a><ul>
<li class="chapter" data-level="7.1.1" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#outcomes-events-observations"><i class="fa fa-check"></i><b>7.1.1</b> Outcomes, events, observations</a></li>
<li class="chapter" data-level="7.1.2" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#probability-distributions"><i class="fa fa-check"></i><b>7.1.2</b> Probability distributions</a></li>
<li class="chapter" data-level="7.1.3" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#interpretations-of-probability"><i class="fa fa-check"></i><b>7.1.3</b> Interpretations of probability</a></li>
<li class="chapter" data-level="7.1.4" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#distributions-as-samples"><i class="fa fa-check"></i><b>7.1.4</b> Distributions as samples</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html"><i class="fa fa-check"></i><b>7.2</b> Structured events &amp; marginal distributions</a><ul>
<li class="chapter" data-level="7.2.1" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html#probability-table-for-a-flip-and-draw-scenario"><i class="fa fa-check"></i><b>7.2.1</b> Probability table for a flip-and-draw scenario</a></li>
<li class="chapter" data-level="7.2.2" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html#structured-events-and-joint-probability-distributions"><i class="fa fa-check"></i><b>7.2.2</b> Structured events and joint-probability distributions</a></li>
<li class="chapter" data-level="7.2.3" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html#marginalization"><i class="fa fa-check"></i><b>7.2.3</b> Marginalization</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="Chap-03-01-probability-conditional.html"><a href="Chap-03-01-probability-conditional.html"><i class="fa fa-check"></i><b>7.3</b> Conditional probability</a><ul>
<li class="chapter" data-level="7.3.1" data-path="Chap-03-01-probability-conditional.html"><a href="Chap-03-01-probability-conditional.html#bayes-rule"><i class="fa fa-check"></i><b>7.3.1</b> Bayes rule</a></li>
<li class="chapter" data-level="7.3.2" data-path="Chap-03-01-probability-conditional.html"><a href="Chap-03-01-probability-conditional.html#Chap-03-01-probability-independence"><i class="fa fa-check"></i><b>7.3.2</b> Stochastic (in-)dependence</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html"><i class="fa fa-check"></i><b>7.4</b> Random variables</a><ul>
<li class="chapter" data-level="7.4.1" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#notation-terminology"><i class="fa fa-check"></i><b>7.4.1</b> Notation &amp; terminology</a></li>
<li class="chapter" data-level="7.4.2" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#cumulative-distribution-functions-mass-density"><i class="fa fa-check"></i><b>7.4.2</b> Cumulative distribution functions, mass &amp; density</a></li>
<li class="chapter" data-level="7.4.3" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#expected-value-variance"><i class="fa fa-check"></i><b>7.4.3</b> Expected value &amp; variance</a></li>
<li class="chapter" data-level="7.4.4" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#composite-random-variables"><i class="fa fa-check"></i><b>7.4.4</b> Composite random variables</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="Chap-03-01-probability-R.html"><a href="Chap-03-01-probability-R.html"><i class="fa fa-check"></i><b>7.5</b> Probability distributions in R</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Chap-03-03-models.html"><a href="Chap-03-03-models.html"><i class="fa fa-check"></i><b>8</b> Statistical models</a><ul>
<li class="chapter" data-level="8.1" data-path="Chap-03-03-models-general.html"><a href="Chap-03-03-models-general.html"><i class="fa fa-check"></i><b>8.1</b> Statistical models</a></li>
<li class="chapter" data-level="8.2" data-path="Chap-03-03-models-representation.html"><a href="Chap-03-03-models-representation.html"><i class="fa fa-check"></i><b>8.2</b> Notation &amp; graphical representation</a><ul>
<li class="chapter" data-level="8.2.1" data-path="Chap-03-03-models-representation.html"><a href="Chap-03-03-models-representation.html#formula-notation"><i class="fa fa-check"></i><b>8.2.1</b> Formula notation</a></li>
<li class="chapter" data-level="8.2.2" data-path="Chap-03-03-models-representation.html"><a href="Chap-03-03-models-representation.html#graphical-notation"><i class="fa fa-check"></i><b>8.2.2</b> Graphical notation</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html"><i class="fa fa-check"></i><b>8.3</b> Parameters, priors, and prior predictions</a><ul>
<li class="chapter" data-level="8.3.1" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html#whats-a-model-parameter"><i class="fa fa-check"></i><b>8.3.1</b> What’s a model parameter?</a></li>
<li class="chapter" data-level="8.3.2" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html#Chap-03-02-models-priors"><i class="fa fa-check"></i><b>8.3.2</b> Priors over parameters</a></li>
<li class="chapter" data-level="8.3.3" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html#Chap-03-03-models-parameters-prior-predictive"><i class="fa fa-check"></i><b>8.3.3</b> Prior predictions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ch-03-04-parameter-estimation.html"><a href="ch-03-04-parameter-estimation.html"><i class="fa fa-check"></i><b>9</b> Bayesian parameter estimation</a><ul>
<li class="chapter" data-level="9.1" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html"><i class="fa fa-check"></i><b>9.1</b> Bayes rule for parameter estimation</a><ul>
<li class="chapter" data-level="9.1.1" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#definitions-and-terminology"><i class="fa fa-check"></i><b>9.1.1</b> Definitions and terminology</a></li>
<li class="chapter" data-level="9.1.2" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#the-effects-of-prior-and-likelihood-on-the-posterior"><i class="fa fa-check"></i><b>9.1.2</b> The effects of prior and likelihood on the posterior</a></li>
<li class="chapter" data-level="9.1.3" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#ch-03-04-parameter-estimation-conjugacy"><i class="fa fa-check"></i><b>9.1.3</b> Computing Bayesian posteriors with conjugate priors</a></li>
<li class="chapter" data-level="9.1.4" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#excursion-sequential-updating"><i class="fa fa-check"></i><b>9.1.4</b> Excursion: Sequential updating</a></li>
<li class="chapter" data-level="9.1.5" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#posterior-predictive-distribution"><i class="fa fa-check"></i><b>9.1.5</b> Posterior predictive distribution</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="ch-03-04-parameter-estimation-points-intervals.html"><a href="ch-03-04-parameter-estimation-points-intervals.html"><i class="fa fa-check"></i><b>9.2</b> Point-valued and interval-ranged estimates</a><ul>
<li class="chapter" data-level="9.2.1" data-path="ch-03-04-parameter-estimation-points-intervals.html"><a href="ch-03-04-parameter-estimation-points-intervals.html#point-valued-estimates"><i class="fa fa-check"></i><b>9.2.1</b> Point-valued estimates</a></li>
<li class="chapter" data-level="9.2.2" data-path="ch-03-04-parameter-estimation-points-intervals.html"><a href="ch-03-04-parameter-estimation-points-intervals.html#interval-ranged-estimates"><i class="fa fa-check"></i><b>9.2.2</b> Interval-ranged estimates</a></li>
<li class="chapter" data-level="9.2.3" data-path="ch-03-04-parameter-estimation-points-intervals.html"><a href="ch-03-04-parameter-estimation-points-intervals.html#computing-bayesian-estimates"><i class="fa fa-check"></i><b>9.2.3</b> Computing Bayesian estimates</a></li>
<li class="chapter" data-level="9.2.4" data-path="ch-03-04-parameter-estimation-points-intervals.html"><a href="ch-03-04-parameter-estimation-points-intervals.html#excursion-computing-mles-and-maps-in-r"><i class="fa fa-check"></i><b>9.2.4</b> Excursion: Computing MLEs and MAPs in R</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="Ch-03-03-estimation-algorithms.html"><a href="Ch-03-03-estimation-algorithms.html"><i class="fa fa-check"></i><b>9.3</b> Approximating the posterior</a><ul>
<li class="chapter" data-level="9.3.1" data-path="Ch-03-03-estimation-algorithms.html"><a href="Ch-03-03-estimation-algorithms.html#ch-03-03-MCMC"><i class="fa fa-check"></i><b>9.3.1</b> Of apples and trees: Markov Chain Monte Carlo sampling</a></li>
<li class="chapter" data-level="9.3.2" data-path="Ch-03-03-estimation-algorithms.html"><a href="Ch-03-03-estimation-algorithms.html#ch-03-03-estimation-Stan"><i class="fa fa-check"></i><b>9.3.2</b> Excursion: Probabilistic modeling with Stan</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="ch-03-04-parameter-estimation-normal.html"><a href="ch-03-04-parameter-estimation-normal.html"><i class="fa fa-check"></i><b>9.4</b> Estimating the parameters of a Normal distribution</a><ul>
<li class="chapter" data-level="9.4.1" data-path="ch-03-04-parameter-estimation-normal.html"><a href="ch-03-04-parameter-estimation-normal.html#uninformative-priors"><i class="fa fa-check"></i><b>9.4.1</b> Uninformative priors</a></li>
<li class="chapter" data-level="9.4.2" data-path="ch-03-04-parameter-estimation-normal.html"><a href="ch-03-04-parameter-estimation-normal.html#conjugate-priors"><i class="fa fa-check"></i><b>9.4.2</b> Conjugate priors</a></li>
<li class="chapter" data-level="9.4.3" data-path="ch-03-04-parameter-estimation-normal.html"><a href="ch-03-04-parameter-estimation-normal.html#estimating-the-difference-between-group-means"><i class="fa fa-check"></i><b>9.4.3</b> Estimating the difference between group means</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="Chap-03-06-model-comparison.html"><a href="Chap-03-06-model-comparison.html"><i class="fa fa-check"></i><b>10</b> Model Comparison</a><ul>
<li class="chapter" data-level="10.1" data-path="Chap-03-06-model-comparison-case-study.html"><a href="Chap-03-06-model-comparison-case-study.html"><i class="fa fa-check"></i><b>10.1</b> Case study: recall models</a></li>
<li class="chapter" data-level="10.2" data-path="Chap-03-06-model-comparison-AIC.html"><a href="Chap-03-06-model-comparison-AIC.html"><i class="fa fa-check"></i><b>10.2</b> Akaike Information Criterion</a></li>
<li class="chapter" data-level="10.3" data-path="Chap-03-06-model-comparison-BF.html"><a href="Chap-03-06-model-comparison-BF.html"><i class="fa fa-check"></i><b>10.3</b> Bayes factors</a><ul>
<li class="chapter" data-level="10.3.1" data-path="Chap-03-06-model-comparison-BF.html"><a href="Chap-03-06-model-comparison-BF.html#Chap-03-06-model-comparison-BF-grid"><i class="fa fa-check"></i><b>10.3.1</b> Grid approximation</a></li>
<li class="chapter" data-level="10.3.2" data-path="Chap-03-06-model-comparison-BF.html"><a href="Chap-03-06-model-comparison-BF.html#Chap-03-06-model-comparison-BF-naiveMC"><i class="fa fa-check"></i><b>10.3.2</b> Naive Monte Carlo</a></li>
<li class="chapter" data-level="10.3.3" data-path="Chap-03-06-model-comparison-BF.html"><a href="Chap-03-06-model-comparison-BF.html#Chap-03-06-model-comparison-BF-bridge"><i class="fa fa-check"></i><b>10.3.3</b> Excursion: Bridge sampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ch-03-07-hypothesis-testing-Bayes.html"><a href="ch-03-07-hypothesis-testing-Bayes.html"><i class="fa fa-check"></i><b>11</b> Bayesian hypothesis testing</a><ul>
<li class="chapter" data-level="11.1" data-path="ch-03-07-hypothesis-testing-Bayes-hypotheses.html"><a href="ch-03-07-hypothesis-testing-Bayes-hypotheses.html"><i class="fa fa-check"></i><b>11.1</b> Statistical hypotheses</a></li>
<li class="chapter" data-level="11.2" data-path="data-and-models-for-this-chapter.html"><a href="data-and-models-for-this-chapter.html"><i class="fa fa-check"></i><b>11.2</b> Data and models for this chapter</a><ul>
<li class="chapter" data-level="11.2.1" data-path="data-and-models-for-this-chapter.html"><a href="data-and-models-for-this-chapter.html#section-1"><i class="fa fa-check"></i><b>11.2.1</b> 24/7</a></li>
<li class="chapter" data-level="11.2.2" data-path="data-and-models-for-this-chapter.html"><a href="data-and-models-for-this-chapter.html#simon-task"><i class="fa fa-check"></i><b>11.2.2</b> Simon task</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="ch-03-05-Bayes-testing-estimation.html"><a href="ch-03-05-Bayes-testing-estimation.html"><i class="fa fa-check"></i><b>11.3</b> Testing via posterior estimation</a><ul>
<li class="chapter" data-level="11.3.1" data-path="ch-03-05-Bayes-testing-estimation.html"><a href="ch-03-05-Bayes-testing-estimation.html#example-247"><i class="fa fa-check"></i><b>11.3.1</b> Example: 24/7</a></li>
<li class="chapter" data-level="11.3.2" data-path="ch-03-05-Bayes-testing-estimation.html"><a href="ch-03-05-Bayes-testing-estimation.html#example-simon-task"><i class="fa fa-check"></i><b>11.3.2</b> Example: Simon Task</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="ch-03-05-Bayesian-testing-comparison.html"><a href="ch-03-05-Bayesian-testing-comparison.html"><i class="fa fa-check"></i><b>11.4</b> Testing via model comparison</a><ul>
<li class="chapter" data-level="11.4.1" data-path="ch-03-05-Bayesian-testing-comparison.html"><a href="ch-03-05-Bayesian-testing-comparison.html#ch-03-07-hypothesis-testing-Bayes-Savage-Dickey"><i class="fa fa-check"></i><b>11.4.1</b> The Savage-Dickey method</a></li>
<li class="chapter" data-level="11.4.2" data-path="ch-03-05-Bayesian-testing-comparison.html"><a href="ch-03-05-Bayesian-testing-comparison.html#ch-03-07-hypothesis-testing-Bayes-encompassing-models"><i class="fa fa-check"></i><b>11.4.2</b> Encompassing models</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch-03-05-Bayesian-testing-comparison" class="section level2">
<h2><span class="header-section-number">11.4</span> Testing via model comparison</h2>
<p>Testing hypotheses based on parameter estimation, and in particular the categorical decision rules for accepting or rejecting hypotheses outlined in the previous section, only give a very coarse-grained picture.
Bayesian analysis is about providing quantitative information about uncertainty and evidence, which are intuitive and easily interpretable.
So, we would also like to have a quantitative assessment of the evidence for or against a hypothesis provided by some data against the background of a given model.
This is what the comparison-based approaches to Bayesian hypothesis testing give us.</p>
<p>Here is some further motivation why model comparison might be a good replacement for “testing via estimation”.
A statistical hypothesis <span class="math inline">\(H\)</span> is basically an event: a subset of parameter values are picked out of the whole parameter space.
After observing data <span class="math inline">\(D_\text{obs}\)</span> and based on model <span class="math inline">\(M\)</span>, the ideal measure to have is <span class="math inline">\(P_M(H \mid D_\text{obs})\)</span>: given data and model, how likely is the hypothesis in question?
The problem with this posterior formulation <span class="math inline">\(P_M(H \mid D_\text{obs})\)</span> is that, for it to be meaningful, it must quantify over the set of all alternative hypotheses.
If <span class="math inline">\(H\)</span> is a point-valued hypothesis over a single parameter, the set of all alternative hypotheses could comprise all other logically possible point-valued hypotheses for the same parameter.
But then, if that parameter is a continuous parameter, the posterior density at <span class="math inline">\(P_M(H \mid D_\text{obs})\)</span> is not meaningfully interpretable as a probability (mass).
If <span class="math inline">\(H\)</span> is an interval-based hypothesis, the posterior <span class="math inline">\(P_M(H \mid D_\text{obs})\)</span> would be meaningfully interpretable as a probability (mass), but still the question of what exactly the space of alternatives is is left implicit.
Moreover, the posterior <span class="math inline">\(P_M(H \mid D_\text{obs})\)</span> is influenced by the model’s prior over <span class="math inline">\(H\)</span>.
So, a nominally high value of <span class="math inline">\(P_M(H \mid D_\text{obs})\)</span> is as such uninteresting because we would need to take the prior <span class="math inline">\(P_M(H)\)</span> into account as well.</p>
<p>This is why a comparison-based approach to Bayesian hypothesis testing explicitly compares two models:</p>
<ul>
<li><strong>The null model</strong> <span class="math inline">\(M_0\)</span> is the model that incorporates the assumption of the hypothesis <span class="math inline">\(H\)</span> to be tested. For example, the null model would put prior probability zero on those parameter values which are ruled out by <span class="math inline">\(H\)</span>.</li>
<li><strong>The alternative model</strong> <span class="math inline">\(M_1\)</span> is an explicitly formulated model which incorporates some contextually or technically useful alternative to <span class="math inline">\(M_0\)</span>.</li>
</ul>
<p>The comparison-based approach to hypothesis testing then quantifies, using Bayes factors, the evidence that <span class="math inline">\(D_\text{obs}\)</span> provides for or against <span class="math inline">\(M_0\)</span> (the model representing the “null hypothesis”) over the alternative model <span class="math inline">\(M_1\)</span> (the model representing the alternative hypothesis).
In this way, by looking at the ratio:</p>
<p><span class="math display">\[
BF_{01} = \frac{P(D_\text{obs} \mid M_0)}{P(D_\text{obs} \mid M_1)}
\]</span></p>
<p>this approach is independent of the prior probability assigned to models <span class="math inline">\(P(M_0)\)</span> and <span class="math inline">\(P(M_1)\)</span>.
Notice, however, that it is <em>not</em> independent of the priors over <span class="math inline">\(\theta\)</span> used in <span class="math inline">\(M_1\)</span>!</p>
<p>When the null hypothesis is point-valued, the alternative model is <em>not</em> based on the complement <span class="math inline">\(\theta \neq \theta^*\)</span>, but on the technically much more practical and also conceptually more plausible alternative model that assumes that <span class="math inline">\(\theta\)</span> is free to range over a larger interval including, but not limited to <span class="math inline">\(\theta^*\)</span>. We can then use the so-called Savage-Dickey method, described in Section <a href="ch-03-05-Bayesian-testing-comparison.html#ch-03-07-hypothesis-testing-Bayes-Savage-Dickey">11.4.1</a>, to compare the null and the alternative models as so-called <em>nested models</em>.</p>
<p>When the null hypothesis is interval-valued, the alternative model can be conceived as based on the complement of the null hypothesis. We can then use an extension of the Savage-Dickey method based on a so-called encompassing model, described in Section <a href="ch-03-05-Bayesian-testing-comparison.html#ch-03-07-hypothesis-testing-Bayes-encompassing-models">11.4.2</a>, where we construe both the null model and the alternative model as nested under a third, well, encompassing model.</p>
<p>This chapter shows how Bayes factors can be approximated based on samples from the posterior following both of these approaches.</p>
<div id="ch-03-07-hypothesis-testing-Bayes-Savage-Dickey" class="section level3">
<h3><span class="header-section-number">11.4.1</span> The Savage-Dickey method</h3>
<p>The Savage-Dickey method is a very convenient way of computing Bayes factors for <em>nested models</em>, especially when models only differ with respect to one parameter.</p>
<p>Suppose that there are <span class="math inline">\(n\)</span> continuous parameters of interest <span class="math inline">\(\theta = \langle \theta_1, \dots, \theta_n \rangle\)</span>. <span class="math inline">\(M_1\)</span> is a (Bayesian) model defined by <span class="math inline">\(P(\theta \mid M_1)\)</span> and <span class="math inline">\(P(D \mid \theta, M_1)\)</span>. <span class="math inline">\(M_0\)</span> is <strong>properly nested</strong> under <span class="math inline">\(M_1\)</span> if:</p>
<ul>
<li><span class="math inline">\(M_0\)</span> assigns fixed values to parameters <span class="math inline">\(\theta_i = x_i, \dots, \theta_n = x_n\)</span></li>
<li><span class="math inline">\(P(D \mid \theta_1, \dots, \theta_{i-1}, M_0) = P(D \mid \theta_1, \dots, \theta_{i-1}, \theta_i = x_i, \dots, \theta_n = x_n, M_1)\)</span></li>
<li><span class="math inline">\(\lim_{\theta_i \rightarrow x_i, \dots, \theta_n \rightarrow x_n} P(\theta_1, \dots, \theta_{i-1} \mid \theta_i, \dots, \theta_n, M_1) = P(\theta_1, \dots, \theta_{i-1} \mid M_0)\)</span></li>
</ul>
<p>Intuitively put, <span class="math inline">\(M_0\)</span> is properly nested under <span class="math inline">\(M_1\)</span>, if <span class="math inline">\(M_0\)</span> is a special case of <span class="math inline">\(M_1\)</span> which fixes certain parameters to specific point-values.
Notice that the last condition is satisfied in particular when <span class="math inline">\(M_1\)</span>’s prior over <span class="math inline">\(\theta_1, \dots, \theta_{i-1}\)</span> is independent of the values for the remaining parameters.</p>
<p>We can express a point-valued hypothesis in terms of a model <span class="math inline">\(M_0\)</span> which is nested under the alternative model <span class="math inline">\(M_1\)</span>, the latter of which assumes that the parameters in question can take more than one value.
For such properly nested models, we can compute a Bayes factor efficiently using the following result.</p>
<div class="mathstuff">

<div class="theorem">
<p><span id="thm:unnamed-chunk-339" class="theorem"><strong>Theorem 11.1  (Savage-Dickey Bayes factors for nested models)  </strong></span>Let <span class="math inline">\(M_0\)</span> be properly nested under <span class="math inline">\(M_1\)</span> s.t. <span class="math inline">\(M_0\)</span> fixes <span class="math inline">\(\theta_i = x_i, \dots, \theta_n = x_n\)</span>. The Bayes factor <span class="math inline">\(\text{BF}_{01}\)</span> in favor of <span class="math inline">\(M_0\)</span> over <span class="math inline">\(M_1\)</span> is then given by the ratio of posterior probability to prior probability of the parameters <span class="math inline">\(\theta_i = x_i, \dots, \theta_n = x_n\)</span> from the point of view of the nesting model <span class="math inline">\(M_1\)</span>:</p>
<span class="math display">\[
\begin{aligned}
\text{BF}_{01} &amp; = \frac{P(\theta_i = x_i, \dots, \theta_n = x_n \mid D, M_1)}{P(\theta_i = x_i, \dots, \theta_n = x_n \mid M_1)}
\end{aligned}
\]</span>
</div>
<div class="collapsibleProof">
<button class="trigger">
Show proof.
</button>
<div class="content">

<div class="proof">
<p> <span class="proof"><em>Proof. </em></span> Let’s assume that <span class="math inline">\(M_0\)</span> has parameters <span class="math inline">\(\theta = \langle\phi, \psi\rangle\)</span> with <span class="math inline">\(\phi = \phi_0\)</span>, and that <span class="math inline">\(M_1\)</span> has parameters <span class="math inline">\(\theta = \langle\phi, \psi \rangle\)</span> with <span class="math inline">\(\phi\)</span> free to vary. If <span class="math inline">\(M_0\)</span> is properly nested under <span class="math inline">\(M_1\)</span>, we know that <span class="math inline">\(\lim_{\phi \rightarrow \phi_0} P(\psi \mid \phi, M_1) = P(\psi \mid M_0)\)</span>. We can then rewrite the marginal likelihood under <span class="math inline">\(M_0\)</span> as follows:</p>
<p><span class="math display">\[ 
\begin{aligned}
P(D \mid M_0) &amp; = \int P(D \mid \psi, M_0) P(\psi \mid M_0) \ \text{d}\psi
&amp; \text{[marginalization]}
\\
 &amp; = \int P(D \mid \psi, \phi = \phi_0, M_1) P(\psi \mid \phi = \phi_0, M_1)  \ \text{d}\psi
 &amp; \text{[assumption of nesting]}
 \\
 &amp; = P(D \mid \phi = \phi_0, M_1) 
 &amp; \text{[marginalization]}
 \\
 &amp; = \frac{P(\phi = \phi_0 \mid D, M_1) P(D \mid M_1)}{P(\phi = \phi_0 \mid M_1)}
 &amp; \text{[Bayes rule]}
\end{aligned}
\]</span></p>
<p>The result follows if we divide by <span class="math inline">\(P(D \mid M_1)\)</span> on both sides of the equation.</p>
</div>
<p> </p>
</div>
</div>
</div>
<div id="example-247-1" class="section level4">
<h4><span class="header-section-number">11.4.1.1</span> Example: 24/7</h4>
<p>Here is an example based on the 24/7 data. For a nesting model with a flat prior (<span class="math inline">\(\theta \sim^{M_1} \text{Beta}(1,1)\)</span>), and a point hypothesis <span class="math inline">\(\theta_c = 0.5\)</span>, we just have to calculate the prior and posterior probability of the critical value <span class="math inline">\(\theta_c = 0.5\)</span>:</p>
<div class="sourceCode" id="cb518"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb518-1"><a href="ch-03-05-Bayesian-testing-comparison.html#cb518-1"></a><span class="co"># point-value of interest</span></span>
<span id="cb518-2"><a href="ch-03-05-Bayesian-testing-comparison.html#cb518-2"></a>theta_star &lt;-<span class="st"> </span><span class="fl">0.5</span></span>
<span id="cb518-3"><a href="ch-03-05-Bayesian-testing-comparison.html#cb518-3"></a><span class="co"># posterior probability in nesting model</span></span>
<span id="cb518-4"><a href="ch-03-05-Bayesian-testing-comparison.html#cb518-4"></a>posterior_theta_star &lt;-<span class="st"> </span><span class="kw">dbeta</span>(theta_star, <span class="dv">8</span>, <span class="dv">18</span>)</span>
<span id="cb518-5"><a href="ch-03-05-Bayesian-testing-comparison.html#cb518-5"></a><span class="co"># prior probability in nesting model</span></span>
<span id="cb518-6"><a href="ch-03-05-Bayesian-testing-comparison.html#cb518-6"></a>prior_theta_star &lt;-<span class="st"> </span><span class="kw">dbeta</span>(theta_star, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb518-7"><a href="ch-03-05-Bayesian-testing-comparison.html#cb518-7"></a><span class="co"># Bayes factor (using Savage-Dickey)</span></span>
<span id="cb518-8"><a href="ch-03-05-Bayesian-testing-comparison.html#cb518-8"></a>BF_<span class="dv">01</span> &lt;-<span class="st"> </span>posterior_theta_star <span class="op">/</span><span class="st"> </span>prior_theta_star</span>
<span id="cb518-9"><a href="ch-03-05-Bayesian-testing-comparison.html#cb518-9"></a>BF_<span class="dv">01</span></span></code></pre></div>
<pre><code>## [1] 0.5157351</code></pre>
<p>This is very minor evidence in favor of the alternative model (Bayes factor <span class="math inline">\(\text{BF}_{10} \approx 1.94\)</span>). We would not like to draw any (strong) categorical conclusions from this result regarding the question of whether the coin might be fair. Figure <a href="ch-03-05-Bayesian-testing-comparison.html#fig:ch-03-07-hypothesis-testing-Bayes-SD-24-7">11.6</a> also shows the relation between prior and posterior at the point-value of interest.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch-03-07-hypothesis-testing-Bayes-SD-24-7"></span>
<img src="I2DA_files/figure-html/ch-03-07-hypothesis-testing-Bayes-SD-24-7-1.png" alt="Illustration of the Savage-Dickey method of Bayes factor computation for the 24/7 case." width="672" />
<p class="caption">
Figure 11.6: Illustration of the Savage-Dickey method of Bayes factor computation for the 24/7 case.
</p>
</div>
</div>
<div id="example-simon-task-1" class="section level4">
<h4><span class="header-section-number">11.4.1.2</span> Example: Simon task</h4>
<p>In the previous 24/7 example, using the Savage-Dickey method was particularly easy because we know a closed-form solution of the precise posterior, so that we could easily calculate the posterior for the critical value without further ado.
When this is not the case, like in the application to the Simon task data, we have to obtain an estimate for the posterior density at the critical value, here: <span class="math inline">\(\delta = 0\)</span>, from the posterior samples which we obtain from sampling, as we did earlier in this chapter (using Stan).
An approximate method for obtaining this value is implemented in the <code>polspline</code> package (using polynomial splines to approximate the posterior curve).</p>
<div class="sourceCode" id="cb520"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb520-1"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-1"></a><span class="co"># extract the samples for the delta parameter</span></span>
<span id="cb520-2"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-2"></a><span class="co">#   from the earlier Stan fit</span></span>
<span id="cb520-3"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-3"></a>delta_samples &lt;-<span class="st"> </span>tidy_draws_tt2 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb520-4"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-4"></a><span class="st">  </span><span class="kw">filter</span>(Parameter <span class="op">==</span><span class="st"> &quot;delta&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb520-5"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-5"></a><span class="st">  </span><span class="kw">pull</span>(value)</span>
<span id="cb520-6"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-6"></a></span>
<span id="cb520-7"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-7"></a><span class="co"># estimating the posterior density at delta = 0 with polynomial splines</span></span>
<span id="cb520-8"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-8"></a>fit.posterior &lt;-<span class="st"> </span>polspline<span class="op">::</span><span class="kw">logspline</span>(delta_samples)</span>
<span id="cb520-9"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-9"></a>posterior_delta_null &lt;-<span class="st"> </span>polspline<span class="op">::</span><span class="kw">dlogspline</span>(<span class="dv">0</span>, fit.posterior)</span>
<span id="cb520-10"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-10"></a></span>
<span id="cb520-11"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-11"></a><span class="co"># computing the prior density of the point-value of interest</span></span>
<span id="cb520-12"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-12"></a><span class="co">#   [NB: the prior on delta was a standard normal]</span></span>
<span id="cb520-13"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-13"></a>prior_delta_null &lt;-<span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>) </span>
<span id="cb520-14"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-14"></a></span>
<span id="cb520-15"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-15"></a><span class="co"># compute BF via Savage-Dickey</span></span>
<span id="cb520-16"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-16"></a>BF_delta_null =<span class="st"> </span>posterior_delta_null <span class="op">/</span><span class="st"> </span>prior_delta_null</span>
<span id="cb520-17"><a href="ch-03-05-Bayesian-testing-comparison.html#cb520-17"></a>BF_delta_null</span></code></pre></div>
<pre><code>## [1] 9.901836e-16</code></pre>
<p>We conclude from this result that the data provide extremely strong evidence against the null model, which assumes that <span class="math inline">\(\delta = 0\)</span>, when compared to an alternative model <span class="math inline">\(M_1\)</span>, which assumes that <span class="math inline">\(\delta \sim \mathcal{N}(0,1)\)</span> in the prior.</p>
<!-- exercise 2 -->
<!-- Taken from the prep exam (IDA-prep-exam-02.pages.pdf) -->
<div class="exercises">
<p><strong>Exercise 11.3: Bayes factors with the Savage-Dickey method</strong></p>
<p>Look at the plot below. You see the prior distribution and the posterior distribution over the <span class="math inline">\(\delta\)</span> parameter in a Bayesian <span class="math inline">\(t\)</span>-test model. We are going to use this plot to determine (roughly) the Bayes factor of two models: the full Bayesian <span class="math inline">\(t\)</span>-test model, and a model nested under this full model which assumes that <span class="math inline">\(\delta = 0\)</span>.</p>
<p><img src="I2DA_files/figure-html/unnamed-chunk-343-1.png" width="384" style="display: block; margin: auto;" /></p>
<ol style="list-style-type: lower-alpha">
<li>Describe in intuitive terms what it means for a Bayesian model to be nested under another model. It is sufficient to neglect the conditions on the priors.</li>
</ol>
<div class="collapsibleSolution">
<button class="trigger">
Solution
</button>
<div class="content">
<p>A model nested under another model fixes certain parameters to specific values which may take on more than one value in the nesting model.</p>
</div>
</div>
<ol start="2" style="list-style-type: lower-alpha">
<li>Write down the formula for the Bayes factor in favor of the null model (where <span class="math inline">\(\delta = 0\)</span>) over the full model using the Savage-Dickey theorem.</li>
</ol>
<div class="collapsibleSolution">
<button class="trigger">
Solution
</button>
<div class="content">
<p><span class="math inline">\(BF_{01}=\frac{P(\delta = 0 \mid D, M_1)}{P(\delta = 0 \mid M_1)}\)</span>.</p>
</div>
</div>
<ol start="3" style="list-style-type: lower-alpha">
<li>Give a natural language paraphrase of the formula you wrote down above.</li>
</ol>
<div class="collapsibleSolution">
<button class="trigger">
Solution
</button>
<div class="content">
<p>The Bayes factor in favor of the embedded null model over the embedding model is given by the posterior density at <span class="math inline">\(\delta = 0\)</span> under the nesting model divided by the prior in the nesting model at <span class="math inline">\(\delta = 0\)</span>.</p>
</div>
</div>
<ol start="4" style="list-style-type: lower-alpha">
<li>Now look at the plot above. Give your approximate guess of the Bayes factor in favor of the null model in terms of a fraction of whole integers (something like: <span class="math inline">\(\frac{4}{3}\)</span> or <span class="math inline">\(\frac{27}{120}\)</span>, …).</li>
</ol>
<div class="collapsibleSolution">
<button class="trigger">
Solution
</button>
<div class="content">
<p><img src="I2DA_files/figure-html/unnamed-chunk-344-1.png" width="384" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(BF_{01} \approx \frac{5}{2}\)</span> (see plot above).</p>
</div>
</div>
<ol start="5" style="list-style-type: lower-alpha">
<li>Formulate a conclusion to be drawn from this numerical result about the research hypothesis that the mean of the two groups compared here is identical. Write one concise sentence like you would in a research paper.</li>
</ol>
<div class="collapsibleSolution">
<button class="trigger">
Solution
</button>
<div class="content">
<p>A BF of <span class="math inline">\(\frac{5}{2}\)</span> is mild evidence in favor of the null model, but conventionally not considered strong enough to be particularly noteworthy.</p>
</div>
</div>
</div>
</div>
<div id="excursion-calculating-the-bayes-factor-precisely" class="section level4">
<h4><span class="header-section-number">11.4.1.3</span> [Excursion:] Calculating the Bayes factor precisely</h4>
<p><span style="color:firebrick">under construction</span></p>
<!-- Since this last numerical result relies on some computational approximation (namely in the estimation of the posterior density at $\delta = 0$ using polynomial splines approximation), we can also make use of the fact that the $t$-test model we used here allows for a direct mathematical computation of the Bayes factor. -->
</div>
</div>
<div id="ch-03-07-hypothesis-testing-Bayes-encompassing-models" class="section level3">
<h3><span class="header-section-number">11.4.2</span> Encompassing models</h3>
<p>The Savage-Dickey method can be generalized to also cover interval-valued hypotheses.
The previous literature has focused on inequality-based intervals/hypotheses (like <span class="math inline">\(\theta \ge 0.5\)</span>) <span class="citation">(Klugkist, Kato, and Hoijtink <a href="#ref-KlugkistKato2005:Bayesian-model" role="doc-biblioref">2005</a>; Wetzels, Grasman, and Wagenmakers <a href="#ref-WetzelsGrasman2010:An-encompassing" role="doc-biblioref">2010</a>; Oh <a href="#ref-Oh2014:Bayesian-compar" role="doc-biblioref">2014</a>)</span>, but the method also applies to ROPE-d hypotheses.
The advantage of this method is that we can use samples from the posterior distribution to approximate integrals, which is more robust than having to estimate point-values of posterior density.</p>
<p>Following previous work <span class="citation">(Klugkist, Kato, and Hoijtink <a href="#ref-KlugkistKato2005:Bayesian-model" role="doc-biblioref">2005</a>; Wetzels, Grasman, and Wagenmakers <a href="#ref-WetzelsGrasman2010:An-encompassing" role="doc-biblioref">2010</a>; Oh <a href="#ref-Oh2014:Bayesian-compar" role="doc-biblioref">2014</a>)</span>, the main idea is to use so-called <strong>encompassing priors</strong>. Let <span class="math inline">\(\theta\)</span> be a single parameter of interest (for simplicity), which can in principle take on any real value. We are interested in the interval-based hypotheses:</p>
<ul>
<li><span class="math inline">\(H_0 \colon \theta \in I_0\)</span>, and</li>
<li><span class="math inline">\(H_a \colon \theta \not \in I_{0}\)</span></li>
</ul>
<p>where <span class="math inline">\(I_{0}\)</span> is some possibly half-open interval.</p>
<p>An <strong>encompassing model</strong> <span class="math inline">\(M_e\)</span> has a suitable likelihood function <span class="math inline">\(P_{M_e}(D \mid \theta, \omega)\)</span> (where <span class="math inline">\(\omega\)</span> is a vector of other parameters besides the parameter <span class="math inline">\(\theta\)</span> of interest). It also defines a prior <span class="math inline">\(P_{M_e}(\theta, \omega)\)</span>, which does not already rule out <span class="math inline">\(H_{0}\)</span> or <span class="math inline">\(H_{a}\)</span>.</p>
<p>Generalizing over the Savage-Dickey approach, we construct <em>two</em> models, one for each hypothesis, <em>both</em> of which are nested under the encompassing model:</p>
<ul>
<li><span class="math inline">\(M_0\)</span> has prior <span class="math inline">\(P_{M_0}(\theta, \omega) = P_{M_e}(\theta, \omega \mid \theta \in [a;b])\)</span></li>
<li><span class="math inline">\(M_a\)</span> has prior <span class="math inline">\(P_{M_a}(\theta, \omega) = P_{M_e}(\theta, \omega \mid \theta \not \in [a;b])\)</span></li>
</ul>
<p>Both <span class="math inline">\(M_0\)</span> and <span class="math inline">\(M_a\)</span> have the same likelihood function as <span class="math inline">\(M_e\)</span>, which is why we drop the model index for better readability in the following.</p>
<p>Figure <a href="ch-03-05-Bayesian-testing-comparison.html#fig:ch-03-07-hypothesis-testing-Bayes-encompassing-prior">11.7</a> shows an example of the priors of an encompassing model for two nested models based on a ROPE-d hypothesis testing approach.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch-03-07-hypothesis-testing-Bayes-encompassing-prior"></span>
<img src="I2DA_files/figure-html/ch-03-07-hypothesis-testing-Bayes-encompassing-prior-1.png" alt="Example of the prior of an encompassing model and the priors of two models nested under it." width="672" />
<p class="caption">
Figure 11.7: Example of the prior of an encompassing model and the priors of two models nested under it.
</p>
</div>
<div class="mathstuff">

<div class="theorem">
<p><span id="thm:BF-ROPED-hypotheses" class="theorem"><strong>Theorem 11.2  </strong></span>Fix a Bayesian model <span class="math inline">\(M\)</span> (the encompassing model) with prior <span class="math inline">\(P_M(\theta, \omega)\)</span> and likelihood function <span class="math inline">\(P_M(D \mid \theta, \omega)\)</span>, where <span class="math inline">\(\theta\)</span> is the parameter of interest and <span class="math inline">\(\omega\)</span> is a vector of other (nuisance) parameters. Assume that the priors over <span class="math inline">\(\theta\)</span> are independent of the nuisance parameters <span class="math inline">\(\omega\)</span>. For an interval-valued hypothesis <span class="math inline">\(H_0 \colon \theta \in I_0\)</span>, the Bayes factor in favor of this hypothesis over its negation <span class="math inline">\(H_a \colon \theta \not \in I_0\)</span> can be expressed as:</p>
<p><span class="math display">\[ 
\begin{aligned}
\text {BF}_{01} &amp; = \frac{\text{posterior-odds of } H_0}{\text{prior-odds of } H_0}  \\
&amp; = \frac{P_M(\theta \in I_0 \mid D)}{P_M(\theta \not \in I_0 \mid D)} \frac{P_M(\theta \not \in I_0)}{P_M(\theta \in I_0)}
\end{aligned}
\]</span></p>
</div>
<div class="collapsibleProof">
<button class="trigger">
Show proof.
</button>
<div class="content">

<div class="proof">
 <span class="proof"><em>Proof. </em></span> TBD
</div>
<p> </p>
</div>
</div>
</div>
<div id="example-247-2" class="section level4">
<h4><span class="header-section-number">11.4.2.1</span> Example: 24/7</h4>
<p>The Bayes factor using the ROPE-d method to compute the interval-valued hypothesis <span class="math inline">\(\theta = 0.5 \pm \epsilon\)</span> is:</p>
<div class="sourceCode" id="cb522"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb522-1"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-1"></a><span class="co"># set the scene</span></span>
<span id="cb522-2"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-2"></a>theta_null &lt;-<span class="st"> </span><span class="fl">0.5</span></span>
<span id="cb522-3"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-3"></a>epsilon &lt;-<span class="st"> </span><span class="fl">0.01</span>                 <span class="co"># epsilon margin for ROPE</span></span>
<span id="cb522-4"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-4"></a>upper &lt;-<span class="st"> </span>theta_null <span class="op">+</span><span class="st"> </span>epsilon   <span class="co"># upper bound of ROPE</span></span>
<span id="cb522-5"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-5"></a>lower &lt;-<span class="st"> </span>theta_null <span class="op">-</span><span class="st"> </span>epsilon   <span class="co"># lower bound of ROPE</span></span>
<span id="cb522-6"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-6"></a><span class="co"># calculate prior odds of the ROPE-d hypothesis</span></span>
<span id="cb522-7"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-7"></a>prior_of_hypothesis &lt;-<span class="st"> </span><span class="kw">pbeta</span>(upper, <span class="dv">1</span>, <span class="dv">1</span>) <span class="op">-</span><span class="st"> </span><span class="kw">pbeta</span>(lower, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb522-8"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-8"></a>prior_odds &lt;-<span class="st"> </span>prior_of_hypothesis <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>prior_of_hypothesis)</span>
<span id="cb522-9"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-9"></a><span class="co"># calculate posterior odds of the ROPE-d hypothesis</span></span>
<span id="cb522-10"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-10"></a>posterior_of_hypothesis &lt;-<span class="st"> </span><span class="kw">pbeta</span>(upper, <span class="dv">8</span>, <span class="dv">18</span>) <span class="op">-</span><span class="st"> </span><span class="kw">pbeta</span>(lower, <span class="dv">8</span>, <span class="dv">18</span>)</span>
<span id="cb522-11"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-11"></a>posterior_odds &lt;-<span class="st"> </span>posterior_of_hypothesis <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>posterior_of_hypothesis)</span>
<span id="cb522-12"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-12"></a><span class="co"># calculate Bayes factor</span></span>
<span id="cb522-13"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-13"></a>bf_ROPEd_hypothesis &lt;-<span class="st"> </span>posterior_odds <span class="op">/</span><span class="st"> </span>prior_odds</span>
<span id="cb522-14"><a href="ch-03-05-Bayesian-testing-comparison.html#cb522-14"></a>bf_ROPEd_hypothesis</span></code></pre></div>
<pre><code>## [1] 0.5133012</code></pre>
<p>This is unnoteworthy evidence in favor of the alternative hypothesis (Bayes factor <span class="math inline">\(\text{BF}_{10} \approx 1.95\)</span>).
Notice that the reason why the alternative hypothesis does not fare better in this analysis is because it also includes a lot of parameter values (<span class="math inline">\(\theta &gt; 0.5\)</span>) which explain the observed data even more poorly than the values included in the null hypothesis.</p>
<p>We can also use this approach to test the directional hypothesis that <span class="math inline">\(\theta &lt; 0.5\)</span>.</p>
<div class="sourceCode" id="cb524"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb524-1"><a href="ch-03-05-Bayesian-testing-comparison.html#cb524-1"></a><span class="co"># calculate prior odds of the ROPE-d hypothesis</span></span>
<span id="cb524-2"><a href="ch-03-05-Bayesian-testing-comparison.html#cb524-2"></a><span class="co">#   [trivial in the case at hand, but just to be explicit]</span></span>
<span id="cb524-3"><a href="ch-03-05-Bayesian-testing-comparison.html#cb524-3"></a>prior_of_hypothesis &lt;-<span class="st"> </span><span class="kw">pbeta</span>(<span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">1</span>) </span>
<span id="cb524-4"><a href="ch-03-05-Bayesian-testing-comparison.html#cb524-4"></a>prior_odds &lt;-<span class="st"> </span>prior_of_hypothesis <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>prior_of_hypothesis)</span>
<span id="cb524-5"><a href="ch-03-05-Bayesian-testing-comparison.html#cb524-5"></a></span>
<span id="cb524-6"><a href="ch-03-05-Bayesian-testing-comparison.html#cb524-6"></a><span class="co"># calculate posterior odds of the ROPE-d hypothesis</span></span>
<span id="cb524-7"><a href="ch-03-05-Bayesian-testing-comparison.html#cb524-7"></a>posterior_of_hypothesis &lt;-<span class="st"> </span><span class="kw">pbeta</span>(<span class="fl">0.5</span>, <span class="dv">8</span>, <span class="dv">18</span>)</span>
<span id="cb524-8"><a href="ch-03-05-Bayesian-testing-comparison.html#cb524-8"></a>posterior_odds &lt;-<span class="st"> </span>posterior_of_hypothesis <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>posterior_of_hypothesis)</span>
<span id="cb524-9"><a href="ch-03-05-Bayesian-testing-comparison.html#cb524-9"></a><span class="co"># calculate Bayes factor</span></span>
<span id="cb524-10"><a href="ch-03-05-Bayesian-testing-comparison.html#cb524-10"></a>bf_directional_hypothesis &lt;-<span class="st"> </span>posterior_odds <span class="op">/</span><span class="st"> </span>prior_odds</span>
<span id="cb524-11"><a href="ch-03-05-Bayesian-testing-comparison.html#cb524-11"></a>bf_directional_hypothesis</span></code></pre></div>
<pre><code>## [1] 45.20512</code></pre>
<p>Here we should conclude that the data provide substantial evidence in favor of the assumption that the coin is biased towards tails, when compared against the alternative assumption that it is biased towards heads.
If the dichotomy is “heads bias vs tails bias” the data clearly tilts our beliefs towards the “tails bias” possibility.</p>
</div>
<div id="example-simon-task-2" class="section level4">
<h4><span class="header-section-number">11.4.2.2</span> Example: Simon task</h4>
<p>Using posterior samples, we can also do similar calculations for the Simon task.
Let’s first approximate the Bayes factor in favor of the ROPE-d hypothesis <span class="math inline">\(\delta = 0 \pm 0.1\)</span> when compared against the alternative hypothesis <span class="math inline">\(\delta \not \in 0 \pm 0.1\)</span>.</p>
<div class="sourceCode" id="cb526"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb526-1"><a href="ch-03-05-Bayesian-testing-comparison.html#cb526-1"></a><span class="co"># estimating the BF for ROPE-d hypothesis with encompassing priors</span></span>
<span id="cb526-2"><a href="ch-03-05-Bayesian-testing-comparison.html#cb526-2"></a>delta_null &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb526-3"><a href="ch-03-05-Bayesian-testing-comparison.html#cb526-3"></a>epsilon &lt;-<span class="st"> </span><span class="fl">0.1</span>                  <span class="co"># epsilon margin for ROPE</span></span>
<span id="cb526-4"><a href="ch-03-05-Bayesian-testing-comparison.html#cb526-4"></a>upper &lt;-<span class="st"> </span>delta_null <span class="op">+</span><span class="st"> </span>epsilon   <span class="co"># upper bound of ROPE</span></span>
<span id="cb526-5"><a href="ch-03-05-Bayesian-testing-comparison.html#cb526-5"></a>lower &lt;-<span class="st"> </span>delta_null <span class="op">-</span><span class="st"> </span>epsilon   <span class="co"># lower bound of ROPE</span></span>
<span id="cb526-6"><a href="ch-03-05-Bayesian-testing-comparison.html#cb526-6"></a><span class="co"># calculate prior odds of the ROPE-d hypothesis</span></span>
<span id="cb526-7"><a href="ch-03-05-Bayesian-testing-comparison.html#cb526-7"></a>prior_of_hypothesis &lt;-<span class="st"> </span><span class="kw">pnorm</span>(upper, <span class="dv">0</span>, <span class="dv">1</span>) <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(lower, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb526-8"><a href="ch-03-05-Bayesian-testing-comparison.html#cb526-8"></a>prior_odds &lt;-<span class="st"> </span>prior_of_hypothesis <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>prior_of_hypothesis)</span>
<span id="cb526-9"><a href="ch-03-05-Bayesian-testing-comparison.html#cb526-9"></a><span class="co"># calculate posterior odds of the ROPE-d hypothesis</span></span>
<span id="cb526-10"><a href="ch-03-05-Bayesian-testing-comparison.html#cb526-10"></a>posterior_of_hypothesis &lt;-<span class="st"> </span><span class="kw">mean</span>( lower <span class="op">&lt;=</span><span class="st"> </span>delta_samples <span class="op">&amp;</span><span class="st"> </span>delta_samples <span class="op">&lt;=</span><span class="st"> </span>upper )</span>
<span id="cb526-11"><a href="ch-03-05-Bayesian-testing-comparison.html#cb526-11"></a>posterior_odds &lt;-<span class="st"> </span>posterior_of_hypothesis <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>posterior_of_hypothesis)</span>
<span id="cb526-12"><a href="ch-03-05-Bayesian-testing-comparison.html#cb526-12"></a><span class="co"># calculate Bayes factor</span></span>
<span id="cb526-13"><a href="ch-03-05-Bayesian-testing-comparison.html#cb526-13"></a>bf_ROPEd_hypothesis &lt;-<span class="st"> </span>posterior_odds <span class="op">/</span><span class="st"> </span>prior_odds</span>
<span id="cb526-14"><a href="ch-03-05-Bayesian-testing-comparison.html#cb526-14"></a>bf_ROPEd_hypothesis</span></code></pre></div>
<pre><code>## [1] 0</code></pre>
<p>This is overwhelming evidence against the ROPE-d hypothesis that <span class="math inline">\(\delta = 0 \pm 0.1\)</span>.</p>
<p>We can also use this approach to test the directional hypothesis that <span class="math inline">\(\delta &gt; 0.5\)</span>.</p>
<div class="sourceCode" id="cb528"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb528-1"><a href="ch-03-05-Bayesian-testing-comparison.html#cb528-1"></a><span class="co"># calculate prior odds of the ROPE-d hypothesis</span></span>
<span id="cb528-2"><a href="ch-03-05-Bayesian-testing-comparison.html#cb528-2"></a><span class="co">#   [trivial in the case at hand, but just to be explicit]</span></span>
<span id="cb528-3"><a href="ch-03-05-Bayesian-testing-comparison.html#cb528-3"></a>prior_of_hypothesis &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb528-4"><a href="ch-03-05-Bayesian-testing-comparison.html#cb528-4"></a>prior_odds &lt;-<span class="st"> </span>prior_of_hypothesis <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>prior_of_hypothesis)</span>
<span id="cb528-5"><a href="ch-03-05-Bayesian-testing-comparison.html#cb528-5"></a><span class="co"># calculate posterior odds of the ROPE-d hypothesis</span></span>
<span id="cb528-6"><a href="ch-03-05-Bayesian-testing-comparison.html#cb528-6"></a>posterior_of_hypothesis &lt;-<span class="st"> </span><span class="kw">mean</span>( delta_samples <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.5</span> )</span>
<span id="cb528-7"><a href="ch-03-05-Bayesian-testing-comparison.html#cb528-7"></a>posterior_odds &lt;-<span class="st"> </span>posterior_of_hypothesis <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>posterior_of_hypothesis)</span>
<span id="cb528-8"><a href="ch-03-05-Bayesian-testing-comparison.html#cb528-8"></a><span class="co"># calculate Bayes factor</span></span>
<span id="cb528-9"><a href="ch-03-05-Bayesian-testing-comparison.html#cb528-9"></a>bf_directional_hypothesis &lt;-<span class="st"> </span>posterior_odds <span class="op">/</span><span class="st"> </span>prior_odds</span>
<span id="cb528-10"><a href="ch-03-05-Bayesian-testing-comparison.html#cb528-10"></a>bf_directional_hypothesis</span></code></pre></div>
<pre><code>## [1] Inf</code></pre>
<p>Modulo imprecision induced by sampling, we see that the evidence in favor of the directional hypothesis <span class="math inline">\(\delta &gt; 0.5\)</span> is immense.</p>
<!-- exercise 3 -->
<div class="exercises">
<p><strong>Exercise 11.4: True or False?</strong></p>
<p>Decide for the following statements whether they are true or false.</p>
<ol style="list-style-type: lower-alpha">
<li>An encompassing model for addressing ROPE-d hypotheses needs two competing models nested under it.</li>
<li>A Bayes factor of <span class="math inline">\(BF_{01} = 20\)</span> constitutes strong evidence in favor of the alternative hypothesis.</li>
<li>A Bayes factor of <span class="math inline">\(BF_{10} = 20\)</span> constitutes minor evidence in favor of the alternative hypothesis.</li>
<li>We can compute the BF in favor of the alternative hypothesis with <span class="math inline">\(BF_{10} = \frac{1}{BF_{01}}\)</span>.</li>
</ol>
<div class="collapsibleSolution">
<button class="trigger">
Solution
</button>
<div class="content">
<p>Statements a. and d. are correct.</p>
</div>
</div>
</div>

<div id="refs" class="references">
<div>
<p>Anscombe, F. J. 1973. “Graphs in Statistical Analysis.” <em>The American Statistician</em> 27 (1): 17–21. <a href="https://doi.org/10.2307/2682899">https://doi.org/10.2307/2682899</a>.</p>
</div>
<div>
<p>Box, George E. P. 1979. “Robustness in the Strategy of Scientific Model Building.” In <em>Robustness in Statistics</em>, edited by R. L. Launer and G. N. Wilkinson, 201–36. Cambridge, MA: Academic Press.</p>
</div>
<div>
<p>Burkner, Paul-Christian. 2017. “brms: An R Package for Bayesian Multilevel Models Using Stan.” <em>Journal of Statistical Software</em> 80 (1): 1–28. <a href="https://doi.org/10.18637/jss.v080.i01">https://doi.org/10.18637/jss.v080.i01</a>.</p>
</div>
<div>
<p>Burnham, Kenneth P., and David R. Anderson. 2002. <em>Model Selection and Multimodel Inference: A Practical Information-Theoretic Approach</em>. Berlin: Springer.</p>
</div>
<div>
<p>Carpenter, Bob, Andrew Gelman, Matthew D. Hoffman, Daniel Lee, Ben Goodrich, Michael Betancourt, Marcus Brubaker, Jiqiang Guo, Peter Li, and Allen Riddell. 2017. “Stan: A Probabilistic Programming Language.” <em>Journal of Statistical Software</em> 76 (1). <a href="https://doi.org/10.18637/jss.v076.i01">https://doi.org/10.18637/jss.v076.i01</a>.</p>
</div>
<div>
<p>Goodman, Noah D, and Andreas Stuhlmüller. 2014. “The Design and Implementation of Probabilistic Programming Languages.” <a href="http://dippl.org">http://dippl.org</a>.</p>
</div>
<div>
<p>Gronau, Quentin F., Alexander Ly, and Eric-Jan Wagenmakers. 2019. “Informed Bayesian <em>T</em>-Tests.” <em>The American Statistician</em>.</p>
</div>
<div>
<p>Gronau, Quentin F., Alexandra Sarafoglou, Dora Matzke, Alexander Ly, Udo Boehm, Maarten Marsman, David S. Leslie, Jonathan J. Forster, Eric-Jan Wagenmakers, and Helen Steingroever. 2017. “A Tutorial on Bridge Sampling.” <em>Journal of Mathematical Psychology</em> 81: 80–97.</p>
</div>
<div>
<p>Halpern, Joseph Y. 2003. <em>Reasoning about Uncertainty</em>. MIT Press.</p>
</div>
<div>
<p>Klugkist, Irene, Bernet Kato, and Herbert Hoijtink. 2005. “Bayesian Model Selection Using Encompassing Priors.” <em>Statistica Neelandica</em> 59 (1): 57–69.</p>
</div>
<div>
<p>Kruschke, John. 2015. <em>Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan</em>. Academic Press.</p>
</div>
<div>
<p>Lee, Michael D., and Eric-Jan Wagenmakers. 2014. <em>Bayesian cognitive modeling: A practical course</em>. Cambridge university press.</p>
</div>
<div>
<p>Mithat Gonen, Yonggang Lu &amp; Peter H. Westfall, Wesley O. Johnson. 2005. “The Bayesian Two-Sample <em>T</em>-Test.” <em>The American Statistician</em> 59 (3): 252–57. <a href="https://doi.org/10.1198/000313005X55233">https://doi.org/10.1198/000313005X55233</a>.</p>
</div>
<div>
<p>Myung, In Jae. 2003. “Tutorial on Maximum Likelihood Estimation.” <em>Journal of Mathematical Psychology</em> 47: 90–100.</p>
</div>
<div>
<p>Oh, Man-Suk. 2014. “Bayesian Comparison of Models with Inequality and Equality Constraints.” <em>Statistics and Probability Letters</em> 84: 176–82.</p>
</div>
<div>
<p>R Core Team. 2018. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/">https://www.R-project.org/</a>.</p>
</div>
<div>
<p>Rouder, Jeffrey N., and Richard D. Morey. 2012. “Default Bayes Factors for Model Selection in Regression.” <em>Multivariate Behavioral Research</em> 47 (6): 877–903.</p>
</div>
<div>
<p>Rouder, Jeffrey N., Paul l. Speckman, Dongchu Sun, Richard D. Morey, and Geoffrey Iverson. 2009. “Bayesian <em>T</em> Tests for Accepting and Rejecting the Null Hypothesis.” <em>Psychonomic Bulletin &amp; Review</em> 16 (2): 225–37.</p>
</div>
<div>
<p>Tufte, Edward. 1983. <em>The Visual Display of Quantitative Information</em>. Graphics Press.</p>
</div>
<div>
<p>Wagenmakers, Eric-Jan, and Simon Farrell. 2004. “AIC Model Selection Using Akaike Weights.” <em>Psychonomic Bulletin &amp; Review</em> 11 (1): 192–96.</p>
</div>
<div>
<p>Wetzels, Ruud, Raoul P. P. P. Grasman, and Eric-Jan Wagenmakers. 2010. “An Encompassing Prior Generalization of the Savage–Dickey Density Ratio.” <em>Computational Statistics and Data Analysis</em> 54: 2094–2102.</p>
</div>
<div>
<p>Wickham, Hadley. 2010. “A Layered Grammar of Graphics.” <em>Journal of Computational and Graphical Statistics</em> 19 (1): 3–28.</p>
</div>
<div>
<p>———. 2014. “Tidy Data.” <em>Journal of Statistical Software</em> 59 (10).</p>
</div>
<div>
<p>———. 2017. <em>tidyverse: Easily Install and Load the ’Tidyverse’</em>. <a href="https://CRAN.R-project.org/package=tidyverse">https://CRAN.R-project.org/package=tidyverse</a>.</p>
</div>
<div>
<p>Wickham, Hadley, and Garrett Grolemund. 2016. <em>R for Data Science: Import, Tidy, Transform, Visualize, and Model Data</em>. O’Reilly Media, Inc.</p>
</div>
</div>
</div>
</div>
</div>
<!-- </div> -->





























































<h3>References</h3>
<div id="refs" class="references">
<div id="ref-KlugkistKato2005:Bayesian-model">
<p>Klugkist, Irene, Bernet Kato, and Herbert Hoijtink. 2005. “Bayesian Model Selection Using Encompassing Priors.” <em>Statistica Neelandica</em> 59 (1): 57–69.</p>
</div>
<div id="ref-Oh2014:Bayesian-compar">
<p>Oh, Man-Suk. 2014. “Bayesian Comparison of Models with Inequality and Equality Constraints.” <em>Statistics and Probability Letters</em> 84: 176–82.</p>
</div>
<div id="ref-WetzelsGrasman2010:An-encompassing">
<p>Wetzels, Ruud, Raoul P. P. P. Grasman, and Eric-Jan Wagenmakers. 2010. “An Encompassing Prior Generalization of the Savage–Dickey Density Ratio.” <em>Computational Statistics and Data Analysis</em> 54: 2094–2102.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ch-03-05-Bayes-testing-estimation.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
