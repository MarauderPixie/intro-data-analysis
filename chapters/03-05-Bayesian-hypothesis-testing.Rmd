# Bayesian hypothesis testing {#ch-03-07-hypothesis-testing-Bayes}

<hr>

The goal of this chapter is to introduce common Bayesian methods of testing what we could call _statistical hypotheses_.
A statistical hypothesis is a hypothesis about a particular model parameter or a set of model parameters.
Most often, such a hypothesis concerns one parameter, and the assumption in question is that this parameter takes on a specific value, or some value from a specific interval.
Henceforth, we speak just of a "hypothesis" even though we mean a specific hypothesis about particular model parameters.
For example, we might be interested in what we will call a _point-valued hypothesis_, stating that the value of parameter $\theta$ is fixed to a specific value $\theta = \theta^*$. 
Section \@ref(ch-03-07-hypothesis-testing-Bayes-hypotheses) introduces different kinds of statistical hypotheses in more detail.

Given a statistical hypothesis about parameter values, we are interested in "testing" it, i.e., checking if observed data tells us whether or not this hypothesis is credible.
The term "testing" in this context really comes from non-Bayesian approaches, which we will only cover much later in Chapter \@ref(ch-05-01-frequentist-hypothesis-testing).
We will speak of "Bayesian hypothesis testing" for simplicity but, actually, it would be better to speak of "Bayesian inferences regarding the plausibility of the given hypotheses".
As, obviously, this is a mouthful, we just say "testing" here.

We consider two conceptually distinct approaches to addressing, that is "testing", these different types of hypotheses, namely:

1. **Estimation-based testing** considers just one model. It uses the observed data $D_\text{obs}$ to retrieve posterior beliefs $P(\theta \mid D_{\text{obs}})$ and checks whether, _a posteriori_, our hypothesis is credible.
2. **Comparison-based testing** uses Bayesian model comparison, in the form of Bayes factors, to compare two models, namely one model that assumes that the hypothesis in question is true, and one model that assumes that the complement of the hypothesis is true.

The main differences between these two approaches is that estimation-based hypothesis testing is simpler (conceptually and computationally), but less informative than comparison-based hypothesis testing. 
However, for special but common use cases, like testing directional hypotheses, there are efficient methods of performing comparison-based hypothesis testing, and this chapter will introduce some of them. 

```{block, type='infobox'}
The learning goals for this chapter are:

- understand the notion of a _statistical hypothesis_ 
  - point-valued, ROPE-d and directional hypotheses
  - complement / alternative hypothesis
- be able to apply Bayesian hypothesis testing to (simple) case studies
- understand and be able to apply the Savage-Dickey method (and its extension to interval-based hypotheses)
```

## More on statistical hypotheses {#ch-03-07-hypothesis-testing-Bayes-hypotheses}

Given a model $M$ with parameter vector $\theta$, a **statistical hypothesis**, in the sense entertained here, is a assumption about which values of $\theta$ are true.
For example, we might be interested in the question of whether a particular coin is fair.
We consider the Binomial model, which contains the coin bias parameter $\theta_c$.
Informal assumptions about the coin's bias can then be translated into a concrete questions about values of $\theta_{c}$.

This chapter considers three types of statistical hypotheses, which are also represented schematically in Figure  \@ref(fig:03-05-Bayesian-testing-overview-hypotheses). 
While all of the below also applies to discrete parameters and vectors of parameters, the implicit assumption in what follows is that we are dealing with a single continuous parameter. 

1. **Point-valued hypotheses** ask whether it is plausible that the the parameter of relevance is identical to exactly one specific value. For example, in a Binomial model with the coin's bias parameter $\theta_{c}$, a point-valued hypothesis could be that $\theta_c = 0.5$. More generally, we write $\theta = \theta^*$ for a point-valued hypothesis about some (singular) parameter $\theta$. 
2. **ROPE-d hypotheses**, where "ROPE" is short for _region of practical equivalence_, define a small $\epsilon$-region around a point-value of interest, and address the question of whether it is plausible that the parameter value lies inside this interval. For example, suppose that instead of addressing the point-valued hypothesis $\theta_{c} = 0.5$ about a coin's latent bias, we are able (e.g., through prior research or *a priori* conceptual considerations) to specify a reasonable *region of practical equivalence (= ROPE)* around the parameter value of interest. For instance, we might know that a difference of 0.1 in a coins bias really counts as normal slack and negligible for practical purposes. We then address the ROPE-d hypothesis that $\theta_{c} in [0.49, 0.51]$. More generally, we write $\theta \in [\theta^* - \epsilon\ ;\ \theta^* + \epsilon]$, or $\theta = \theta^* \pm \epsilon$ for ROPE-d hypothesis around the pivotal values $\theta^*$.
3. **Directional hypotheses** fix a specific parameter value, as a lower or upper bound and ask whether it is plausible that the parameter's value is bigger or smaller than that fixed value. For example, $\theta_{c} > 0.5$ could be the directional hypothesis that a coin is biased towards heads.

```{r 03-05-Bayesian-testing-overview-hypotheses, echo = F, fig.cap="Three common types of hypotheses achored to a point-value of interest of a parameter."}
knitr::include_graphics("visuals/3-types-hypotheses.png")
```

Ignoring trivial edge cases, both ROPE-d and directional hypotheses are instances of **interval-based hypotheses** in the sense that they they assume that the true value lies in an interval.

The complement of a point-valued hypothesis $\theta = \theta^*$ is the hypothesis that the true value is _not_ equal to the cricical value: $\theta \neq \theta^*$.
The complement of an interval-based hypothesis is the hypothesis that the true parameter value does _not_ lie in the relevant interval.
For example, the complement of the ROPE-d hypothesis $\theta \in [\theta^* - \epsilon\ ;\ \theta^* + \epsilon]$ is that $\theta \not \in [\theta^* - \epsilon\ ;\ \theta^* + \epsilon]$.

In the context of hypothesis testing, in particular frequentist testing (see Chapter \@ref(ch-05-01-frequentist-hypothesis-testing)), we often address the hypothesis to be tested as the **null hypothesis**.
The complement of the null hypothesis is called **alternative hypothesis**.

## Data and models for this chapter

This chapter uses two case studies as running example: the (fictitious) 24/7 coin-flip example, and data from the [Simon task](app-93-data-sets-simon-task).

### 24/7

We will use the same (old) example of binomial data: $k = 7$ heads out of $N = 24$ flips. 
Just as before, we will use the standard binomial model with a flat Beta prior, show below in graphical notation:

```{r ch-03-06-Binomial-Model-repeated, echo = F, fig.cap="The Binomial Model (repeated from before).", out.width = '40%'}
knitr::include_graphics("visuals/binomial-model.png")
```

We are interested in the following hypotheses:

1. **Point-valued**: $\theta_c = 0.5$
2. **ROPE-d** $\theta_c = \in [0.5 - \epsilon; 0.5 + \epsilon]$ with $\epsilon = 0.01$
3. **Directional** $\theta_c < 0.5$

### Simon task

<div style = "float:right; width:20%;">
<img src="visuals/badge-Simon-task.png" alt="badge model comparison">
</div>

The Simon task is a classic experimental design to investigate interference of, intuitively put, task-relevant properties and task-irrelevant properties. 
Chapter \@ref(app-93-data-sets-simon-task) introduces the experiment and the (cleaned) data we analyze here.

```{r, eval = F}
data_simon_cleaned <- read_csv(url('https://raw.githubusercontent.com/michael-franke/intro-data-analysis/master/data_sets/simon-task_cleaned.csv'))
```

```{r echo = F}
# load cleaned data from the Simon task
data_simon_cleaned <- read_csv("data_sets/simon-task_cleaned.csv")
```

The most important columns in this data set for our current purposes are:

- `RT`: The reaction time for each trial.
- `condition`: Whether the trial was a congruent or an incongruent trial.

Concretely, we are interested in comparing the mean reaction times across conditions:

```{r ch-03-05-Bayesian-testing-Simon-data, echo = F, out.width = '80%', fig.cap="Distribution of reaction times of correct answers in the congruent and incongruent condition of the Simon task. Vertical lines indicate the mean of each condition."}
data_simon_cleaned %>% 
  ggplot(aes(x = RT, color = condition, fill = condition)) +
  geom_density(alpha=0.3) +
  geom_vline(
    aes(xintercept = mean_RT, color = condition),
    data = data_simon_cleaned %>% 
      group_by(condition) %>% 
      summarize(
        mean_RT = mean(RT)
      )
    )
```


In order to compare the means of continuous measurements between two groups we will use a so-called **$t$-test model**. (The reason why this is called a "$t$-test model" are historical and will become clear in Chapter \@ref(ch-05-01-frequentist-hypothesis-testing).) 
There are different instances of Bayesian $t$-test models.
Here, we use the one proposed by Gönen et al. [-@GoenenJohnson2005], which enables us to compute Bayes factor model comparison analytically later on.
The model is shown in Figure \@ref(fig:ch-03-06-comparison-t-test-eco).

```{r ch-03-06-comparison-t-test-eco, echo = F, out.width = '80%', fig.cap="Bayesian $t$-test model following Gönen et al. [-@GoenenJohnson2005] for inferences about the difference in means in the eco-sensitivity data."}
knitr::include_graphics("visuals/t-test-model-eco-data-GoenenJohnson2005.png")
```

The model in Figure \@ref(fig:ch-03-06-comparison-t-test-eco) assumes that there are two vectors $y_1$ and $y_2$ of continuous measurements. 
In our case, these are the continuous measurements of reaction times in the congruent and incongruent group.
The model further assumes that all measurements in $y_1$ and $y_2$ are samples from two normal distributions, one for each group, with shared variance but possibly different means.
The means of the two normal distributions is represented in terms of a shared mean $\mu$, which indicates the midpoint between the means of either group.
The model is set-up (very cleverly!) in such a way that there is a difference parameter $\delta$ which specifies the *standardized difference between group means*.
Standardization here means that the difference between the means is represented in relation to the variance of the measurements in each group (which is assumed to be the same in both groups).
The free variables in this model are therefore: the average of the group means $\mu$, the standardized difference $\delta$ of the group means from each other, and the common variance $\sigma$ of measurements in each group.
The priors for these parameters are chosen in such a way as to enable us later to calculate Bayes factor model comparison for particular comparison-based tests analytically.
Notice that, by explicitly representing the difference parameter $\delta$ in the mode, it is possible to put different kinds of _a priori_ assumptions about the likely differences between groups directly into the model, namely in the form of $\mu_g$ and $g$, which are not free model parameters, but will be set by us modellers, here as $\mu_g = 0$ and $g = 1$.


Based on this data and model, we are interested in the following statistical hypotheses:

1. 

We focus on the the first hypothesis spelled out in Chapter \@ref(app-93-data-sets-simon-task), namely that the correct choices are faster in the congruent condition than in the incongruent condition.

1. **Point-valued**: $\delta = 0$
2. **ROPE-d** $\delta = \in [0 - \epsilon; 0 + \epsilon]$ with $\epsilon = 0.1$
3. **Directional** $\delta < 0$

#### Stan model

Here is the model from Figure \@ref(fig:ch-03-06-comparison-t-test-eco) implemented in `Stan`:

```{r, echo = F, eval = F}
# data as greta array
y0 <- as_data(x_A)
y1 <- as_data(x_B)
# priors (regularizing (data-informed) for smooth fitting)
sd_delta <- sd(c(x_A, x_B))
mean_0   <- normal(mean(x_A), 10)
delta    <- normal(0, sd_delta)
sigma_0  <- normal(sd(x_A), 10, truncation = c(0, Inf))
sigma_1  <- normal(sd(x_B), 10, truncation = c(0, Inf))
mean_1   <- mean_0 + delta
# likelihood 
distribution(y0) <- normal(mean_0, sigma_0)
distribution(y1) <- normal(mean_1, sigma_1)
# model
m <- model(delta)
```

```{r, echo = F, eval = F}
sd_delta <- sd(c(x_A, x_B))
```

```{r, eval = F}
eco_data_4_Stan <- list(
  y1 = x_A,
  N1 = length(x_A),
  y2 = x_B,
  N2 = length(x_B)
)
```

```{mystan, eval = F}
data {
int<lower=1> N1 ;
int<lower=1> N2 ;
vector[N1] y1 ;
vector[N2] y2 ;
}
parameters {
real mu ;
real<lower=0> sigma ;
real delta ;
} 
model {
# priors
target += log(1/sigma) ;
delta ~ normal(0, 5) ;

# likelihood
y1 ~ normal(mu + sigma*delta/2, sigma^2) ;
y2 ~ normal(mu - sigma*delta/2, sigma^2) ;
}
```

<link rel="stylesheet" href="hljs.css">
<script src="stan.js"></script>
<script>$('pre.mystan code').each(function(i, block) {hljs.highlightBlock(block);});</script>

## Testing as posterior estimation

### Example: 24/7

The following repeats code and calculations from Chapter \@ref(ch-03-04-parameter-estimation). We can calculate the 95% HDI as follows (via Beta/Binomial conjugacy):

```{r}
estimates_24_7 <- tibble(
  `lower_Bayes` = HDInterval::hdi(function(x) qbeta(x, 8, 18))[1],
  `upper_Bayes` = HDInterval::hdi(function(x) qbeta(x, 8, 18))[2],
) %>% 
  pivot_longer(
    everything(),
    names_pattern = "(.*)_(.*)",
    names_to = c(".value", "approach")
  )
estimates_24_7
```

Here is a plot of the posterior.

```{r, echo = F}
posterior_plot_24_7
```


Using Lindley's approach, we notice that the point-value of interest, namely $\theta = 0.5$, is excluded from the 95% HDI. We therefore reject the idea of a fair coin as being sufficiently unlikely to act as if it was false. 
Using the ROPE-approach of Kruschke, we notice that our ROPE of $\theta = 0.5 \pm 0.01$ is also fully outside of the 95% HDI. Here too, we conclude that the idea of a fair coin is sufficiently unlikely to act as if it was false.

### Example: Eco-sensitivity

We use `Stan` to draw samples from the posterior distribution.

```{r, echo = F, eval = F}
# sampling
draws_t_test_2 <- greta::mcmc(m, n_samples = 4000)
# cast results (type 'mcmc.list') into tidy tibble
tidy_draws_tt2 = ggmcmc::ggs(draws_t_test_2)
```

```{r echo = F, eval = F}
draws_t_test_2 <- readRDS('models_greta/ttest_2_draws.rds')
tidy_draws_tt2 = ggmcmc::ggs(draws_t_test_2)
```

```{r}
# sampling
stan_fit_ttest <- rstan::stan(
  # where is the Stan code
  file = 'models_stan/ttest_model.stan',
  # data to supply to the Stan program
  data = eco_data_4_Stan,
  # how many iterations of MCMC
  iter = 3000,
  # how many warmup steps
  warmup = 500
)

# cast results (type 'mcmc.list') into tidy tibble
tidy_draws_tt2 = ggmcmc::ggs(stan_fit_ttest)
```

We then check the 95% HDI of the posterior.

```{r}
# get the mean difference and 95% HDI
Bayes_estimates_eco <- tidy_draws_tt2 %>% 
  group_by(Parameter) %>%
  summarise(
    '|95%' = HDInterval::hdi(value)[1],
    mean = mean(value),
    '95|%' = HDInterval::hdi(value)[2]
  )
Bayes_estimates_eco
```

Figure \@ref(fig:ch-03-07-hypothesis-testing-Bayes-tt2-posterior) shows the posterior distribution and the 95% HDI (in red).

```{r ch-03-07-hypothesis-testing-Bayes-tt2-posterior, echo = F, fig.cap = "Posterior density of the $\\delta$ parameter in Bayesian $t$-test model for (fictitious) eco-sensitivity data with the 95% HDI (in red)."}
dens <- filter(tidy_draws_tt2, Parameter == "delta") %>% pull(value) %>% 
  density()

tibble(
  delta = dens$x,
  density = dens$y
) %>% 
  ggplot(aes(x = delta, y = density)) +
  geom_line() +
  geom_area(aes(x = ifelse(delta > Bayes_estimates_eco[1,3] %>% as.numeric & delta < Bayes_estimates_eco[1,4] %>% as.numeric , delta, 0)),
            fill = "firebrick", alpha = 0.5) +
  ylim(0, max(dens$y)) +
  xlim(min(dens$x), max(dens$x))
```

Using Lindley's approach, we'd conclude from the fact that the critical value of $\delta = 0$ is outside the 95% HDI that the idea of group-mean equality is sufficiently unlikely to be practically dismissed. The ROPE $\delta = 0 \pm 2$, however, is neither fully included, nor fully outside of the 95% HDI. Using Kruschke's approach, we withhold judgement.

<!-- exercise 1 -->
<div class = "exercises">
**Exercise 12.1: Lindley vs. Kruschke**

In this exercise, we will recap the decision rules of the two approaches introduced in this chapter. Using Lindley's approach, there are two possible outcomes, namely rejecting $H_0$ and failing to reject $H_0$. Following Kruschke's ROPE approach, we can also withhold judgement. For each outcome, draw any distribution representing the posterior, the approximate 95% HDI and an arbitrary point value of interest. For tasks c-e, also draw an arbitrary ROPE around the point value.

Concretely, we'd like you to sketch...

a. ...one instance where we would not reject a point-valued hypothesis $H_0: \theta = \theta^*$.
b. ...one instance where we would reject a point-valued hypothesis $H_0: \theta = \theta^*$.
c. ...two instances where we would not reject a ROPE-d hypothesis $H_0: \theta = \theta^* \pm \epsilon$.
d. ...two instances where we would reject a ROPE-d hypothesis $H_0: \theta = \theta^* \pm \epsilon$.
e. ...two instances where we would withhold judgement regarding a ROPE-d hypothesis $H_0: \theta = \theta^* \pm \epsilon$.

<div class="collapsibleSolution">
<button class="trigger">Solution</button>
<div class="content">

One solution to this exercise might look as follows.

```{r echo=FALSE, out.width='80%'}

hdi <- tibble(
  `lower` = HDInterval::hdi(function(x) qnorm(x, mean = 0, sd = 0.3))[1],
  `upper` = HDInterval::hdi(function(x) qnorm(x, mean = 0, sd = 0.3))[2],
 )

base_plot <- ggplot(data.frame(x = c(-2, 2)), aes(x = x)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 0.3)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 0.3),
                geom = "area", fill = "firebrick", xlim = c(hdi$lower, hdi$upper), alpha = 0.4) +
  annotate(geom = "text", label = "95% HDI", x = 0, y = 0.5, color = "firebrick", size = 3, alpha = 0.5) +
  theme_void()

# Lindley: accept
a <- base_plot +
  geom_point(aes(x = -0.3, y = 0), size = 3) +
  annotate(geom = "text", label = "(a)", x = -2, y = 1.1, fontface = "bold")

# Lindley: reject
b <- base_plot +
  geom_point(aes(x = 1, y = 0), size = 3) +
  annotate(geom = "text", label = "(b)", x = -2, y = 1.1, fontface = "bold")

# Kruschke: accept
c1 <- base_plot +
  geom_point(aes(x = 0, y = 0), size = 3) +
  annotate(geom = "segment", x = -0.8, xend = 0.8, y = 0, yend = 0, size = 2) +
  annotate(geom = "text", label = "(c)", x = -2, y = 1.1, fontface = "bold")

# Kruschke: accept
c2 <- base_plot +
  geom_point(aes(x = -0.7, y = 0), size = 3) +
  annotate(geom = "segment", x = -2, xend = 0.6, y = 0, yend = 0, size = 2)

# Kruschke: reject
d1 <- base_plot +
  geom_point(aes(x = -1.5, y = 0), size = 3) +
  annotate(geom = "segment", x = -1.8, xend = -1.2, y = 0, yend = 0, size = 2) +
  annotate(geom = "text", label = "(d)", x = -2, y = 1.1, fontface = "bold")

# Kruschke: reject
d2 <- base_plot +
  geom_point(aes(x = 1.1, y = 0), size = 3) +
  annotate(geom = "segment", x = 0.6, xend = 1.6, y = 0, yend = 0, size = 2)

# Kruschke: withhold judgement
e1 <- base_plot +
  geom_point(aes(x = -1, y = 0), size = 3) +
  annotate(geom = "segment", x = -1.8, xend = -0.2 , y = 0, yend = 0, size = 2) +
  annotate(geom = "text", label = "(e)", x = -2, y = 1.1, fontface = "bold")

# Kruschke: withhold judgement
e2 <- base_plot +
  geom_point(aes(x = 0.2, y = 0), size = 3) +
  annotate(geom = "segment", x = -0.1, xend = 0.5, y = 0, yend = 0, size = 2)

cowplot::plot_grid(a,b,c1,c2,d1,d2,e1,e2, ncol = 2)
```

The red shaded area under the curves shows the 95% credible interval. The black dots represent (arbitrary) point values of interest, and the horizontal bars in panels (c)-(e) depict the ROPE around a given point value.
  
</div>
</div>
</div>


## The Savage-Dickey method {#ch-03-07-hypothesis-testing-Bayes-Savage-Dickey}

The Savage-Dickey method is a very convenient way of computing Bayes factors for nested models, especially when models only differ with respect to one parameter.

### Nested (Bayesian) models  

Suppose that there are $n$ continuous parameters of interest $\theta = \langle \theta_1, \dots, \theta_n \rangle$. $M_1$ is a (Bayesian) model defined by $P(\theta \mid M_1)$ and $P(D \mid \theta, M_1)$. $M_0$ is **properly nested** under $M_1$ if:

- $M_0$ assigns fixed values to parameters $\theta_i = x_i, \dots, \theta_n = x_n$
- $P(D \mid \theta_1, \dots, \theta_{i-1}, M_0) = P(D \mid \theta_1, \dots, \theta_{i-1}, \theta_i = x_i, \dots, \theta_n = x_n, M_1)$
- $\lim_{\theta_i \rightarrow x_i, \dots, \theta_n \rightarrow x_n} P(\theta_1, \dots, \theta_{i-1} \mid \theta_i, \dots, \theta_n, M_1) = P(\theta_1, \dots, \theta_{i-1} \mid M_0)$

Notice that the last condition is satisfied in particular when $M_1$'s prior over $\theta_1, \dots, \theta_{i-1}$ is independent of the values for the remaining parameters.

### Savage-Dickey theorem

```{theorem, name = "Savage-Dickey Bayes factors for nested models"}
Let $M_0$ be properly nested under $M_1$ s.t. $M_0$ fixes $\theta_i = x_i, \dots, \theta_n = x_n$. The Bayes factor $\text{BF}_{01}$ in favor of $M_0$ over $M_1$ is then given by the ratio of posterior probability to prior probability of the parameters $\theta_i = x_i, \dots, \theta_n = x_n$ from the point of view of the nesting model $M_1$:

$$
\begin{aligned}
\text{BF}_{01} & = \frac{P(\theta_i = x_i, \dots, \theta_n = x_n \mid D, M_1)}{P(\theta_i = x_i, \dots, \theta_n = x_n \mid M_1)}
\end{aligned}
$$
```


```{proof}
Let's assume that $M_0$ has parameters $\theta = \langle\phi, \psi\rangle$ with $\phi = \phi_0$, and that $M_1$ has parameters $\theta = \langle\phi, \psi \rangle$ with $\phi$ free to vary. If $M_0$ is properly nested under $M_1$, we know that $\lim_{\phi \rightarrow \phi_0} P(\psi \mid \phi, M_1) = P(\psi \mid M_0)$. We can then rewrite the marginal likelihood under $M_0$ as follows:

$$ 
\begin{aligned}
P(D \mid M_0) & = \int P(D \mid \psi, M_0) P(\psi \mid M_0) \ \text{d}\psi
& \text{[marginalization]}
\\
 & = \int P(D \mid \psi, \phi = \phi_0, M_1) P(\psi \mid \phi = \phi_0, M_1)  \ \text{d}\psi
 & \text{[assumption of nesting]}
 \\
 & = P(D \mid \phi = \phi_0, M_1) 
 & \text{[marginalization]}
 \\
 & = \frac{P(\phi = \phi_0 \mid D, M_1) P(D \mid M_1)}{P(\phi = \phi_0 \mid M_1)}
 & \text{[Bayes rule]}
\end{aligned}
$$

The result follows if we divide by $P(D \mid M_1)$ on both sides of the equation.

```

&nbsp;

### Example: 24/7

Here is an example based on the 24/7 data. For a nesting model with a flat prior ($\theta \sim^{M_1} \text{Beta}(1,1)$), and a point hypothesis $\theta^* = 0.5$, we calculate:

```{r}
# point-value of interest
theta_star <- 0.5
# posterior probability in nesting model
posterior_theta_star <- dbeta(theta_star, 8, 18)
# prior probability in nesting model
prior_theta_star <- dbeta(theta_star, 1, 1)
# Bayes factor (using Savage-Dickey)
BF_01 <- posterior_theta_star / prior_theta_star
BF_01
```

This is very minor evidence in favor of the alternative model (Bayes factor $\text{BF}_{10} \approx `r signif(1/BF_01,3)`$). We would not like to draw any (strong) categorical conclusions from this result regarding the question of whether the coin might be fair. Figure \@ref(fig:ch-03-07-hypothesis-testing-Bayes-SD-24-7) also shows the relation between prior and posterior at the point-value of interest. 

```{r ch-03-07-hypothesis-testing-Bayes-SD-24-7, echo = F, fig.cap = "Illustration of the Savage-Dickey method of Bayes factor computation for the 24/7 case."}
plotData <- tibble(
  theta = seq(0.01,1, by = 0.01),
  posterior = dbeta(theta, 8, 18 ),
  prior = dbeta(theta, 1, 1)
)
plotData = pivot_longer(plotData, cols = c("posterior", "prior"), names_to = "distribution")
pointData <- data.frame(x = c(0.5,0.5), y = c(dbeta(0.5,8,18),1))

ggplot(plotData, aes(x = theta, y = value, color = distribution)) + xlim(0,1) + geom_line() + ylab("probability") +
  geom_segment(aes(x = 0.52, y = 0, xend = 0.52, yend = 1), color = "darkgray") +
  geom_segment(aes(x = 0.48, y = 0, xend = 0.48, yend = dbeta(0.5,8,18)), color = "darkgray") +
  geom_segment(aes(x = 0.5, y = 1, xend = 0.52, yend = 1), color = "darkgray") +
  geom_segment(aes(x = 0.5, y = dbeta(0.5,8,18), xend = 0.48, yend = dbeta(0.5,8,18)), color = "darkgray") +
  annotate("point", x = 0.5, y = 1, color = "black") +
  annotate("point", x = 0.5, y = dbeta(0.5,8,18), color = "black") + 
  annotate("text", x = 0.3, y = 0.25, color = "darkgray", label = "P(0.5 | D, M1) = 0.516", size = 3) +
  annotate("text", x = 0.68, y = 0.75, color = "darkgray", label = "P(0.5 | M1) = 1", size = 3)
```

### Example: Eco-sensitivity

To apply the Savage-Dickey method to the eco-sensitivity model, we have to obtain an estimate for the posterior density at the critical value $\delta = 0$ from the posterior samples. An approximate method for obtaining this value is implemented in the `polspline` package (using polynomial splines to approximate the posterior curve).

```{r}
# extract the samples for the delta parameter
delta_samples <- tidy_draws_tt2 %>% 
  filter(Parameter == "delta") %>% 
  pull(value)
# estimating the posterior density at delta = 0 with Savage-Dickey
fit.posterior <- polspline::logspline(delta_samples)
posterior_delta_null <- polspline::dlogspline(0, fit.posterior)
prior_delta_null <- dnorm(0, 0, 5) 
BF_delta_null = posterior_delta_null / prior_delta_null
BF_delta_null
```

We conclude from this result that there is only very mild (unnoteworthy) evidence in favor of the alternative hypothesis (Bayes factor $\text{BF}_{10} \approx `r signif(1/BF_delta_null,3)`$).

<!-- exercise 2 -->
<!-- Taken from the prep exam (IDA-prep-exam-02.pages.pdf) -->
<div class = "exercises">
**Exercise 12.2: Bayes factors with the Savage-Dickey method**

Look at the plot below. You see the prior distribution and the posterior distribution over the $\delta$ parameter in a Bayesian $t$-test model. We are going to use this plot to determine (roughly) the Bayes factor of two models: the full Bayesian $t$-test model, and a model nested under this full model which assumes that $\delta = 0$.

```{r echo=FALSE, fig.align="center", fig.width=4, fig.height=4, warning=FALSE}
ggplot(data = NULL, aes(x = x, color = legend)) +
  stat_function(data = data.frame(x = -20:20, legend = factor(1)), fun = dnorm, args = list(mean = 1.5, sd = 3), size = 2) +
  stat_function(data = data.frame(x = -20:20, legend = factor(2)), fun = dnorm, args = list(mean = 0, sd = 8), size = 2) +
  scale_colour_manual(values = c("#E69F00", "#0072B2"), labels = c("posterior", "prior")) +
  theme_minimal() +
  theme(legend.title = element_blank(), 
        legend.position = "top",
        axis.title.y = element_blank()) +
  xlab(latex2exp::TeX("$\\delta$"))
```

a. Describe in intuitive terms what it means for a Bayesian model to be nested under another model. It is sufficient to neglect the conditions on the priors, i.e., focus on the meaning of “nesting” that also applies to a pair of frequentist models.

<div class="collapsibleSolution">
<button class="trigger">Solution</button>
<div class="content">

A model nested under another model fixes certain parameters to specific values which may take on more than one value in the nesting model.

</div>
</div>

b. Write down the formula for the Bayes factor in favor of the null model (where $\delta = 0$) over the full model using the Savage-Dickey theorem.

<div class="collapsibleSolution">
<button class="trigger">Solution</button>
<div class="content">

$BF_{01}=\frac{P(\delta = 0|D, M_1)}{P(\delta = 0|M_1)}$.

</div>
</div>

c. Give a natural language paraphrase of the formula you wrote down above.

<div class="collapsibleSolution">
<button class="trigger">Solution</button>
<div class="content">

The Bayes factor in favor of the embedded null model over the embedding model is given by the posterior density at $\delta = 0$ under the nesting model divided by the prior in the nesting model at $\delta = 0$.

</div>
</div>

d. Now look at the plot above. Give your approximate guess of the Bayes factor in favor of the null model in terms of a fraction of whole integers (something like: $\frac{4}{3}$ or $\frac{27}{120}$, ...).

<div class="collapsibleSolution">
<button class="trigger">Solution</button>
<div class="content">

```{r echo=FALSE, fig.align="center", fig.width=4, fig.height=4, warning=FALSE}
ggplot(data = NULL, aes(x = x, color = legend)) +
  stat_function(data = data.frame(x = -20:20, legend = factor(1)), fun = dnorm, args = list(mean = 1.5, sd = 3), size = 2) +
  stat_function(data = data.frame(x = -20:20, legend = factor(2)), fun = dnorm, args = list(mean = 0, sd = 8), size = 2) +
  scale_colour_manual(values = c("#E69F00", "#0072B2"), labels = c("posterior", "prior")) +
  annotate(geom = "segment", x = 0, xend = 0, y = 0, yend = 0.049, arrow = arrow(length = unit(0.3, "cm"))) +
  annotate(geom = "text", x = -1, y = 0.03, label = "2", color = "#0072B2") +
  annotate(geom = "segment", x = 1.5, xend = 1.5, y = 0, yend = 0.125, arrow = arrow(length = unit(0.3, "cm"))) +
  annotate(geom = "text", x = 3, y = 0.08, label = "5", color = "#E69F00") +
  theme_minimal() +
  theme(legend.title = element_blank(), 
        legend.position = "top",
        axis.title.y = element_blank()) +
  xlab(latex2exp::TeX("$\\delta$"))
```

$BF_{01} \approx \frac{5}{2}$ (see plot above).

</div>
</div>

e. Formulate a conclusion to be drawn from this numerical result about the research hypothesis that the mean of the two groups compared here are identical. Write one concise sentence like you would in a research paper.

<div class="collapsibleSolution">
<button class="trigger">Solution</button>
<div class="content">

A BF of $\frac{5}{2}$ is mild evidence in favor of the null model, but conventionally not considered strong enough to be particularly noteworthy.
  
</div>
</div>

</div>


## Bayes factors for ROPE-d hypotheses through encompassing models {#ch-03-07-hypothesis-testing-Bayes-encompassing-models}

The Savage-Dickey method can be generalized to also cover interval-valued hypotheses in general, and therefore also ROPE-d hypotheses in particular. The previous literature has focused on inequality-based intervals/hypotheses (like $\theta \ge 0.5$) [@KlugkistKato2005:Bayesian-model;@WetzelsGrasman2010:An-encompassing;@Oh2014:Bayesian-compar]. Here, we show that this method also extends to arbitrary intervals. The advantage of this method is that we can use samples from the posterior distribution to approximate integrals, which is more robust than having to estimate point-values of posterior density. 

Following previous work [@KlugkistKato2005:Bayesian-model;@WetzelsGrasman2010:An-encompassing;@Oh2014:Bayesian-compar], the main idea is to use so-called **encompassing priors**. Let $\theta$ be a single parameter of interest (for simplicity), which can in principle take on any real value. We are interested in the interval-based hypotheses:

- $H_0 \colon \theta \in [a;b]$, and 
- $H_a \colon \theta \not \in [a;b]$

An **encompassing model** $M_e$ has a suitable likelihood function $P_{M_e}(D \mid \theta, \omega)$ (where $\omega$ is a vector of other parameters besides the parameter $\theta$ of interest). It also defines a prior $P_{M_e}(\theta, \omega)$, for which crucially:

$$0 < P_{M_e}(\theta, \omega) < 1$$

This latter constraint makes sure that the parameter ranges of $H_0$ and $H_a$ are not ruled out *a priori*.

Generalizing over the Savage-Dickey approach, we construct *two* models, one for each hypothesis, *both* of which are nested under the encompassing model:

- $M_0$ has prior $P_{M_0}(\theta, \omega) = P_{M_e}(\theta, \omega \mid \theta \in [a;b])$
- $M_a$ has prior $P_{M_a}(\theta, \omega) = P_{M_e}(\theta, \omega \mid \theta \not \in [a;b])$

Both $M_0$ and $M_a$ have the same likelihood function as $M_e$, which is why we drop the model index for better readability in the following. 

Figure \@ref(fig:ch-03-07-hypothesis-testing-Bayes-encompassing-prior) shows an example of the priors of an encompassing model for two nested models based on a ROPE-d hypothesis testing approach.

```{r ch-03-07-hypothesis-testing-Bayes-encompassing-prior, echo = F, fig.cap = "Example of the prior of an encompassing model and the priors of two models nested under it."}
tibble(
  delta = seq(-3,3,length.out = 1000),
  encompassing = dnorm(delta)
) %>%
  mutate(
    null = ifelse(-0.1 <= delta & delta <= 0.1,
                  encompassing, 0),
    alt  = ifelse(-0.1 >= delta | delta >= 0.1,
                  encompassing, 0)
  ) %>%
  mutate(
    encompassing = encompassing / sum(encompassing),
    null = null / sum(null),
    alt = alt / sum(alt)
  ) %>%
  pivot_longer(cols = -delta, names_to = "model", values_to = "density") %>%
  mutate(model = factor(model, ordered = T, levels = c("encompassing", "null", "alt"))) %>%
  ggplot(aes(x = delta, y = density)) +
  geom_line() +
  geom_area(fill = "lightgray", alpha = 0.6) +
  facet_wrap(. ~ model, nrow = 3, scales = "free") +
  labs(
    x = "", y = ""
  ) +
  guides(fill = F) +
  theme(
    axis.text.y  = element_blank(),
    axis.ticks.y = element_blank()
  )
```


```{theorem, "BF-ROPED-hypotheses"}
Fix a Bayesian model $M$ (the encompassing model) with prior $P_M(\theta, \omega)$ and likelihood function $P_M(D \mid \theta, \omega)$, where $\theta$ is the parameter of interest and $\omega$ is a vector of other (nuisance) parameters. Assume that the priors over $\theta$ are independent of the nuisance parameters $\omega$. For an interval-valued hypothesis $H_0 \colon \theta = \theta^* \pm \epsilon$, the Bayes factor in favor of this hypothesis over its negation $H_a \colon \theta \neq \theta^* \pm \epsilon$ can be expressed as:

$$ 
\begin{aligned}
\text {BF}_{01} & = \frac{\text{posterior-odds of } H_0}{\text{prior-odds of } H_0}  \\
& = \frac{P_M(\theta = \theta^* \pm \epsilon \mid D)}{P_M(\theta \neq \theta^* \pm \epsilon \mid D)} \frac{P_M(\theta \neq \theta^* \pm \epsilon)}{P_M(\theta = \theta^* \pm \epsilon)}
\end{aligned}
$$

```

```{proof}
TBD
```

### Example: 24/7

The Bayes factor using the ROPE-d method to compute the interval-valued hypothesis $\theta = 0.5 \pm \epsilon$ is:

```{r}
# set the scene
theta_null <- 0.5
epsilon <- 0.01                 # epsilon margin for ROPE
upper <- theta_null + epsilon   # upper bound of ROPE
lower <- theta_null - epsilon   # lower bound of ROPE
# calculate prior odds of the ROPE-d hypothesis
prior_of_hypothesis <- pbeta(upper, 1, 1) - pbeta(lower, 1, 1)
prior_odds <- prior_of_hypothesis / (1 - prior_of_hypothesis)
# calculate posterior odds of the ROPE-d hypothesis
posterior_of_hypothesis <- qbeta(upper, 8, 18) - qbeta(lower, 8, 18)
posterior_odds <- posterior_of_hypothesis / (1 - posterior_of_hypothesis)
# calculate Bayes factor
bf_ROPEd_hypothesis <- posterior_odds / prior_odds
bf_ROPEd_hypothesis
```

This is mild evidence in favor of the alternative hypothesis (Bayes factor $\text{BF}_{10} \approx `r signif(1/bf_ROPEd_hypothesis,3)`$).

### Example: Eco-sensitivity


```{r}
# estimating the BF for ROPE-d hypothesis with encompassing priors
delta_null <- 0
epsilon <- 0.25                 # epsilon margin for ROPE
upper <- delta_null + epsilon   # upper bound of ROPE
lower <- delta_null - epsilon   # lower bound of ROPE
# calculate prior odds of the ROPE-d hypothesis
prior_of_hypothesis <- pnorm(upper, 0, 5) - pnorm(lower, 0, 5)
prior_odds <- prior_of_hypothesis / (1 - prior_of_hypothesis)
# calculate posterior odds of the ROPE-d hypothesis
posterior_of_hypothesis <- mean( lower <= delta_samples & delta_samples <= upper )
posterior_odds <- posterior_of_hypothesis / (1 - posterior_of_hypothesis)
# calculate Bayes factor
bf_ROPEd_hypothesis <- posterior_odds / prior_odds
bf_ROPEd_hypothesis
```

This is only minor evidence in favor of the alternative hypothesis (Bayes factor $\text{BF}_{10} \approx `r signif(1/bf_ROPEd_hypothesis,3)`$).

<!-- exercise 3 -->
<div class = "exercises">
**Exercise 12.3: True or False?**

Decide for the following statements whether they are true or false.

a. An encompassing model for addressing ROPE-d hypotheses needs two competing models nested under it.
b. A Bayes factor of $BF_{01} = 20$ constitutes strong evidence in favor of the alternative hypothesis.
c. A Bayes factor of $BF_{10} = 20$ constitutes minor evidence in favor of the alternative hypothesis.
d. We can compute the BF in favor of the alternative hypothesis with $BF_{10} = \frac{1}{BF_{01}}$.

<div class="collapsibleSolution">
<button class="trigger">Solution</button>
<div class="content">

Statements a. and d. are correct.
  
</div>
</div>
</div>

