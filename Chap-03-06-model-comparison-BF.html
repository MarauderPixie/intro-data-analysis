<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>10.3 Bayes factors | An Introduction to Data Analysis</title>
  <meta name="description" content="Introductory text for statistics and data analysis (using R)" />
  <meta name="generator" content="bookdown 0.24.1 and GitBook 2.6.7" />

  <meta property="og:title" content="10.3 Bayes factors | An Introduction to Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Introductory text for statistics and data analysis (using R)" />
  <meta name="github-repo" content="MarauderPixie/intro-data-analysis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="10.3 Bayes factors | An Introduction to Data Analysis" />
  
  <meta name="twitter:description" content="Introductory text for statistics and data analysis (using R)" />
  

<meta name="author" content="Michael Franke" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="Chap-03-06-model-comparison-AIC.html"/>
<link rel="next" href="ch-03-07-hypothesis-testing-Bayes.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span. { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>


<link rel="stylesheet" href="styles.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="index.html#section"></a></li>
<li class="part"><span><b>I Preliminaries</b></span></li>
<li class="chapter" data-level="1" data-path="general-introduction.html"><a href="general-introduction.html"><i class="fa fa-check"></i><b>1</b> General Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="Chap-01-00-intro-learning-goals.html"><a href="Chap-01-00-intro-learning-goals.html"><i class="fa fa-check"></i><b>1.1</b> Learning goals</a></li>
<li class="chapter" data-level="1.2" data-path="Chap-01-00-intro-course-structure.html"><a href="Chap-01-00-intro-course-structure.html"><i class="fa fa-check"></i><b>1.2</b> Course structure</a></li>
<li class="chapter" data-level="1.3" data-path="Chap-01-00-intro-tools.html"><a href="Chap-01-00-intro-tools.html"><i class="fa fa-check"></i><b>1.3</b> Tools used in this course</a></li>
<li class="chapter" data-level="1.4" data-path="Chap-01-00-intro-topics.html"><a href="Chap-01-00-intro-topics.html"><i class="fa fa-check"></i><b>1.4</b> Topics covered (and not covered) in the course</a></li>
<li class="chapter" data-level="1.5" data-path="Chap-01-00-intro-data-sets.html"><a href="Chap-01-00-intro-data-sets.html"><i class="fa fa-check"></i><b>1.5</b> Data sets covered</a></li>
<li class="chapter" data-level="1.6" data-path="Chap-01-00-intro-installation.html"><a href="Chap-01-00-intro-installation.html"><i class="fa fa-check"></i><b>1.6</b> Installation</a></li>
<li class="chapter" data-level="1.7" data-path="Chap-01-00-intro-schedule.html"><a href="Chap-01-00-intro-schedule.html"><i class="fa fa-check"></i><b>1.7</b> Example schedule (12-week course)</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chap-01-01-R.html"><a href="Chap-01-01-R.html"><i class="fa fa-check"></i><b>2</b> Basics of R</a><ul>
<li class="chapter" data-level="2.1" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html"><i class="fa fa-check"></i><b>2.1</b> First steps</a><ul>
<li class="chapter" data-level="2.1.1" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#functions"><i class="fa fa-check"></i><b>2.1.1</b> Functions</a></li>
<li class="chapter" data-level="2.1.2" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#variables"><i class="fa fa-check"></i><b>2.1.2</b> Variables</a></li>
<li class="chapter" data-level="2.1.3" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#literate-coding"><i class="fa fa-check"></i><b>2.1.3</b> Literate coding</a></li>
<li class="chapter" data-level="2.1.4" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#objects"><i class="fa fa-check"></i><b>2.1.4</b> Objects</a></li>
<li class="chapter" data-level="2.1.5" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#packages"><i class="fa fa-check"></i><b>2.1.5</b> Packages</a></li>
<li class="chapter" data-level="2.1.6" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#Chap-01-01-R-help"><i class="fa fa-check"></i><b>2.1.6</b> Getting help</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="ch1-data-types.html"><a href="ch1-data-types.html"><i class="fa fa-check"></i><b>2.2</b> Data types</a><ul>
<li class="chapter" data-level="2.2.1" data-path="ch1-data-types.html"><a href="ch1-data-types.html#numeric-vectors-matrices"><i class="fa fa-check"></i><b>2.2.1</b> Numeric vectors &amp; matrices</a></li>
<li class="chapter" data-level="2.2.2" data-path="ch1-data-types.html"><a href="ch1-data-types.html#booleans"><i class="fa fa-check"></i><b>2.2.2</b> Booleans</a></li>
<li class="chapter" data-level="2.2.3" data-path="ch1-data-types.html"><a href="ch1-data-types.html#special-values"><i class="fa fa-check"></i><b>2.2.3</b> Special values</a></li>
<li class="chapter" data-level="2.2.4" data-path="ch1-data-types.html"><a href="ch1-data-types.html#characters-strings"><i class="fa fa-check"></i><b>2.2.4</b> Characters (= strings)</a></li>
<li class="chapter" data-level="2.2.5" data-path="ch1-data-types.html"><a href="ch1-data-types.html#factors"><i class="fa fa-check"></i><b>2.2.5</b> Factors</a></li>
<li class="chapter" data-level="2.2.6" data-path="ch1-data-types.html"><a href="ch1-data-types.html#lists-data-frames-tibbles"><i class="fa fa-check"></i><b>2.2.6</b> Lists, data frames &amp; tibbles</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="Chap-01-01-functions.html"><a href="Chap-01-01-functions.html"><i class="fa fa-check"></i><b>2.3</b> Functions</a><ul>
<li class="chapter" data-level="2.3.1" data-path="Chap-01-01-functions.html"><a href="Chap-01-01-functions.html#some-important-built-in-functions"><i class="fa fa-check"></i><b>2.3.1</b> Some important built-in functions</a></li>
<li class="chapter" data-level="2.3.2" data-path="Chap-01-01-functions.html"><a href="Chap-01-01-functions.html#defining-your-own-functions"><i class="fa fa-check"></i><b>2.3.2</b> Defining your own functions</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="ch-01-01-loops-and-maps.html"><a href="ch-01-01-loops-and-maps.html"><i class="fa fa-check"></i><b>2.4</b> Loops and maps</a><ul>
<li class="chapter" data-level="2.4.1" data-path="ch-01-01-loops-and-maps.html"><a href="ch-01-01-loops-and-maps.html#for-loops"><i class="fa fa-check"></i><b>2.4.1</b> For-loops</a></li>
<li class="chapter" data-level="2.4.2" data-path="ch-01-01-loops-and-maps.html"><a href="ch-01-01-loops-and-maps.html#functional-iterators"><i class="fa fa-check"></i><b>2.4.2</b> Functional iterators</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="Chap-01-01-piping.html"><a href="Chap-01-01-piping.html"><i class="fa fa-check"></i><b>2.5</b> Piping</a><ul>
<li class="chapter" data-level="2.5.1" data-path="Chap-01-01-piping.html"><a href="Chap-01-01-piping.html#excursion-more-on-pipes-in-r"><i class="fa fa-check"></i><b>2.5.1</b> Excursion: More on pipes in R</a></li>
<li class="chapter" data-level="2.5.2" data-path="Chap-01-01-piping.html"><a href="Chap-01-01-piping.html#excursion-multiple-assignments-or-unpacking"><i class="fa fa-check"></i><b>2.5.2</b> Excursion: Multiple assignments, or “unpacking”</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="ch-01-01-Rmarkdown.html"><a href="ch-01-01-Rmarkdown.html"><i class="fa fa-check"></i><b>2.6</b> Rmarkdown</a></li>
</ul></li>
<li class="part"><span><b>II Data</b></span></li>
<li class="chapter" data-level="3" data-path="Chap-02-01-data.html"><a href="Chap-02-01-data.html"><i class="fa fa-check"></i><b>3</b> Data, variables &amp; experimental designs</a><ul>
<li class="chapter" data-level="3.1" data-path="Chap-02-01-data-what-is-data.html"><a href="Chap-02-01-data-what-is-data.html"><i class="fa fa-check"></i><b>3.1</b> What is data?</a></li>
<li class="chapter" data-level="3.2" data-path="Chap-02-01-data-kinds-of-data.html"><a href="Chap-02-01-data-kinds-of-data.html"><i class="fa fa-check"></i><b>3.2</b> Different kinds of data</a></li>
<li class="chapter" data-level="3.3" data-path="Chap-02-01-data-variables.html"><a href="Chap-02-01-data-variables.html"><i class="fa fa-check"></i><b>3.3</b> On the notion of “variables”</a></li>
<li class="chapter" data-level="3.4" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html"><i class="fa fa-check"></i><b>3.4</b> Basics of experimental design</a><ul>
<li class="chapter" data-level="3.4.1" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html#what-to-analyze-dependent-variables"><i class="fa fa-check"></i><b>3.4.1</b> What to analyze? – Dependent variables</a></li>
<li class="chapter" data-level="3.4.2" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html#conditions-trials-items"><i class="fa fa-check"></i><b>3.4.2</b> Conditions, trials, items</a></li>
<li class="chapter" data-level="3.4.3" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html#sample-size"><i class="fa fa-check"></i><b>3.4.3</b> Sample size</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-wrangling.html"><a href="data-wrangling.html"><i class="fa fa-check"></i><b>4</b> Data Wrangling</a><ul>
<li class="chapter" data-level="4.1" data-path="Chap-02-02-data-IO.html"><a href="Chap-02-02-data-IO.html"><i class="fa fa-check"></i><b>4.1</b> Data in, data out</a></li>
<li class="chapter" data-level="4.2" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html"><i class="fa fa-check"></i><b>4.2</b> Tidy data</a><ul>
<li class="chapter" data-level="4.2.1" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html#running-example"><i class="fa fa-check"></i><b>4.2.1</b> Running example</a></li>
<li class="chapter" data-level="4.2.2" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html#definition-of-tidy-data"><i class="fa fa-check"></i><b>4.2.2</b> Definition of <em>tidy data</em></a></li>
<li class="chapter" data-level="4.2.3" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html#excursion-non-redundant-data"><i class="fa fa-check"></i><b>4.2.3</b> Excursion: non-redundant data</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html"><i class="fa fa-check"></i><b>4.3</b> Data manipulation: the basics</a><ul>
<li class="chapter" data-level="4.3.1" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#pivoting"><i class="fa fa-check"></i><b>4.3.1</b> Pivoting</a></li>
<li class="chapter" data-level="4.3.2" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#subsetting-rows-columns"><i class="fa fa-check"></i><b>4.3.2</b> Subsetting rows &amp; columns</a></li>
<li class="chapter" data-level="4.3.3" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#Chap-02-02-tidy-selection"><i class="fa fa-check"></i><b>4.3.3</b> Tidy selection of column names</a></li>
<li class="chapter" data-level="4.3.4" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#adding-changing-and-renaming-columns"><i class="fa fa-check"></i><b>4.3.4</b> Adding, changing and renaming columns</a></li>
<li class="chapter" data-level="4.3.5" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#splitting-and-uniting-columns"><i class="fa fa-check"></i><b>4.3.5</b> Splitting and uniting columns</a></li>
<li class="chapter" data-level="4.3.6" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#sorting-a-data-set"><i class="fa fa-check"></i><b>4.3.6</b> Sorting a data set</a></li>
<li class="chapter" data-level="4.3.7" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#combining-tibbles"><i class="fa fa-check"></i><b>4.3.7</b> Combining tibbles</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="Chap-02-02-data-grouping-nesting.html"><a href="Chap-02-02-data-grouping-nesting.html"><i class="fa fa-check"></i><b>4.4</b> Grouped operations</a></li>
<li class="chapter" data-level="4.5" data-path="Chap-02-02-data-case-study-KoF.html"><a href="Chap-02-02-data-case-study-KoF.html"><i class="fa fa-check"></i><b>4.5</b> Case study: the King of France</a><ul>
<li class="chapter" data-level="4.5.1" data-path="Chap-02-02-data-case-study-KoF.html"><a href="Chap-02-02-data-case-study-KoF.html#cleaning-the-data"><i class="fa fa-check"></i><b>4.5.1</b> Cleaning the data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Chap-02-03-summary-statistics.html"><a href="Chap-02-03-summary-statistics.html"><i class="fa fa-check"></i><b>5</b> Summary statistics</a><ul>
<li class="chapter" data-level="5.1" data-path="Chap-02-03-summary-statistics-counts.html"><a href="Chap-02-03-summary-statistics-counts.html"><i class="fa fa-check"></i><b>5.1</b> Counts and proportions</a><ul>
<li class="chapter" data-level="5.1.1" data-path="Chap-02-03-summary-statistics-counts.html"><a href="Chap-02-03-summary-statistics-counts.html#loading-and-inspecting-the-data"><i class="fa fa-check"></i><b>5.1.1</b> Loading and inspecting the data</a></li>
<li class="chapter" data-level="5.1.2" data-path="Chap-02-03-summary-statistics-counts.html"><a href="Chap-02-03-summary-statistics-counts.html#obtaining-counts-with-n-count-and-tally"><i class="fa fa-check"></i><b>5.1.2</b> Obtaining counts with <code>n</code>, <code>count</code> and <code>tally</code></a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html"><i class="fa fa-check"></i><b>5.2</b> Central tendency and dispersion</a><ul>
<li class="chapter" data-level="5.2.1" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#the-data-for-the-remainder-of-the-chapter"><i class="fa fa-check"></i><b>5.2.1</b> The data for the remainder of the chapter</a></li>
<li class="chapter" data-level="5.2.2" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#measures-of-central-tendency"><i class="fa fa-check"></i><b>5.2.2</b> Measures of central tendency</a></li>
<li class="chapter" data-level="5.2.3" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#measures-of-dispersion"><i class="fa fa-check"></i><b>5.2.3</b> Measures of dispersion</a></li>
<li class="chapter" data-level="5.2.4" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#excursion-quantifying-confidence-with-bootstrapping"><i class="fa fa-check"></i><b>5.2.4</b> Excursion: Quantifying confidence with bootstrapping</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="Chap-02-03-summary-statistics-2D.html"><a href="Chap-02-03-summary-statistics-2D.html"><i class="fa fa-check"></i><b>5.3</b> Covariance and correlation</a><ul>
<li class="chapter" data-level="5.3.1" data-path="Chap-02-03-summary-statistics-2D.html"><a href="Chap-02-03-summary-statistics-2D.html#covariance"><i class="fa fa-check"></i><b>5.3.1</b> Covariance</a></li>
<li class="chapter" data-level="5.3.2" data-path="Chap-02-03-summary-statistics-2D.html"><a href="Chap-02-03-summary-statistics-2D.html#correlation"><i class="fa fa-check"></i><b>5.3.2</b> Correlation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Chap-02-02-visualization.html"><a href="Chap-02-02-visualization.html"><i class="fa fa-check"></i><b>6</b> Data Visualization</a><ul>
<li class="chapter" data-level="6.1" data-path="Chap-02-04-Anscombe-example.html"><a href="Chap-02-04-Anscombe-example.html"><i class="fa fa-check"></i><b>6.1</b> Motivating example: Anscombe’s quartet</a></li>
<li class="chapter" data-level="6.2" data-path="Chap-02-04-good-visualization.html"><a href="Chap-02-04-good-visualization.html"><i class="fa fa-check"></i><b>6.2</b> Visualization: the good, the bad and the infographic</a></li>
<li class="chapter" data-level="6.3" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html"><i class="fa fa-check"></i><b>6.3</b> Basics of <code>ggplot</code></a><ul>
<li class="chapter" data-level="6.3.1" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#incremental-composition-of-a-plot"><i class="fa fa-check"></i><b>6.3.1</b> Incremental composition of a plot</a></li>
<li class="chapter" data-level="6.3.2" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#elements-in-the-layered-grammar-of-graphs"><i class="fa fa-check"></i><b>6.3.2</b> Elements in the layered grammar of graphs</a></li>
<li class="chapter" data-level="6.3.3" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#layers-and-groups"><i class="fa fa-check"></i><b>6.3.3</b> Layers and groups</a></li>
<li class="chapter" data-level="6.3.4" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#grouping"><i class="fa fa-check"></i><b>6.3.4</b> Grouping</a></li>
<li class="chapter" data-level="6.3.5" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#example-of-a-customized-plot"><i class="fa fa-check"></i><b>6.3.5</b> Example of a customized plot</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html"><i class="fa fa-check"></i><b>6.4</b> A rendezvous with popular geoms</a><ul>
<li class="chapter" data-level="6.4.1" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#scatter-plots-with-geom_point"><i class="fa fa-check"></i><b>6.4.1</b> Scatter plots with <code>geom_point</code></a></li>
<li class="chapter" data-level="6.4.2" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#smooth"><i class="fa fa-check"></i><b>6.4.2</b> Smooth</a></li>
<li class="chapter" data-level="6.4.3" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#line"><i class="fa fa-check"></i><b>6.4.3</b> Line</a></li>
<li class="chapter" data-level="6.4.4" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#bar-plot"><i class="fa fa-check"></i><b>6.4.4</b> Bar plot</a></li>
<li class="chapter" data-level="6.4.5" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#plotting-distributions-histograms-boxplots-densities-and-violins"><i class="fa fa-check"></i><b>6.4.5</b> Plotting distributions: histograms, boxplots, densities and violins</a></li>
<li class="chapter" data-level="6.4.6" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#rugs"><i class="fa fa-check"></i><b>6.4.6</b> Rugs</a></li>
<li class="chapter" data-level="6.4.7" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#annotation"><i class="fa fa-check"></i><b>6.4.7</b> Annotation</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="Chap-02-04-faceting.html"><a href="Chap-02-04-faceting.html"><i class="fa fa-check"></i><b>6.5</b> Faceting</a></li>
<li class="chapter" data-level="6.6" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html"><i class="fa fa-check"></i><b>6.6</b> Customization etc.</a><ul>
<li class="chapter" data-level="6.6.1" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#themes"><i class="fa fa-check"></i><b>6.6.1</b> Themes</a></li>
<li class="chapter" data-level="6.6.2" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#guides"><i class="fa fa-check"></i><b>6.6.2</b> Guides</a></li>
<li class="chapter" data-level="6.6.3" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#axes-ticks-and-tick-labels"><i class="fa fa-check"></i><b>6.6.3</b> Axes, ticks and tick labels</a></li>
<li class="chapter" data-level="6.6.4" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#labels"><i class="fa fa-check"></i><b>6.6.4</b> Labels</a></li>
<li class="chapter" data-level="6.6.5" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#combining-arranging-plots"><i class="fa fa-check"></i><b>6.6.5</b> Combining &amp; arranging plots</a></li>
<li class="chapter" data-level="6.6.6" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#latex-expressions-in-plot-labels"><i class="fa fa-check"></i><b>6.6.6</b> LaTeX expressions in plot labels</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Bayesian Data Analysis</b></span></li>
<li class="chapter" data-level="7" data-path="Chap-03-01-probability.html"><a href="Chap-03-01-probability.html"><i class="fa fa-check"></i><b>7</b> Basics of Probability Theory</a><ul>
<li class="chapter" data-level="7.1" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html"><i class="fa fa-check"></i><b>7.1</b> Probability</a><ul>
<li class="chapter" data-level="7.1.1" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#outcomes-events-observations"><i class="fa fa-check"></i><b>7.1.1</b> Outcomes, events, observations</a></li>
<li class="chapter" data-level="7.1.2" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#probability-distributions"><i class="fa fa-check"></i><b>7.1.2</b> Probability distributions</a></li>
<li class="chapter" data-level="7.1.3" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#interpretations-of-probability"><i class="fa fa-check"></i><b>7.1.3</b> Interpretations of probability</a></li>
<li class="chapter" data-level="7.1.4" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#distributions-as-samples"><i class="fa fa-check"></i><b>7.1.4</b> Distributions as samples</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html"><i class="fa fa-check"></i><b>7.2</b> Structured events &amp; marginal distributions</a><ul>
<li class="chapter" data-level="7.2.1" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html#probability-table-for-a-flip-and-draw-scenario"><i class="fa fa-check"></i><b>7.2.1</b> Probability table for a flip-and-draw scenario</a></li>
<li class="chapter" data-level="7.2.2" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html#structured-events-and-joint-probability-distributions"><i class="fa fa-check"></i><b>7.2.2</b> Structured events and joint-probability distributions</a></li>
<li class="chapter" data-level="7.2.3" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html#marginalization"><i class="fa fa-check"></i><b>7.2.3</b> Marginalization</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="Chap-03-01-probability-conditional.html"><a href="Chap-03-01-probability-conditional.html"><i class="fa fa-check"></i><b>7.3</b> Conditional probability</a><ul>
<li class="chapter" data-level="7.3.1" data-path="Chap-03-01-probability-conditional.html"><a href="Chap-03-01-probability-conditional.html#bayes-rule"><i class="fa fa-check"></i><b>7.3.1</b> Bayes rule</a></li>
<li class="chapter" data-level="7.3.2" data-path="Chap-03-01-probability-conditional.html"><a href="Chap-03-01-probability-conditional.html#Chap-03-01-probability-independence"><i class="fa fa-check"></i><b>7.3.2</b> Stochastic (in-)dependence</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html"><i class="fa fa-check"></i><b>7.4</b> Random variables</a><ul>
<li class="chapter" data-level="7.4.1" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#notation-terminology"><i class="fa fa-check"></i><b>7.4.1</b> Notation &amp; terminology</a></li>
<li class="chapter" data-level="7.4.2" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#cumulative-distribution-functions-mass-density"><i class="fa fa-check"></i><b>7.4.2</b> Cumulative distribution functions, mass &amp; density</a></li>
<li class="chapter" data-level="7.4.3" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#expected-value-variance"><i class="fa fa-check"></i><b>7.4.3</b> Expected value &amp; variance</a></li>
<li class="chapter" data-level="7.4.4" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#composite-random-variables"><i class="fa fa-check"></i><b>7.4.4</b> Composite random variables</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="Chap-03-01-probability-R.html"><a href="Chap-03-01-probability-R.html"><i class="fa fa-check"></i><b>7.5</b> Probability distributions in R</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Chap-03-03-models.html"><a href="Chap-03-03-models.html"><i class="fa fa-check"></i><b>8</b> Statistical models</a><ul>
<li class="chapter" data-level="8.1" data-path="Chap-03-03-models-general.html"><a href="Chap-03-03-models-general.html"><i class="fa fa-check"></i><b>8.1</b> Statistical models</a></li>
<li class="chapter" data-level="8.2" data-path="Chap-03-03-models-representation.html"><a href="Chap-03-03-models-representation.html"><i class="fa fa-check"></i><b>8.2</b> Notation &amp; graphical representation</a><ul>
<li class="chapter" data-level="8.2.1" data-path="Chap-03-03-models-representation.html"><a href="Chap-03-03-models-representation.html#formula-notation"><i class="fa fa-check"></i><b>8.2.1</b> Formula notation</a></li>
<li class="chapter" data-level="8.2.2" data-path="Chap-03-03-models-representation.html"><a href="Chap-03-03-models-representation.html#graphical-notation"><i class="fa fa-check"></i><b>8.2.2</b> Graphical notation</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html"><i class="fa fa-check"></i><b>8.3</b> Parameters, priors, and prior predictions</a><ul>
<li class="chapter" data-level="8.3.1" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html#whats-a-model-parameter"><i class="fa fa-check"></i><b>8.3.1</b> What’s a model parameter?</a></li>
<li class="chapter" data-level="8.3.2" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html#Chap-03-02-models-priors"><i class="fa fa-check"></i><b>8.3.2</b> Priors over parameters</a></li>
<li class="chapter" data-level="8.3.3" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html#Chap-03-03-models-parameters-prior-predictive"><i class="fa fa-check"></i><b>8.3.3</b> Prior predictions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ch-03-04-parameter-estimation.html"><a href="ch-03-04-parameter-estimation.html"><i class="fa fa-check"></i><b>9</b> Bayesian parameter estimation</a><ul>
<li class="chapter" data-level="9.1" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html"><i class="fa fa-check"></i><b>9.1</b> Bayes rule for parameter estimation</a><ul>
<li class="chapter" data-level="9.1.1" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#definitions-and-terminology"><i class="fa fa-check"></i><b>9.1.1</b> Definitions and terminology</a></li>
<li class="chapter" data-level="9.1.2" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#the-effects-of-prior-and-likelihood-on-the-posterior"><i class="fa fa-check"></i><b>9.1.2</b> The effects of prior and likelihood on the posterior</a></li>
<li class="chapter" data-level="9.1.3" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#ch-03-04-parameter-estimation-conjugacy"><i class="fa fa-check"></i><b>9.1.3</b> Computing Bayesian posteriors with conjugate priors</a></li>
<li class="chapter" data-level="9.1.4" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#excursion-sequential-updating"><i class="fa fa-check"></i><b>9.1.4</b> Excursion: Sequential updating</a></li>
<li class="chapter" data-level="9.1.5" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#posterior-predictive-distribution"><i class="fa fa-check"></i><b>9.1.5</b> Posterior predictive distribution</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="ch-03-04-parameter-estimation-points-intervals.html"><a href="ch-03-04-parameter-estimation-points-intervals.html"><i class="fa fa-check"></i><b>9.2</b> Point-valued and interval-ranged estimates</a><ul>
<li class="chapter" data-level="9.2.1" data-path="ch-03-04-parameter-estimation-points-intervals.html"><a href="ch-03-04-parameter-estimation-points-intervals.html#point-valued-estimates"><i class="fa fa-check"></i><b>9.2.1</b> Point-valued estimates</a></li>
<li class="chapter" data-level="9.2.2" data-path="ch-03-04-parameter-estimation-points-intervals.html"><a href="ch-03-04-parameter-estimation-points-intervals.html#interval-ranged-estimates"><i class="fa fa-check"></i><b>9.2.2</b> Interval-ranged estimates</a></li>
<li class="chapter" data-level="9.2.3" data-path="ch-03-04-parameter-estimation-points-intervals.html"><a href="ch-03-04-parameter-estimation-points-intervals.html#computing-bayesian-estimates"><i class="fa fa-check"></i><b>9.2.3</b> Computing Bayesian estimates</a></li>
<li class="chapter" data-level="9.2.4" data-path="ch-03-04-parameter-estimation-points-intervals.html"><a href="ch-03-04-parameter-estimation-points-intervals.html#excursion-computing-mles-and-maps-in-r"><i class="fa fa-check"></i><b>9.2.4</b> Excursion: Computing MLEs and MAPs in R</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="Ch-03-03-estimation-algorithms.html"><a href="Ch-03-03-estimation-algorithms.html"><i class="fa fa-check"></i><b>9.3</b> Approximating the posterior</a><ul>
<li class="chapter" data-level="9.3.1" data-path="Ch-03-03-estimation-algorithms.html"><a href="Ch-03-03-estimation-algorithms.html#ch-03-03-MCMC"><i class="fa fa-check"></i><b>9.3.1</b> Of apples and trees: Markov Chain Monte Carlo sampling</a></li>
<li class="chapter" data-level="9.3.2" data-path="Ch-03-03-estimation-algorithms.html"><a href="Ch-03-03-estimation-algorithms.html#ch-03-03-estimation-Stan"><i class="fa fa-check"></i><b>9.3.2</b> Excursion: Probabilistic modeling with Stan</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="ch-03-04-parameter-estimation-normal.html"><a href="ch-03-04-parameter-estimation-normal.html"><i class="fa fa-check"></i><b>9.4</b> Estimating the parameters of a Normal distribution</a><ul>
<li class="chapter" data-level="9.4.1" data-path="ch-03-04-parameter-estimation-normal.html"><a href="ch-03-04-parameter-estimation-normal.html#uninformative-priors"><i class="fa fa-check"></i><b>9.4.1</b> Uninformative priors</a></li>
<li class="chapter" data-level="9.4.2" data-path="ch-03-04-parameter-estimation-normal.html"><a href="ch-03-04-parameter-estimation-normal.html#conjugate-priors"><i class="fa fa-check"></i><b>9.4.2</b> Conjugate priors</a></li>
<li class="chapter" data-level="9.4.3" data-path="ch-03-04-parameter-estimation-normal.html"><a href="ch-03-04-parameter-estimation-normal.html#estimating-the-difference-between-group-means"><i class="fa fa-check"></i><b>9.4.3</b> Estimating the difference between group means</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="Chap-03-06-model-comparison.html"><a href="Chap-03-06-model-comparison.html"><i class="fa fa-check"></i><b>10</b> Model Comparison</a><ul>
<li class="chapter" data-level="10.1" data-path="Chap-03-06-model-comparison-case-study.html"><a href="Chap-03-06-model-comparison-case-study.html"><i class="fa fa-check"></i><b>10.1</b> Case study: recall models</a></li>
<li class="chapter" data-level="10.2" data-path="Chap-03-06-model-comparison-AIC.html"><a href="Chap-03-06-model-comparison-AIC.html"><i class="fa fa-check"></i><b>10.2</b> Akaike Information Criterion</a></li>
<li class="chapter" data-level="10.3" data-path="Chap-03-06-model-comparison-BF.html"><a href="Chap-03-06-model-comparison-BF.html"><i class="fa fa-check"></i><b>10.3</b> Bayes factors</a><ul>
<li class="chapter" data-level="10.3.1" data-path="Chap-03-06-model-comparison-BF.html"><a href="Chap-03-06-model-comparison-BF.html#Chap-03-06-model-comparison-BF-grid"><i class="fa fa-check"></i><b>10.3.1</b> Grid approximation</a></li>
<li class="chapter" data-level="10.3.2" data-path="Chap-03-06-model-comparison-BF.html"><a href="Chap-03-06-model-comparison-BF.html#Chap-03-06-model-comparison-BF-naiveMC"><i class="fa fa-check"></i><b>10.3.2</b> Naive Monte Carlo</a></li>
<li class="chapter" data-level="10.3.3" data-path="Chap-03-06-model-comparison-BF.html"><a href="Chap-03-06-model-comparison-BF.html#Chap-03-06-model-comparison-BF-bridge"><i class="fa fa-check"></i><b>10.3.3</b> Excursion: Bridge sampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ch-03-07-hypothesis-testing-Bayes.html"><a href="ch-03-07-hypothesis-testing-Bayes.html"><i class="fa fa-check"></i><b>11</b> Bayesian hypothesis testing</a><ul>
<li class="chapter" data-level="11.1" data-path="ch-03-07-hypothesis-testing-Bayes-hypotheses.html"><a href="ch-03-07-hypothesis-testing-Bayes-hypotheses.html"><i class="fa fa-check"></i><b>11.1</b> Statistical hypotheses</a></li>
<li class="chapter" data-level="11.2" data-path="data-and-models-for-this-chapter.html"><a href="data-and-models-for-this-chapter.html"><i class="fa fa-check"></i><b>11.2</b> Data and models for this chapter</a><ul>
<li class="chapter" data-level="11.2.1" data-path="data-and-models-for-this-chapter.html"><a href="data-and-models-for-this-chapter.html#section-1"><i class="fa fa-check"></i><b>11.2.1</b> 24/7</a></li>
<li class="chapter" data-level="11.2.2" data-path="data-and-models-for-this-chapter.html"><a href="data-and-models-for-this-chapter.html#simon-task"><i class="fa fa-check"></i><b>11.2.2</b> Simon task</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="ch-03-05-Bayes-testing-estimation.html"><a href="ch-03-05-Bayes-testing-estimation.html"><i class="fa fa-check"></i><b>11.3</b> Testing via posterior estimation</a><ul>
<li class="chapter" data-level="11.3.1" data-path="ch-03-05-Bayes-testing-estimation.html"><a href="ch-03-05-Bayes-testing-estimation.html#example-247"><i class="fa fa-check"></i><b>11.3.1</b> Example: 24/7</a></li>
<li class="chapter" data-level="11.3.2" data-path="ch-03-05-Bayes-testing-estimation.html"><a href="ch-03-05-Bayes-testing-estimation.html#example-simon-task"><i class="fa fa-check"></i><b>11.3.2</b> Example: Simon Task</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="ch-03-05-Bayesian-testing-comparison.html"><a href="ch-03-05-Bayesian-testing-comparison.html"><i class="fa fa-check"></i><b>11.4</b> Testing via model comparison</a><ul>
<li class="chapter" data-level="11.4.1" data-path="ch-03-05-Bayesian-testing-comparison.html"><a href="ch-03-05-Bayesian-testing-comparison.html#ch-03-07-hypothesis-testing-Bayes-Savage-Dickey"><i class="fa fa-check"></i><b>11.4.1</b> The Savage-Dickey method</a></li>
<li class="chapter" data-level="11.4.2" data-path="ch-03-05-Bayesian-testing-comparison.html"><a href="ch-03-05-Bayesian-testing-comparison.html#ch-03-07-hypothesis-testing-Bayes-encompassing-models"><i class="fa fa-check"></i><b>11.4.2</b> Encompassing models</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Applied (generalized) linear modeling</b></span></li>
<li class="chapter" data-level="12" data-path="Chap-04-01-simple-linear-regression.html"><a href="Chap-04-01-simple-linear-regression.html"><i class="fa fa-check"></i><b>12</b> Linear regression</a><ul>
<li class="chapter" data-level="12.1" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html"><i class="fa fa-check"></i><b>12.1</b> Ordinary least squares regression</a><ul>
<li class="chapter" data-level="12.1.1" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html#prediction-without-any-further-information"><i class="fa fa-check"></i><b>12.1.1</b> Prediction without any further information</a></li>
<li class="chapter" data-level="12.1.2" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html#prediction-with-knowledge-of-unemployment-rate"><i class="fa fa-check"></i><b>12.1.2</b> Prediction with knowledge of unemployment rate</a></li>
<li class="chapter" data-level="12.1.3" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html#linear-regression-general-problem-formulation"><i class="fa fa-check"></i><b>12.1.3</b> Linear regression: general problem formulation</a></li>
<li class="chapter" data-level="12.1.4" data-path="ordinary-least-squares-regression.html"><a href="ordinary-least-squares-regression.html#finding-the-ols-solution"><i class="fa fa-check"></i><b>12.1.4</b> Finding the OLS-solution</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="Chap-04-01-linear-regression-MLE.html"><a href="Chap-04-01-linear-regression-MLE.html"><i class="fa fa-check"></i><b>12.2</b> A maximum-likelihood approach</a><ul>
<li class="chapter" data-level="12.2.1" data-path="Chap-04-01-linear-regression-MLE.html"><a href="Chap-04-01-linear-regression-MLE.html#a-likelihood-based-model"><i class="fa fa-check"></i><b>12.2.1</b> A likelihood-based model</a></li>
<li class="chapter" data-level="12.2.2" data-path="Chap-04-01-linear-regression-MLE.html"><a href="Chap-04-01-linear-regression-MLE.html#finding-the-mle-solution-with-optim"><i class="fa fa-check"></i><b>12.2.2</b> Finding the MLE-solution with <code>optim</code></a></li>
<li class="chapter" data-level="12.2.3" data-path="Chap-04-01-linear-regression-MLE.html"><a href="Chap-04-01-linear-regression-MLE.html#finding-the-mle-solution-with-glm"><i class="fa fa-check"></i><b>12.2.3</b> Finding the MLE-solution with <code>glm</code></a></li>
<li class="chapter" data-level="12.2.4" data-path="Chap-04-01-linear-regression-MLE.html"><a href="Chap-04-01-linear-regression-MLE.html#finding-the-mle-solution-with-math"><i class="fa fa-check"></i><b>12.2.4</b> Finding the MLE-solution with math</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="a-bayesian-approach.html"><a href="a-bayesian-approach.html"><i class="fa fa-check"></i><b>12.3</b> A Bayesian approach</a></li>
<li class="chapter" data-level="12.4" data-path="comparison-of-approaches.html"><a href="comparison-of-approaches.html"><i class="fa fa-check"></i><b>12.4</b> Comparison of approaches</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Chap-04-02-Bayes-regression-practice.html"><a href="Chap-04-02-Bayes-regression-practice.html"><i class="fa fa-check"></i><b>13</b> Bayesian regression in practice</a><ul>
<li class="chapter" data-level="13.1" data-path="simple-linear-regression-with-brms.html"><a href="simple-linear-regression-with-brms.html"><i class="fa fa-check"></i><b>13.1</b> Simple linear regression with <code>brms</code></a></li>
<li class="chapter" data-level="13.2" data-path="extracting-posterior-samples.html"><a href="extracting-posterior-samples.html"><i class="fa fa-check"></i><b>13.2</b> Extracting posterior samples</a></li>
<li class="chapter" data-level="13.3" data-path="excursion-inspecting-the-underlying-stan-code.html"><a href="excursion-inspecting-the-underlying-stan-code.html"><i class="fa fa-check"></i><b>13.3</b> [Excursion:] Inspecting the underlying Stan code</a></li>
<li class="chapter" data-level="13.4" data-path="setting-priors.html"><a href="setting-priors.html"><i class="fa fa-check"></i><b>13.4</b> Setting priors</a></li>
<li class="chapter" data-level="13.5" data-path="posterior-predictions.html"><a href="posterior-predictions.html"><i class="fa fa-check"></i><b>13.5</b> Posterior predictions</a></li>
<li class="chapter" data-level="13.6" data-path="testing-hypotheses.html"><a href="testing-hypotheses.html"><i class="fa fa-check"></i><b>13.6</b> Testing hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Chap-04-03-predictors.html"><a href="Chap-04-03-predictors.html"><i class="fa fa-check"></i><b>14</b> Categorical predictors</a><ul>
<li class="chapter" data-level="14.1" data-path="Chap-04-03-predictors-two-levels.html"><a href="Chap-04-03-predictors-two-levels.html"><i class="fa fa-check"></i><b>14.1</b> Single two-level predictor</a></li>
<li class="chapter" data-level="14.2" data-path="Chap-04-03-predictors-multi-levels.html"><a href="Chap-04-03-predictors-multi-levels.html"><i class="fa fa-check"></i><b>14.2</b> Single multi-level predictor</a></li>
<li class="chapter" data-level="14.3" data-path="Chap-04-03-predictors-multiple-predictors.html"><a href="Chap-04-03-predictors-multiple-predictors.html"><i class="fa fa-check"></i><b>14.3</b> Multiple predictors</a><ul>
<li class="chapter" data-level="14.3.1" data-path="Chap-04-03-predictors-multiple-predictors.html"><a href="Chap-04-03-predictors-multiple-predictors.html#treatment-coding"><i class="fa fa-check"></i><b>14.3.1</b> Treatment coding</a></li>
<li class="chapter" data-level="14.3.2" data-path="Chap-04-03-predictors-multiple-predictors.html"><a href="Chap-04-03-predictors-multiple-predictors.html#sum-coding"><i class="fa fa-check"></i><b>14.3.2</b> Sum coding</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="Chap-04-04-GLM.html"><a href="Chap-04-04-GLM.html"><i class="fa fa-check"></i><b>15</b> Generalized linear model</a><ul>
<li class="chapter" data-level="15.1" data-path="generalizing-the-linear-regression-model.html"><a href="generalizing-the-linear-regression-model.html"><i class="fa fa-check"></i><b>15.1</b> Generalizing the linear regression model</a></li>
<li class="chapter" data-level="15.2" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>15.2</b> Logistic regression</a></li>
</ul></li>
<li class="part"><span><b>V Frequentist statistics</b></span></li>
<li class="chapter" data-level="16" data-path="ch-05-01-frequentist-hypothesis-testing.html"><a href="ch-05-01-frequentist-hypothesis-testing.html"><i class="fa fa-check"></i><b>16</b> Null Hypothesis Significance Testing</a><ul>
<li class="chapter" data-level="16.1" data-path="ch-05-01-frequentist-testing-overview.html"><a href="ch-05-01-frequentist-testing-overview.html"><i class="fa fa-check"></i><b>16.1</b> Frequentist statistics: why &amp; how</a></li>
<li class="chapter" data-level="16.2" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html"><i class="fa fa-check"></i><b>16.2</b> Quantifying evidence against a null-model with <em>p</em>-values</a><ul>
<li class="chapter" data-level="16.2.1" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#frequentist-null-models"><i class="fa fa-check"></i><b>16.2.1</b> Frequentist null-models</a></li>
<li class="chapter" data-level="16.2.2" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#one--vs.-two-sided-p-values"><i class="fa fa-check"></i><b>16.2.2</b> One- vs. two-sided <span class="math inline">\(p\)</span>-values</a></li>
<li class="chapter" data-level="16.2.3" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#significance-categorical-decisions"><i class="fa fa-check"></i><b>16.2.3</b> Significance &amp; categorical decisions</a></li>
<li class="chapter" data-level="16.2.4" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#how-not-to-interpret-p-values"><i class="fa fa-check"></i><b>16.2.4</b> How (not) to interpret <em>p</em>-values</a></li>
<li class="chapter" data-level="16.2.5" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#excursion-distribution-of-p-values"><i class="fa fa-check"></i><b>16.2.5</b> [Excursion] Distribution of <span class="math inline">\(p\)</span>-values</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="ch-03-05-hypothesis-testing-CLT.html"><a href="ch-03-05-hypothesis-testing-CLT.html"><i class="fa fa-check"></i><b>16.3</b> [Excursion] Central Limit Theorem</a></li>
<li class="chapter" data-level="16.4" data-path="ch-03-04-hypothesis-significance-errors.html"><a href="ch-03-04-hypothesis-significance-errors.html"><i class="fa fa-check"></i><b>16.4</b> [Excursion] The Neyman-Pearson approach</a></li>
<li class="chapter" data-level="16.5" data-path="ch-05-01-frequentist-testing-confidence-intervals.html"><a href="ch-05-01-frequentist-testing-confidence-intervals.html"><i class="fa fa-check"></i><b>16.5</b> Confidence intervals</a><ul>
<li class="chapter" data-level="16.5.1" data-path="ch-05-01-frequentist-testing-confidence-intervals.html"><a href="ch-05-01-frequentist-testing-confidence-intervals.html#relation-of-p-values-to-confidence-intervals"><i class="fa fa-check"></i><b>16.5.1</b> Relation of <em>p</em>-values to confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html"><i class="fa fa-check"></i><b>16.6</b> Selected tests</a><ul>
<li class="chapter" data-level="16.6.1" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-Pearsons-Chi"><i class="fa fa-check"></i><b>16.6.1</b> Pearson’s <span class="math inline">\(\chi^2\)</span>-tests</a></li>
<li class="chapter" data-level="16.6.2" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-z-test"><i class="fa fa-check"></i><b>16.6.2</b> <em>z</em>-test</a></li>
<li class="chapter" data-level="16.6.3" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-t-test"><i class="fa fa-check"></i><b>16.6.3</b> <em>t</em>-tests</a></li>
<li class="chapter" data-level="16.6.4" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-ANOVA"><i class="fa fa-check"></i><b>16.6.4</b> ANOVA</a></li>
<li class="chapter" data-level="16.6.5" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#linear-regression"><i class="fa fa-check"></i><b>16.6.5</b> Linear regression</a></li>
<li class="chapter" data-level="16.6.6" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#Chap-05-01-LR-test"><i class="fa fa-check"></i><b>16.6.6</b> Likelihood-Ratio Test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="ch-05-02-comparison-freq-Bayes.html"><a href="ch-05-02-comparison-freq-Bayes.html"><i class="fa fa-check"></i><b>17</b> Comparing frequentist and Bayesian statistics</a><ul>
<li class="chapter" data-level="17.1" data-path="frequentist-and-bayesian-statistical-models.html"><a href="frequentist-and-bayesian-statistical-models.html"><i class="fa fa-check"></i><b>17.1</b> Frequentist and Bayesian statistical models</a></li>
<li class="chapter" data-level="17.2" data-path="approximation-in-the-model-or-through-the-computation.html"><a href="approximation-in-the-model-or-through-the-computation.html"><i class="fa fa-check"></i><b>17.2</b> Approximation: in the model or through the computation</a></li>
<li class="chapter" data-level="17.3" data-path="mc-simulated-p-values.html"><a href="mc-simulated-p-values.html"><i class="fa fa-check"></i><b>17.3</b> MC-simulated <span class="math inline">\(p\)</span>-values</a></li>
<li class="chapter" data-level="17.4" data-path="bayesian-p-values-model-checking.html"><a href="bayesian-p-values-model-checking.html"><i class="fa fa-check"></i><b>17.4</b> Bayesian <span class="math inline">\(p\)</span>-values &amp; model checking</a></li>
<li class="chapter" data-level="17.5" data-path="ch-05-01-estimation-comparison.html"><a href="ch-05-01-estimation-comparison.html"><i class="fa fa-check"></i><b>17.5</b> Comparing Bayesian and frequentist estimates</a></li>
<li class="chapter" data-level="17.6" data-path="beliefs-decisions-and-long-term-error.html"><a href="beliefs-decisions-and-long-term-error.html"><i class="fa fa-check"></i><b>17.6</b> Beliefs, decisions and long-term error</a></li>
<li class="chapter" data-level="17.7" data-path="evidence-for-the-null.html"><a href="evidence-for-the-null.html"><i class="fa fa-check"></i><b>17.7</b> Evidence for the null</a></li>
<li class="chapter" data-level="17.8" data-path="Chap-05-02-models-three-pillars.html"><a href="Chap-05-02-models-three-pillars.html"><i class="fa fa-check"></i><b>17.8</b> Three pillars of data analysis</a></li>
<li class="chapter" data-level="17.9" data-path="testing-hypotheses-by-estimation-comparison-model-checking.html"><a href="testing-hypotheses-by-estimation-comparison-model-checking.html"><i class="fa fa-check"></i><b>17.9</b> Testing hypotheses by estimation, comparison &amp; model checking</a></li>
<li class="chapter" data-level="17.10" data-path="jeffreys-lindley-paradox.html"><a href="jeffreys-lindley-paradox.html"><i class="fa fa-check"></i><b>17.10</b> Jeffreys-Lindley paradox</a></li>
<li class="chapter" data-level="17.11" data-path="explicit-beliefs-vs.-implicit-intentions.html"><a href="explicit-beliefs-vs.-implicit-intentions.html"><i class="fa fa-check"></i><b>17.11</b> Explicit beliefs vs. implicit intentions</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="Chap-03-06-model-comparison-BF" class="section level2">
<h2><span class="header-section-number">10.3</span> Bayes factors</h2>
<p>At the end of the previous section, we saw that we can use the AIC-approach to calculate an approximate value of the posterior probability <span class="math inline">\(P(M_{i} \mid D)\)</span> for model <span class="math inline">\(M_{i}\)</span> given data <span class="math inline">\(D\)</span>. The Bayes factor approach is similar to this, but avoids taking priors over models into the equation by focusing on <em>the extent to which data <span class="math inline">\(D\)</span> changes our beliefs about which model is more likely</em>.</p>
<p>Take two Bayesian models:</p>
<ul>
<li><span class="math inline">\(M_1\)</span> has prior <span class="math inline">\(P(\theta_1 \mid M_1)\)</span> and likelihood <span class="math inline">\(P(D \mid \theta_1, M_1)\)</span></li>
<li><span class="math inline">\(M_2\)</span> has prior <span class="math inline">\(P(\theta_2 \mid M_2)\)</span> and likelihood <span class="math inline">\(P(D \mid \theta_2, M_2)\)</span></li>
</ul>
<p>Using Bayes rule, we compute the posterior odds of models (given the data) as the product of the likelihood ratio and the prior odds.</p>
<p><span class="math display">\[\underbrace{\frac{P(M_1 \mid D)}{P(M_2 \mid D)}}_{\text{posterior odds}} = \underbrace{\frac{P(D \mid M_1)}{P(D \mid M_2)}}_{\text{Bayes factor}} \ \underbrace{\frac{P(M_1)}{P(M_2)}}_{\text{prior odds}}\]</span></p>
<p>The likelihood ratio is also called the <strong>Bayes factor</strong>. Formally, the Bayes factor is the factor by which a rational agent changes her prior odds in the light of observed data to arrive at the posterior odds. More intuitively, the Bayes factor quantifies the strength of evidence given by the data about the models of interest. It expresses this evidence in terms of the models’ relative prior predictive accuracy. To see the latter, let’s expand the Bayes factor as what it actually is: the ratio of marginal likelihoods.</p>
<p><span class="math display">\[
\frac{P(D \mid M_1)}{P(D \mid M_2)} = \frac{\int P(\theta_1 \mid M_1) \ P(D \mid \theta_1, M_1) \text{ d}\theta_1}{\int P(\theta_2 \mid M_2) \ P(D \mid \theta_2, M_2) \text{ d}\theta_2}
\]</span></p>
<p>Three insights are to be gained from this expansion. Firstly, the Bayes factor is a measure of how well each model would have predicted the data <em>ex ante</em>, i.e., before having seen any data. In this way, it is diametrically opposed to a concept like AIC, which relies on models’ maximum likelihood fits (therefore <em>using the data</em>, so being <em>ex post</em>).</p>
<p>Secondly, the marginal likelihood of a model is exactly the quantity that we identified (in the context of parameter estimation) as being very hard to compute, especially for complex models. The fact that marginal likelihoods are hard to compute was the reason that methods like MCMC sampling are useful, since they give posterior samples <em>without</em> requiring the calculation of marginal likelihoods.
It follows that Bayes factors can be very difficult to compute in general.
However, for many prominent models, it is possible to calculate Bayes factors analytically if the right kinds of priors are specified <span class="citation">(Rouder et al. <a href="#ref-RouderSpeckman2009:Bayesian-t-test" role="doc-biblioref">2009</a>; Rouder and Morey <a href="#ref-RouderMorey2012:Default-Bayes-F" role="doc-biblioref">2012</a>; Gronau, Ly, and Wagenmakers <a href="#ref-GronauLy2019:Informed-Bayesi" role="doc-biblioref">2019</a>)</span>.
We will see an example of this in Chapter <a href="ch-03-07-hypothesis-testing-Bayes.html#ch-03-07-hypothesis-testing-Bayes">11</a>.
Also, as we will see in the following there are very clever approaches to computing Bayes factors in special cases and good algorithms for approximating marginal likelihoods also for complex models.</p>
<p>Thirdly, Bayes factor model comparison implicitly (and quite vigorously) punishes model complexity, but in a more sophisticated manner than just counting free parameters. To appreciate this intuitively, imagine a model with a large parameter set and a very diffuse, uninformative prior that spreads its probability over a wide range of parameter values. Since Bayes factors are computed based on <em>ex ante</em> predictions, a diffuse model is punished for its imprecision of prior predictions because we integrate over all parameters (weighted by priors) and their associated likelihood.</p>
<p>As for notation, we write:</p>
<p><span class="math display">\[\text{BF}_{12} = \frac{P(D \mid M_1)}{P(D \mid M_2)}\]</span>
for the Bayes factor in favor of model <span class="math inline">\(M_1\)</span> over model <span class="math inline">\(M_2\)</span>. This quantity can take on positive values, which are often translated into natural language as follows:</p>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(BF_{12}\)</span></th>
<th align="center">interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">irrelevant data</td>
</tr>
<tr class="even">
<td align="center">1 - 3</td>
<td align="center">hardly worth ink or breath</td>
</tr>
<tr class="odd">
<td align="center">3 - 6</td>
<td align="center">anecdotal</td>
</tr>
<tr class="even">
<td align="center">6 - 10</td>
<td align="center">now we’re talking: substantial</td>
</tr>
<tr class="odd">
<td align="center">10 - 30</td>
<td align="center">strong</td>
</tr>
<tr class="even">
<td align="center">30 - 100</td>
<td align="center">very strong</td>
</tr>
<tr class="odd">
<td align="center">100 +</td>
<td align="center">decisive (bye, bye <span class="math inline">\(M_2\)</span>!)</td>
</tr>
</tbody>
</table>
<p>As <span class="math inline">\(\text{BF}_{12} = \text{BF}_{21}^{-1}\)</span>, it suffices to give this translation into natural language only for values <span class="math inline">\(\ge 1\)</span>.</p>
<p>There are at least two general approaches to calculating or approximating Bayes factors, paired here with a (non-exhaustive) list of example methods:</p>
<ol style="list-style-type: decimal">
<li>get each model’s marginal likelihood
<ul>
<li>grid approximation (see Section <a href="Chap-03-06-model-comparison-BF.html#Chap-03-06-model-comparison-BF-grid">10.3.1</a>)</li>
<li>by Monte Carlo sampling (see Section <a href="Chap-03-06-model-comparison-BF.html#Chap-03-06-model-comparison-BF-naiveMC">10.3.2</a>)</li>
<li>bridge sampling (see Section <a href="Chap-03-06-model-comparison-BF.html#Chap-03-06-model-comparison-BF-bridge">10.3.3</a>)</li>
</ul></li>
<li>get Bayes factor directly
<ul>
<li>Savage-Dickey method (see Section <a href="ch-03-05-Bayesian-testing-comparison.html#ch-03-07-hypothesis-testing-Bayes-Savage-Dickey">11.4.1</a>)</li>
<li>using encompassing models (see Section <a href="ch-03-05-Bayesian-testing-comparison.html#ch-03-07-hypothesis-testing-Bayes-encompassing-models">11.4.2</a>)</li>
</ul></li>
</ol>
<div id="Chap-03-06-model-comparison-BF-grid" class="section level3">
<h3><span class="header-section-number">10.3.1</span> Grid approximation</h3>
<p>We can use <em>grid approximation</em> to approximate a model’s marginal likelihood if the model is small enough, say, no more than 4-5 free parameters.
Grid approximation considers discrete values for each parameter evenly spaced over the whole range of plausible parameter values, thereby approximating the integral in the definition of marginal likelihoods.</p>
<p>Let’s calculate an example for the comparison of the exponential and the power model of forgetting.
To begin with, we need to define a prior over parameters to obtain Bayesian versions of the exponential and power model.
Here, we assume flat priors over a reasonable range of parameter values for simplicity. For the exponential model, we choose:</p>
<p><span class="math display">\[
\begin{aligned}
P(k \mid a, b, N, M_{\text{exp}}) &amp; = \text{Binom}(k,N, a \exp (-bt_i)) \\
P(a \mid M_{\text{exp}}) &amp; = \text{Uniform}(a, 0, 1.5) \\
P(b \mid M_{\text{exp}}) &amp; = \text{Uniform}(b, 0, 1.5) 
\end{aligned}
\]</span></p>
<p>The (Bayesian) power model is given by:</p>
<p><span class="math display">\[
\begin{aligned}
P(k \mid c, d, N, M_{\text{pow}}) &amp; = \text{Binom}(k,N, c\ t_i^{-d}) \\
P(c \mid M_{\text{pow}}) &amp; = \text{Uniform}(c, 0, 1.5) \\
P(d \mid M_{\text{pow}}) &amp; = \text{Uniform}(d, 0, 1.5) 
\end{aligned}
\]</span></p>
<p>We can also express these models in code, like so:</p>
<div class="sourceCode" id="cb497"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb497-1"><a href="Chap-03-06-model-comparison-BF.html#cb497-1"></a><span class="co"># prior exponential model</span></span>
<span id="cb497-2"><a href="Chap-03-06-model-comparison-BF.html#cb497-2"></a>priorExp &lt;-<span class="st"> </span><span class="cf">function</span>(a, b){</span>
<span id="cb497-3"><a href="Chap-03-06-model-comparison-BF.html#cb497-3"></a>  <span class="kw">dunif</span>(a, <span class="dv">0</span>, <span class="fl">1.5</span>) <span class="op">*</span><span class="st"> </span><span class="kw">dunif</span>(b, <span class="dv">0</span>, <span class="fl">1.5</span>)</span>
<span id="cb497-4"><a href="Chap-03-06-model-comparison-BF.html#cb497-4"></a>}</span>
<span id="cb497-5"><a href="Chap-03-06-model-comparison-BF.html#cb497-5"></a><span class="co"># likelihood function exponential model</span></span>
<span id="cb497-6"><a href="Chap-03-06-model-comparison-BF.html#cb497-6"></a>lhExp &lt;-<span class="st"> </span><span class="cf">function</span>(a, b){</span>
<span id="cb497-7"><a href="Chap-03-06-model-comparison-BF.html#cb497-7"></a>  theta &lt;-<span class="st"> </span>a <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>b <span class="op">*</span><span class="st"> </span>t)</span>
<span id="cb497-8"><a href="Chap-03-06-model-comparison-BF.html#cb497-8"></a>  theta[theta <span class="op">&lt;=</span><span class="st"> </span><span class="fl">0.0</span>] &lt;-<span class="st"> </span><span class="fl">1.0e-5</span></span>
<span id="cb497-9"><a href="Chap-03-06-model-comparison-BF.html#cb497-9"></a>  theta[theta <span class="op">&gt;=</span><span class="st"> </span><span class="fl">1.0</span>] &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="fl">1.0e-5</span></span>
<span id="cb497-10"><a href="Chap-03-06-model-comparison-BF.html#cb497-10"></a>  <span class="kw">prod</span>(<span class="kw">dbinom</span>(<span class="dt">x =</span> obs, <span class="dt">prob =</span> theta, <span class="dt">size =</span> <span class="dv">100</span>))</span>
<span id="cb497-11"><a href="Chap-03-06-model-comparison-BF.html#cb497-11"></a>}</span>
<span id="cb497-12"><a href="Chap-03-06-model-comparison-BF.html#cb497-12"></a></span>
<span id="cb497-13"><a href="Chap-03-06-model-comparison-BF.html#cb497-13"></a><span class="co"># prior power model</span></span>
<span id="cb497-14"><a href="Chap-03-06-model-comparison-BF.html#cb497-14"></a>priorPow &lt;-<span class="st"> </span><span class="cf">function</span>(c, d){</span>
<span id="cb497-15"><a href="Chap-03-06-model-comparison-BF.html#cb497-15"></a>  <span class="kw">dunif</span>(c, <span class="dv">0</span>, <span class="fl">1.5</span>) <span class="op">*</span><span class="st"> </span><span class="kw">dunif</span>(d, <span class="dv">0</span>, <span class="fl">1.5</span>)</span>
<span id="cb497-16"><a href="Chap-03-06-model-comparison-BF.html#cb497-16"></a>}</span>
<span id="cb497-17"><a href="Chap-03-06-model-comparison-BF.html#cb497-17"></a><span class="co"># likelihood function power model</span></span>
<span id="cb497-18"><a href="Chap-03-06-model-comparison-BF.html#cb497-18"></a>lhPow &lt;-<span class="st"> </span><span class="cf">function</span>(c, d){</span>
<span id="cb497-19"><a href="Chap-03-06-model-comparison-BF.html#cb497-19"></a>  theta &lt;-<span class="st"> </span>c <span class="op">*</span><span class="st"> </span>t<span class="op">^</span>(<span class="op">-</span>d)</span>
<span id="cb497-20"><a href="Chap-03-06-model-comparison-BF.html#cb497-20"></a>  theta[theta <span class="op">&lt;=</span><span class="st"> </span><span class="fl">0.0</span>] &lt;-<span class="st"> </span><span class="fl">1.0e-5</span></span>
<span id="cb497-21"><a href="Chap-03-06-model-comparison-BF.html#cb497-21"></a>  theta[theta <span class="op">&gt;=</span><span class="st"> </span><span class="fl">1.0</span>] &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="fl">1.0e-5</span></span>
<span id="cb497-22"><a href="Chap-03-06-model-comparison-BF.html#cb497-22"></a>  <span class="kw">prod</span>(<span class="kw">dbinom</span>(<span class="dt">x =</span> obs, <span class="dt">prob =</span> theta, <span class="dt">size =</span> <span class="dv">100</span>))</span>
<span id="cb497-23"><a href="Chap-03-06-model-comparison-BF.html#cb497-23"></a>}</span></code></pre></div>
<p>To approximate each model’s marginal likelihood via grid approximation, we consider equally spaced values for both parameters (a tighly knit grid), assess the prior and likelihood for each parameter pair and finally take the sum over all of the visited values:</p>
<div class="sourceCode" id="cb498"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb498-1"><a href="Chap-03-06-model-comparison-BF.html#cb498-1"></a><span class="co"># make sure the functions accept vector input</span></span>
<span id="cb498-2"><a href="Chap-03-06-model-comparison-BF.html#cb498-2"></a>lhExp &lt;-<span class="st"> </span><span class="kw">Vectorize</span>(lhExp)</span>
<span id="cb498-3"><a href="Chap-03-06-model-comparison-BF.html#cb498-3"></a>lhPow &lt;-<span class="st"> </span><span class="kw">Vectorize</span>(lhPow)</span>
<span id="cb498-4"><a href="Chap-03-06-model-comparison-BF.html#cb498-4"></a></span>
<span id="cb498-5"><a href="Chap-03-06-model-comparison-BF.html#cb498-5"></a><span class="co"># define the step size of the grid</span></span>
<span id="cb498-6"><a href="Chap-03-06-model-comparison-BF.html#cb498-6"></a>stepsize &lt;-<span class="st"> </span><span class="fl">0.01</span></span>
<span id="cb498-7"><a href="Chap-03-06-model-comparison-BF.html#cb498-7"></a><span class="co"># calculate the marginal likelihood</span></span>
<span id="cb498-8"><a href="Chap-03-06-model-comparison-BF.html#cb498-8"></a>marg_lh &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(</span>
<span id="cb498-9"><a href="Chap-03-06-model-comparison-BF.html#cb498-9"></a>  <span class="dt">x =</span> <span class="kw">seq</span>(<span class="fl">0.005</span>, <span class="fl">1.495</span>, <span class="dt">by =</span> stepsize),</span>
<span id="cb498-10"><a href="Chap-03-06-model-comparison-BF.html#cb498-10"></a>  <span class="dt">y =</span> <span class="kw">seq</span>(<span class="fl">0.005</span>, <span class="fl">1.495</span>, <span class="dt">by =</span> stepsize)</span>
<span id="cb498-11"><a href="Chap-03-06-model-comparison-BF.html#cb498-11"></a>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb498-12"><a href="Chap-03-06-model-comparison-BF.html#cb498-12"></a><span class="st">  </span><span class="kw">mutate</span>(</span>
<span id="cb498-13"><a href="Chap-03-06-model-comparison-BF.html#cb498-13"></a>    <span class="dt">lhExp =</span> <span class="kw">lhExp</span>(x, y), <span class="dt">priExp =</span> <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(x),  <span class="co"># uniform priors!</span></span>
<span id="cb498-14"><a href="Chap-03-06-model-comparison-BF.html#cb498-14"></a>    <span class="dt">lhPow =</span> <span class="kw">lhPow</span>(x, y), <span class="dt">priPow =</span> <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(x)</span>
<span id="cb498-15"><a href="Chap-03-06-model-comparison-BF.html#cb498-15"></a>  )</span>
<span id="cb498-16"><a href="Chap-03-06-model-comparison-BF.html#cb498-16"></a><span class="co"># output result</span></span>
<span id="cb498-17"><a href="Chap-03-06-model-comparison-BF.html#cb498-17"></a><span class="kw">str_c</span>(</span>
<span id="cb498-18"><a href="Chap-03-06-model-comparison-BF.html#cb498-18"></a>  <span class="st">&quot;BF in favor of exponential model: &quot;</span>, </span>
<span id="cb498-19"><a href="Chap-03-06-model-comparison-BF.html#cb498-19"></a>  <span class="kw">with</span>(marg_lh, <span class="kw">sum</span>(priExp <span class="op">*</span><span class="st"> </span>lhExp) <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(priPow <span class="op">*</span><span class="st"> </span>lhPow)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dv">2</span>)</span>
<span id="cb498-20"><a href="Chap-03-06-model-comparison-BF.html#cb498-20"></a>)</span></code></pre></div>
<pre><code>## [1] &quot;BF in favor of exponential model: 1221.39&quot;</code></pre>
<p>Based on this computation, we would be entitled to conclude that the data provide overwhelming evidence in favor of the exponential model. The result tells us that a rational agent should adjust her prior odds by a factor of more than 1000 in favor of the exponential model when updating her beliefs with the data. In other words, the data tilt our beliefs very strongly towards the exponential model, no matter what we believed initially. In this sense, the data provide strong evidence for the exponential model.</p>
</div>
<div id="Chap-03-06-model-comparison-BF-naiveMC" class="section level3">
<h3><span class="header-section-number">10.3.2</span> Naive Monte Carlo</h3>
<p>For simple models (with maybe 4-5 free parameters), we can also use naive Monte Carlo sampling to approximate Bayes factors. In particular, we can approximate the marginal likelihood by taking samples from the prior, calculating the likelihood of the data for each sampled parameter tuple, and then averaging over all calculated likelihoods:</p>
<p><span class="math display">\[P(D, M_i) = \int P(D \mid \theta, M_i) \ P(\theta \mid M_i) \ \text{d}\theta \approx \frac{1}{n} \sum^{n}_{\theta_j \sim P(\theta \mid M_i)} P(D \mid \theta_j, M_i)\]</span></p>
<p>Here is a calculation using one million samples from the prior of each model:</p>
<div class="sourceCode" id="cb500"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb500-1"><a href="Chap-03-06-model-comparison-BF.html#cb500-1"></a>nSamples &lt;-<span class="st"> </span><span class="dv">1000000</span></span>
<span id="cb500-2"><a href="Chap-03-06-model-comparison-BF.html#cb500-2"></a><span class="co"># sample from the prior</span></span>
<span id="cb500-3"><a href="Chap-03-06-model-comparison-BF.html#cb500-3"></a>a &lt;-<span class="st"> </span><span class="kw">runif</span>(nSamples, <span class="dv">0</span>, <span class="fl">1.5</span>)</span>
<span id="cb500-4"><a href="Chap-03-06-model-comparison-BF.html#cb500-4"></a>b &lt;-<span class="st"> </span><span class="kw">runif</span>(nSamples, <span class="dv">0</span>, <span class="fl">1.5</span>)</span>
<span id="cb500-5"><a href="Chap-03-06-model-comparison-BF.html#cb500-5"></a><span class="co"># calculate likelihood of data for each sample</span></span>
<span id="cb500-6"><a href="Chap-03-06-model-comparison-BF.html#cb500-6"></a>lhExpVec &lt;-<span class="st"> </span><span class="kw">lhExp</span>(a, b)</span>
<span id="cb500-7"><a href="Chap-03-06-model-comparison-BF.html#cb500-7"></a>lhPowVec &lt;-<span class="st"> </span><span class="kw">lhPow</span>(a, b)</span>
<span id="cb500-8"><a href="Chap-03-06-model-comparison-BF.html#cb500-8"></a><span class="co"># compute marginal likelihoods</span></span>
<span id="cb500-9"><a href="Chap-03-06-model-comparison-BF.html#cb500-9"></a><span class="kw">str_c</span>(</span>
<span id="cb500-10"><a href="Chap-03-06-model-comparison-BF.html#cb500-10"></a> <span class="st">&quot;BF in favor of exponential model: &quot;</span>, </span>
<span id="cb500-11"><a href="Chap-03-06-model-comparison-BF.html#cb500-11"></a> <span class="kw">round</span>(<span class="kw">mean</span>(lhExpVec) <span class="op">/</span><span class="st"> </span><span class="kw">mean</span>(lhPowVec), <span class="dv">2</span>)</span>
<span id="cb500-12"><a href="Chap-03-06-model-comparison-BF.html#cb500-12"></a>)</span></code></pre></div>
<pre><code>## [1] &quot;BF in favor of exponential model: 1251.66&quot;</code></pre>
<p>We can also check the time course of our MC-estimate by a plot like that in Figure <a href="Chap-03-06-model-comparison-BF.html#fig:Chap-03-06-model-comparison-MC-estimate-time">10.3</a>.
The plot shows the current estimate of the Bayes factor on the <span class="math inline">\(y\)</span>-axis after having taken the number of samples given on the <span class="math inline">\(x\)</span>-axis.
We see that the initial calculations (after only 10,000 samples) are far off, but that the approximation finally gets reasonably close to the value calculated by grid approximation, which is shown as the red line.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Chap-03-06-model-comparison-MC-estimate-time"></span>
<img src="I2DA_files/figure-html/Chap-03-06-model-comparison-MC-estimate-time-1.png" alt="Temporal development (as more samples come in) of the Monte Carlo estimate of the Bayes factor in favor of the exponential model over the power model of forgetting. The red horizontal line indicates the Bayes factor estimate obtained previously via grid approximation." width="672" />
<p class="caption">
Figure 10.3: Temporal development (as more samples come in) of the Monte Carlo estimate of the Bayes factor in favor of the exponential model over the power model of forgetting. The red horizontal line indicates the Bayes factor estimate obtained previously via grid approximation.
</p>
</div>
<div class="exercises">
<p><strong>Exercise 11.3</strong></p>
<p>Which statements concerning Bayes Factors (BF) are correct?</p>
<ol style="list-style-type: lower-alpha">
<li>The Bayes Factor shows the absolute probability of a particular model to be a good explanation of the observed data.</li>
<li>If <span class="math inline">\(BF_{12} = 11\)</span>, one should conclude that there is strong evidence in favor of <span class="math inline">\(M_1\)</span>.</li>
<li>Grid approximation allows us to compare no more than five models simultaneously.</li>
<li>With the Naive Monte Carlo method, we can only approximate the BF for models with continuous parameters.</li>
<li>BF computation penalizes more complex models.</li>
</ol>
<div class="collapsibleSolution">
<button class="trigger">
Solution
</button>
<div class="content">
<p>Statements b. and e. are correct.</p>
</div>
</div>
</div>
</div>
<div id="Chap-03-06-model-comparison-BF-bridge" class="section level3">
<h3><span class="header-section-number">10.3.3</span> Excursion: Bridge sampling</h3>
<p>For more complex models (e.g., high-dimensional/hierarchical parameter spaces), naive Monte Carlo methods can be highly inefficient. If random sampling of parameter values from the priors is unlikely to deliver values for which the likelihood of the data is reasonably high, most naive MC samples will contribute very little information to the overall estimate of the marginal likelihood. For this reason, there are better sampling-based procedures which preferentially sample <em>a posteriori</em> credible parameter values (given the data) and use clever math to compensate for using the wrong distribution to sample from. This is the main idea behind approaches like <a href="https://en.wikipedia.org/wiki/Importance_sampling">importance sampling</a>. A very promising approach is in particular <strong>bridge sampling</strong>, which also has its own R package <span class="citation">(Gronau et al. <a href="#ref-GronauSarafoglou2017:A-tutorial-on-b" role="doc-biblioref">2017</a>)</span>.</p>
<p>We will not go into the formal details of this method, but just showcase here an application of the <code>bridgesampling</code> package.
This approach requires samples from the posterior, which we can obtain using Stan (see Section <a href="Ch-03-03-estimation-algorithms.html#ch-03-03-estimation-Stan">9.3.2</a>).
Towards this end, we first assemble the data for input to the Stan program in a list:</p>
<div class="sourceCode" id="cb502"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb502-1"><a href="Chap-03-06-model-comparison-BF.html#cb502-1"></a>forgetting_data &lt;-<span class="st"> </span><span class="kw">list</span>(</span>
<span id="cb502-2"><a href="Chap-03-06-model-comparison-BF.html#cb502-2"></a>  <span class="dt">N =</span> <span class="dv">100</span>,</span>
<span id="cb502-3"><a href="Chap-03-06-model-comparison-BF.html#cb502-3"></a>  <span class="dt">k =</span> obs,</span>
<span id="cb502-4"><a href="Chap-03-06-model-comparison-BF.html#cb502-4"></a>  <span class="dt">t =</span> t</span>
<span id="cb502-5"><a href="Chap-03-06-model-comparison-BF.html#cb502-5"></a>)</span></code></pre></div>
<p>The models are implemented in Stan. We here only show the exponential model.</p>
<pre class="mystan"><code>data {
  int&lt;lower=1&gt; N ;
  int&lt;lower=0,upper=N&gt; k[6] ;
  int&lt;lower=0&gt; t[6];
}
parameters {
  real&lt;lower=0,upper=1.5&gt; a ;
  real&lt;lower=0,upper=1.5&gt; b ;
} 
model {
  // likelihood
  for (i in 1:6) {
    target += binomial_lpmf(k[i] | N,  a * exp(-b * t[i])) ;
  }
}</code></pre>
<link rel="stylesheet" href="hljs.css">
<script src="stan.js"></script>
<script>$('pre.mystan code').each(function(i, block) {hljs.highlightBlock(block);});</script>
<p>We then use Stan to obtain samples from the posterior in the usual way. To get reliable estimates of Bayes factors via bridge sampling, we should take a much larger number of samples than we usually would for a reliable estimation of, say, the posterior means and credible intervals.</p>
<div class="sourceCode" id="cb504"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb504-1"><a href="Chap-03-06-model-comparison-BF.html#cb504-1"></a>stan_fit_expon &lt;-<span class="st"> </span>rstan<span class="op">::</span><span class="kw">stan</span>(</span>
<span id="cb504-2"><a href="Chap-03-06-model-comparison-BF.html#cb504-2"></a>  <span class="co"># where is the Stan code</span></span>
<span id="cb504-3"><a href="Chap-03-06-model-comparison-BF.html#cb504-3"></a>  <span class="dt">file =</span> <span class="st">&#39;models_stan/model_comp_exponential_forgetting.stan&#39;</span>,</span>
<span id="cb504-4"><a href="Chap-03-06-model-comparison-BF.html#cb504-4"></a>  <span class="co"># data to supply to the Stan program</span></span>
<span id="cb504-5"><a href="Chap-03-06-model-comparison-BF.html#cb504-5"></a>  <span class="dt">data =</span> forgetting_data,</span>
<span id="cb504-6"><a href="Chap-03-06-model-comparison-BF.html#cb504-6"></a>  <span class="co"># how many iterations of MCMC</span></span>
<span id="cb504-7"><a href="Chap-03-06-model-comparison-BF.html#cb504-7"></a>  <span class="dt">iter =</span> <span class="dv">20000</span>,</span>
<span id="cb504-8"><a href="Chap-03-06-model-comparison-BF.html#cb504-8"></a>  <span class="co"># how many warmup steps</span></span>
<span id="cb504-9"><a href="Chap-03-06-model-comparison-BF.html#cb504-9"></a>  <span class="dt">warmup =</span> <span class="dv">2000</span></span>
<span id="cb504-10"><a href="Chap-03-06-model-comparison-BF.html#cb504-10"></a>)</span></code></pre></div>
<pre><code>## 
## SAMPLING FOR MODEL &#39;model_comp_exponential_forgetting&#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 1.4e-05 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:     1 / 20000 [  0%]  (Warmup)
## Chain 1: Iteration:  2000 / 20000 [ 10%]  (Warmup)
## Chain 1: Iteration:  2001 / 20000 [ 10%]  (Sampling)
## Chain 1: Iteration:  4000 / 20000 [ 20%]  (Sampling)
## Chain 1: Iteration:  6000 / 20000 [ 30%]  (Sampling)
## Chain 1: Iteration:  8000 / 20000 [ 40%]  (Sampling)
## Chain 1: Iteration: 10000 / 20000 [ 50%]  (Sampling)
## Chain 1: Iteration: 12000 / 20000 [ 60%]  (Sampling)
## Chain 1: Iteration: 14000 / 20000 [ 70%]  (Sampling)
## Chain 1: Iteration: 16000 / 20000 [ 80%]  (Sampling)
## Chain 1: Iteration: 18000 / 20000 [ 90%]  (Sampling)
## Chain 1: Iteration: 20000 / 20000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.055513 seconds (Warm-up)
## Chain 1:                0.444982 seconds (Sampling)
## Chain 1:                0.500495 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &#39;model_comp_exponential_forgetting&#39; NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 1.1e-05 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:     1 / 20000 [  0%]  (Warmup)
## Chain 2: Iteration:  2000 / 20000 [ 10%]  (Warmup)
## Chain 2: Iteration:  2001 / 20000 [ 10%]  (Sampling)
## Chain 2: Iteration:  4000 / 20000 [ 20%]  (Sampling)
## Chain 2: Iteration:  6000 / 20000 [ 30%]  (Sampling)
## Chain 2: Iteration:  8000 / 20000 [ 40%]  (Sampling)
## Chain 2: Iteration: 10000 / 20000 [ 50%]  (Sampling)
## Chain 2: Iteration: 12000 / 20000 [ 60%]  (Sampling)
## Chain 2: Iteration: 14000 / 20000 [ 70%]  (Sampling)
## Chain 2: Iteration: 16000 / 20000 [ 80%]  (Sampling)
## Chain 2: Iteration: 18000 / 20000 [ 90%]  (Sampling)
## Chain 2: Iteration: 20000 / 20000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.054433 seconds (Warm-up)
## Chain 2:                0.461635 seconds (Sampling)
## Chain 2:                0.516068 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL &#39;model_comp_exponential_forgetting&#39; NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 9e-06 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:     1 / 20000 [  0%]  (Warmup)
## Chain 3: Iteration:  2000 / 20000 [ 10%]  (Warmup)
## Chain 3: Iteration:  2001 / 20000 [ 10%]  (Sampling)
## Chain 3: Iteration:  4000 / 20000 [ 20%]  (Sampling)
## Chain 3: Iteration:  6000 / 20000 [ 30%]  (Sampling)
## Chain 3: Iteration:  8000 / 20000 [ 40%]  (Sampling)
## Chain 3: Iteration: 10000 / 20000 [ 50%]  (Sampling)
## Chain 3: Iteration: 12000 / 20000 [ 60%]  (Sampling)
## Chain 3: Iteration: 14000 / 20000 [ 70%]  (Sampling)
## Chain 3: Iteration: 16000 / 20000 [ 80%]  (Sampling)
## Chain 3: Iteration: 18000 / 20000 [ 90%]  (Sampling)
## Chain 3: Iteration: 20000 / 20000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 0.05527 seconds (Warm-up)
## Chain 3:                0.487729 seconds (Sampling)
## Chain 3:                0.542999 seconds (Total)
## Chain 3: 
## 
## SAMPLING FOR MODEL &#39;model_comp_exponential_forgetting&#39; NOW (CHAIN 4).
## Chain 4: Rejecting initial value:
## Chain 4:   Error evaluating the log probability at the initial value.
## Chain 4: Exception: binomial_lpmf: Probability parameter is 1.02476, but must be in the interval [0, 1]  (in &#39;model3e961577733f_model_comp_exponential_forgetting&#39; at line 13)
## 
## Chain 4: 
## Chain 4: Gradient evaluation took 1e-05 seconds
## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.
## Chain 4: Adjust your expectations accordingly!
## Chain 4: 
## Chain 4: 
## Chain 4: Iteration:     1 / 20000 [  0%]  (Warmup)
## Chain 4: Iteration:  2000 / 20000 [ 10%]  (Warmup)
## Chain 4: Iteration:  2001 / 20000 [ 10%]  (Sampling)
## Chain 4: Iteration:  4000 / 20000 [ 20%]  (Sampling)
## Chain 4: Iteration:  6000 / 20000 [ 30%]  (Sampling)
## Chain 4: Iteration:  8000 / 20000 [ 40%]  (Sampling)
## Chain 4: Iteration: 10000 / 20000 [ 50%]  (Sampling)
## Chain 4: Iteration: 12000 / 20000 [ 60%]  (Sampling)
## Chain 4: Iteration: 14000 / 20000 [ 70%]  (Sampling)
## Chain 4: Iteration: 16000 / 20000 [ 80%]  (Sampling)
## Chain 4: Iteration: 18000 / 20000 [ 90%]  (Sampling)
## Chain 4: Iteration: 20000 / 20000 [100%]  (Sampling)
## Chain 4: 
## Chain 4:  Elapsed Time: 0.055248 seconds (Warm-up)
## Chain 4:                0.424547 seconds (Sampling)
## Chain 4:                0.479795 seconds (Total)
## Chain 4:</code></pre>
<div class="sourceCode" id="cb506"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb506-1"><a href="Chap-03-06-model-comparison-BF.html#cb506-1"></a>stan_fit_power &lt;-<span class="st"> </span>rstan<span class="op">::</span><span class="kw">stan</span>(</span>
<span id="cb506-2"><a href="Chap-03-06-model-comparison-BF.html#cb506-2"></a>  <span class="co"># where is the Stan code</span></span>
<span id="cb506-3"><a href="Chap-03-06-model-comparison-BF.html#cb506-3"></a>  <span class="dt">file =</span> <span class="st">&#39;models_stan/model_comp_power_forgetting.stan&#39;</span>,</span>
<span id="cb506-4"><a href="Chap-03-06-model-comparison-BF.html#cb506-4"></a>  <span class="co"># data to supply to the Stan program</span></span>
<span id="cb506-5"><a href="Chap-03-06-model-comparison-BF.html#cb506-5"></a>  <span class="dt">data =</span> forgetting_data,</span>
<span id="cb506-6"><a href="Chap-03-06-model-comparison-BF.html#cb506-6"></a>  <span class="co"># how many iterations of MCMC</span></span>
<span id="cb506-7"><a href="Chap-03-06-model-comparison-BF.html#cb506-7"></a>  <span class="dt">iter =</span> <span class="dv">20000</span>,</span>
<span id="cb506-8"><a href="Chap-03-06-model-comparison-BF.html#cb506-8"></a>  <span class="co"># how many warmup steps</span></span>
<span id="cb506-9"><a href="Chap-03-06-model-comparison-BF.html#cb506-9"></a>  <span class="dt">warmup =</span> <span class="dv">2000</span></span>
<span id="cb506-10"><a href="Chap-03-06-model-comparison-BF.html#cb506-10"></a>)</span></code></pre></div>
<pre><code>## 
## SAMPLING FOR MODEL &#39;model_comp_power_forgetting&#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 1.2e-05 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:     1 / 20000 [  0%]  (Warmup)
## Chain 1: Iteration:  2000 / 20000 [ 10%]  (Warmup)
## Chain 1: Iteration:  2001 / 20000 [ 10%]  (Sampling)
## Chain 1: Iteration:  4000 / 20000 [ 20%]  (Sampling)
## Chain 1: Iteration:  6000 / 20000 [ 30%]  (Sampling)
## Chain 1: Iteration:  8000 / 20000 [ 40%]  (Sampling)
## Chain 1: Iteration: 10000 / 20000 [ 50%]  (Sampling)
## Chain 1: Iteration: 12000 / 20000 [ 60%]  (Sampling)
## Chain 1: Iteration: 14000 / 20000 [ 70%]  (Sampling)
## Chain 1: Iteration: 16000 / 20000 [ 80%]  (Sampling)
## Chain 1: Iteration: 18000 / 20000 [ 90%]  (Sampling)
## Chain 1: Iteration: 20000 / 20000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.045508 seconds (Warm-up)
## Chain 1:                0.37634 seconds (Sampling)
## Chain 1:                0.421848 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &#39;model_comp_power_forgetting&#39; NOW (CHAIN 2).
## Chain 2: Rejecting initial value:
## Chain 2:   Error evaluating the log probability at the initial value.
## Chain 2: Exception: binomial_lpmf: Probability parameter is 1.31725, but must be in the interval [0, 1]  (in &#39;model3e9655fa1358_model_comp_power_forgetting&#39; at line 13)
## 
## Chain 2: 
## Chain 2: Gradient evaluation took 1e-05 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:     1 / 20000 [  0%]  (Warmup)
## Chain 2: Iteration:  2000 / 20000 [ 10%]  (Warmup)
## Chain 2: Iteration:  2001 / 20000 [ 10%]  (Sampling)
## Chain 2: Iteration:  4000 / 20000 [ 20%]  (Sampling)
## Chain 2: Iteration:  6000 / 20000 [ 30%]  (Sampling)
## Chain 2: Iteration:  8000 / 20000 [ 40%]  (Sampling)
## Chain 2: Iteration: 10000 / 20000 [ 50%]  (Sampling)
## Chain 2: Iteration: 12000 / 20000 [ 60%]  (Sampling)
## Chain 2: Iteration: 14000 / 20000 [ 70%]  (Sampling)
## Chain 2: Iteration: 16000 / 20000 [ 80%]  (Sampling)
## Chain 2: Iteration: 18000 / 20000 [ 90%]  (Sampling)
## Chain 2: Iteration: 20000 / 20000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.044843 seconds (Warm-up)
## Chain 2:                0.333266 seconds (Sampling)
## Chain 2:                0.378109 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL &#39;model_comp_power_forgetting&#39; NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 1e-05 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:     1 / 20000 [  0%]  (Warmup)
## Chain 3: Iteration:  2000 / 20000 [ 10%]  (Warmup)
## Chain 3: Iteration:  2001 / 20000 [ 10%]  (Sampling)
## Chain 3: Iteration:  4000 / 20000 [ 20%]  (Sampling)
## Chain 3: Iteration:  6000 / 20000 [ 30%]  (Sampling)
## Chain 3: Iteration:  8000 / 20000 [ 40%]  (Sampling)
## Chain 3: Iteration: 10000 / 20000 [ 50%]  (Sampling)
## Chain 3: Iteration: 12000 / 20000 [ 60%]  (Sampling)
## Chain 3: Iteration: 14000 / 20000 [ 70%]  (Sampling)
## Chain 3: Iteration: 16000 / 20000 [ 80%]  (Sampling)
## Chain 3: Iteration: 18000 / 20000 [ 90%]  (Sampling)
## Chain 3: Iteration: 20000 / 20000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 0.046901 seconds (Warm-up)
## Chain 3:                0.365732 seconds (Sampling)
## Chain 3:                0.412633 seconds (Total)
## Chain 3: 
## 
## SAMPLING FOR MODEL &#39;model_comp_power_forgetting&#39; NOW (CHAIN 4).
## Chain 4: Rejecting initial value:
## Chain 4:   Error evaluating the log probability at the initial value.
## Chain 4: Exception: binomial_lpmf: Probability parameter is 1.16612, but must be in the interval [0, 1]  (in &#39;model3e9655fa1358_model_comp_power_forgetting&#39; at line 13)
## 
## Chain 4: 
## Chain 4: Gradient evaluation took 1e-05 seconds
## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.
## Chain 4: Adjust your expectations accordingly!
## Chain 4: 
## Chain 4: 
## Chain 4: Iteration:     1 / 20000 [  0%]  (Warmup)
## Chain 4: Iteration:  2000 / 20000 [ 10%]  (Warmup)
## Chain 4: Iteration:  2001 / 20000 [ 10%]  (Sampling)
## Chain 4: Iteration:  4000 / 20000 [ 20%]  (Sampling)
## Chain 4: Iteration:  6000 / 20000 [ 30%]  (Sampling)
## Chain 4: Iteration:  8000 / 20000 [ 40%]  (Sampling)
## Chain 4: Iteration: 10000 / 20000 [ 50%]  (Sampling)
## Chain 4: Iteration: 12000 / 20000 [ 60%]  (Sampling)
## Chain 4: Iteration: 14000 / 20000 [ 70%]  (Sampling)
## Chain 4: Iteration: 16000 / 20000 [ 80%]  (Sampling)
## Chain 4: Iteration: 18000 / 20000 [ 90%]  (Sampling)
## Chain 4: Iteration: 20000 / 20000 [100%]  (Sampling)
## Chain 4: 
## Chain 4:  Elapsed Time: 0.046359 seconds (Warm-up)
## Chain 4:                0.398662 seconds (Sampling)
## Chain 4:                0.445021 seconds (Total)
## Chain 4:</code></pre>
<p>The <code>bridgesampling</code> package can then be used to calculate each model’s marginal likelihood.</p>
<div class="sourceCode" id="cb508"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb508-1"><a href="Chap-03-06-model-comparison-BF.html#cb508-1"></a>expon_bridge &lt;-<span class="st"> </span>bridgesampling<span class="op">::</span><span class="kw">bridge_sampler</span>(stan_fit_expon, <span class="dt">silent =</span> T)</span>
<span id="cb508-2"><a href="Chap-03-06-model-comparison-BF.html#cb508-2"></a>power_bridge &lt;-<span class="st"> </span>bridgesampling<span class="op">::</span><span class="kw">bridge_sampler</span>(stan_fit_power, <span class="dt">silent =</span> T)</span></code></pre></div>
<p>We then obtain an estimate of the Bayes factor in favor of the exponential model with this function:</p>
<div class="sourceCode" id="cb509"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb509-1"><a href="Chap-03-06-model-comparison-BF.html#cb509-1"></a>bridgesampling<span class="op">::</span><span class="kw">bf</span>(expon_bridge, power_bridge)</span></code></pre></div>
<pre><code>## Estimated Bayes factor in favor of expon_bridge over power_bridge: 1220.52849</code></pre>

</div>
</div>
<!-- </div> -->
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-GronauLy2019:Informed-Bayesi">
<p>Gronau, Quentin F., Alexander Ly, and Eric-Jan Wagenmakers. 2019. “Informed Bayesian <em>T</em>-Tests.” <em>The American Statistician</em>.</p>
</div>
<div id="ref-GronauSarafoglou2017:A-tutorial-on-b">
<p>Gronau, Quentin F., Alexandra Sarafoglou, Dora Matzke, Alexander Ly, Udo Boehm, Maarten Marsman, David S. Leslie, Jonathan J. Forster, Eric-Jan Wagenmakers, and Helen Steingroever. 2017. “A Tutorial on Bridge Sampling.” <em>Journal of Mathematical Psychology</em> 81: 80–97.</p>
</div>
<div id="ref-RouderMorey2012:Default-Bayes-F">
<p>Rouder, Jeffrey N., and Richard D. Morey. 2012. “Default Bayes Factors for Model Selection in Regression.” <em>Multivariate Behavioral Research</em> 47 (6): 877–903.</p>
</div>
<div id="ref-RouderSpeckman2009:Bayesian-t-test">
<p>Rouder, Jeffrey N., Paul l. Speckman, Dongchu Sun, Richard D. Morey, and Geoffrey Iverson. 2009. “Bayesian <em>T</em> Tests for Accepting and Rejecting the Null Hypothesis.” <em>Psychonomic Bulletin &amp; Review</em> 16 (2): 225–37.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="Chap-03-06-model-comparison-AIC.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ch-03-07-hypothesis-testing-Bayes.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
